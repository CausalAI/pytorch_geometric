

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torch_geometric.nn.conv.message_passing &mdash; pytorch_geometric 1.4.3 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../../../_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../index.html">
          

          
            
            <img src="../../../../_static/pyg_logo_text.svg" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                1.4.3
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/installation.html">PyG 安装</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../notes/installation.html#id1">安装步骤</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../notes/installation.html#c-cuda-extensions-on-macos">C++/CUDA Extensions on macOS</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../notes/installation.html#id2">常见问题集</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/introduction.html">PyG中基本概念</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../notes/introduction.html#id1">图数据类</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../notes/introduction.html#id2">基准数据集</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../notes/introduction.html#mini-batches">Mini-batches</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../notes/introduction.html#data-transforms">Data Transforms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../notes/introduction.html#id3">图网络端对端例子</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/create_gnn.html">图网络消息传递框架</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../notes/create_gnn.html#messagepassing">“MessagePassing” 基类</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../notes/create_gnn.html#gcn">GCN层实现</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../notes/create_gnn.html#id2">边卷积层的实现</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/create_dataset.html">构建数据集</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../notes/create_dataset.html#creating-in-memory-datasets">Creating “In Memory Datasets”</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../notes/create_dataset.html#creating-larger-datasets">Creating “Larger” Datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../notes/create_dataset.html#id2">常见问题集</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/batching.html">Advanced Mini-Batching</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../notes/batching.html#pairs-of-graphs">Pairs of Graphs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../notes/batching.html#bipartite-graphs">Bipartite Graphs</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/resources.html">相关资料</a></li>
</ul>
<p class="caption"><span class="caption-text">Graph Networks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebooks/01-quick_survey.html">PyG 的快速调研</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../notebooks/01-quick_survey.html#资料">资料</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../notebooks/01-quick_survey.html#综述理解">综述理解</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../notebooks/01-quick_survey.html#课程内容">课程内容</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../notebooks/01-quick_survey.html#重点阅读">重点阅读</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../notebooks/01-quick_survey.html#GCN,GAT,GraphSAGE框架回顾及其PyG复现">GCN,GAT,GraphSAGE框架回顾及其PyG复现</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../notebooks/01-quick_survey.html#图网络综述">图网络综述</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../notebooks/01-quick_survey.html#Introduction-to-Graph-Neural-Networks">Introduction to Graph Neural Networks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../notebooks/01-quick_survey.html#为什么图网络会有用？">为什么图网络会有用？</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebooks/02-researchers.html">图网络 Researchers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../notebooks/02-researchers.html#Tsinghua">Tsinghua</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../notebooks/02-researchers.html#Bengio">Bengio</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Package Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../modules/root.html">torch_geometric</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../modules/nn.html">torch_geometric.nn</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/nn.html#module-torch_geometric.nn.conv.message_passing">Convolutional Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/nn.html#module-torch_geometric.nn.dense.dense_gcn_conv">Dense Convolutional Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/nn.html#module-torch_geometric.nn.norm">Normalization Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/nn.html#module-torch_geometric.nn.glob">Global Pooling Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/nn.html#module-torch_geometric.nn.pool">Pooling Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/nn.html#module-torch_geometric.nn.dense.diff_pool">Dense Pooling Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/nn.html#module-torch_geometric.nn.unpool">Unpooling Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/nn.html#module-torch_geometric.nn.models">Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/nn.html#module-torch_geometric.nn.data_parallel">DataParallel Layers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../modules/data.html">torch_geometric.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../modules/datasets.html">torch_geometric.datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../modules/transforms.html">torch_geometric.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../modules/utils.html">torch_geometric.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../modules/io.html">torch_geometric.io</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">pytorch_geometric</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../../index.html">Module code</a> &raquo;</li>
        
      <li>torch_geometric.nn.conv.message_passing</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for torch_geometric.nn.conv.message_passing</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">inspect</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="k">import</span> <span class="n">OrderedDict</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch_sparse</span> <span class="k">import</span> <span class="n">SparseTensor</span>
<span class="kn">from</span> <span class="nn">torch_scatter</span> <span class="k">import</span> <span class="n">gather_csr</span><span class="p">,</span> <span class="n">scatter</span><span class="p">,</span> <span class="n">segment_csr</span>

<span class="n">msg_aggr_special_args</span> <span class="o">=</span> <span class="nb">set</span><span class="p">([</span>
    <span class="s1">&#39;adj_t&#39;</span><span class="p">,</span>
<span class="p">])</span>

<span class="n">msg_special_args</span> <span class="o">=</span> <span class="nb">set</span><span class="p">([</span>
    <span class="s1">&#39;edge_index_i&#39;</span><span class="p">,</span>
    <span class="s1">&#39;edge_index_j&#39;</span><span class="p">,</span>
    <span class="s1">&#39;size_i&#39;</span><span class="p">,</span>
    <span class="s1">&#39;size_j&#39;</span><span class="p">,</span>
<span class="p">])</span>

<span class="n">aggr_special_args</span> <span class="o">=</span> <span class="nb">set</span><span class="p">([</span>
    <span class="s1">&#39;ptr&#39;</span><span class="p">,</span>
    <span class="s1">&#39;index&#39;</span><span class="p">,</span>
    <span class="s1">&#39;dim_size&#39;</span><span class="p">,</span>
<span class="p">])</span>

<span class="n">update_special_args</span> <span class="o">=</span> <span class="nb">set</span><span class="p">([])</span>


<div class="viewcode-block" id="MessagePassing"><a class="viewcode-back" href="../../../../modules/nn.html#torch_geometric.nn.conv.message_passing.MessagePassing">[docs]</a><span class="k">class</span> <span class="nc">MessagePassing</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Base class for creating message passing layers of the form</span>

<span class="sd">    .. math::</span>
<span class="sd">        \mathbf{x}_i^{\prime} = \gamma_{\mathbf{\Theta}} \left( \mathbf{x}_i,</span>
<span class="sd">        \square_{j \in \mathcal{N}(i)} \, \phi_{\mathbf{\Theta}}</span>
<span class="sd">        \left(\mathbf{x}_i, \mathbf{x}_j,\mathbf{e}_{i,j}\right) \right),</span>

<span class="sd">    where :math:`\square` denotes a differentiable, permutation invariant</span>
<span class="sd">    function, *e.g.*, sum, mean or max, and :math:`\gamma_{\mathbf{\Theta}}`</span>
<span class="sd">    and :math:`\phi_{\mathbf{\Theta}}` denote differentiable functions such as</span>
<span class="sd">    MLPs.</span>
<span class="sd">    See `here &lt;https://pytorch-geometric.readthedocs.io/en/latest/notes/</span>
<span class="sd">    create_gnn.html&gt;`__ for the accompanying tutorial.</span>

<span class="sd">    Args:</span>
<span class="sd">        aggr (string, optional): The aggregation scheme to use</span>
<span class="sd">            (:obj:`&quot;add&quot;`, :obj:`&quot;mean&quot;`, :obj:`&quot;max&quot;` or :obj:`None`).</span>
<span class="sd">            (default: :obj:`&quot;add&quot;`)</span>
<span class="sd">        flow (string, optional): The flow direction of message passing</span>
<span class="sd">            (:obj:`&quot;source_to_target&quot;` or :obj:`&quot;target_to_source&quot;`).</span>
<span class="sd">            (default: :obj:`&quot;source_to_target&quot;`)</span>
<span class="sd">        node_dim (int, optional): The axis along which to propagate.</span>
<span class="sd">            (default: :obj:`0`)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">aggr</span><span class="o">=</span><span class="s2">&quot;add&quot;</span><span class="p">,</span> <span class="n">flow</span><span class="o">=</span><span class="s2">&quot;source_to_target&quot;</span><span class="p">,</span> <span class="n">node_dim</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MessagePassing</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">aggr</span> <span class="o">=</span> <span class="n">aggr</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">aggr</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;add&#39;</span><span class="p">,</span> <span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="s1">&#39;max&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">flow</span> <span class="o">=</span> <span class="n">flow</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">flow</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;source_to_target&#39;</span><span class="p">,</span> <span class="s1">&#39;target_to_source&#39;</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">node_dim</span> <span class="o">=</span> <span class="n">node_dim</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_dim</span> <span class="o">&gt;=</span> <span class="mi">0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">__msg_aggr_params__</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">message_and_aggregate</span><span class="p">)</span><span class="o">.</span><span class="n">parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__msg_aggr_params__</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__msg_aggr_params__</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">__msg_params__</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">message</span><span class="p">)</span><span class="o">.</span><span class="n">parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__msg_params__</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__msg_params__</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">__aggr_params__</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">aggregate</span><span class="p">)</span><span class="o">.</span><span class="n">parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__aggr_params__</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__aggr_params__</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__aggr_params__</span><span class="o">.</span><span class="n">popitem</span><span class="p">(</span><span class="n">last</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">__update_params__</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">)</span><span class="o">.</span><span class="n">parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__update_params__</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__update_params__</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__update_params__</span><span class="o">.</span><span class="n">popitem</span><span class="p">(</span><span class="n">last</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="n">msg_aggr_args</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__msg_aggr_params__</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">-</span> <span class="n">msg_aggr_special_args</span>
        <span class="n">msg_args</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__msg_params__</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">-</span> <span class="n">msg_special_args</span>
        <span class="n">aggr_args</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__aggr_params__</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">-</span> <span class="n">aggr_special_args</span>
        <span class="n">update_args</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__update_params__</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">-</span> <span class="n">update_special_args</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">__user_args__</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">msg_aggr_args</span><span class="p">,</span> <span class="n">msg_args</span><span class="p">,</span> <span class="n">aggr_args</span><span class="p">,</span>
                                         <span class="n">update_args</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">__fuse__</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">__get_mp_type__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">):</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">edge_index</span><span class="p">)</span> <span class="ow">and</span> <span class="n">edge_index</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">long</span>
                <span class="ow">and</span> <span class="n">edge_index</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">edge_index</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)):</span>
            <span class="k">return</span> <span class="s1">&#39;edge_index&#39;</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">SparseTensor</span><span class="p">):</span>
            <span class="k">return</span> <span class="s1">&#39;adj_t&#39;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="p">(</span><span class="s1">&#39;`MessagePassing.propagate` only supports `torch.LongTensor` &#39;</span>
                 <span class="s1">&#39;of shape `[2, num_messages]` or `torch_sparse.SparseTensor` &#39;</span>
                 <span class="s1">&#39;for argument :obj:`edge_index`.&#39;</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">__set_size__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">tensor</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
            <span class="k">pass</span>
        <span class="k">elif</span> <span class="n">size</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">size</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">node_dim</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">size</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">!=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">node_dim</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="p">(</span><span class="n">f</span><span class="s1">&#39;Encountered node tensor with size &#39;</span>
                 <span class="n">f</span><span class="s1">&#39;{tensor.size(self.node_dim)} in dimension </span><span class="si">{self.node_dim}</span><span class="s1">, &#39;</span>
                 <span class="n">f</span><span class="s1">&#39;but expected size </span><span class="si">{size[idx]}</span><span class="s1">.&#39;</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">__collect__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">mp_type</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">):</span>
        <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">flow</span> <span class="o">==</span> <span class="s1">&#39;target_to_source&#39;</span> <span class="k">else</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">ij</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;_i&#39;</span><span class="p">:</span> <span class="n">i</span><span class="p">,</span> <span class="s1">&#39;_j&#39;</span><span class="p">:</span> <span class="n">j</span><span class="p">}</span>

        <span class="n">out</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">arg</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">__user_args__</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">arg</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ij</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">out</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">arg</span><span class="p">,</span> <span class="n">inspect</span><span class="o">.</span><span class="n">Parameter</span><span class="o">.</span><span class="n">empty</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">idx</span> <span class="o">=</span> <span class="n">ij</span><span class="p">[</span><span class="n">arg</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]]</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">arg</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">inspect</span><span class="o">.</span><span class="n">Parameter</span><span class="o">.</span><span class="n">empty</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">data</span> <span class="ow">is</span> <span class="n">inspect</span><span class="o">.</span><span class="n">Parameter</span><span class="o">.</span><span class="n">empty</span><span class="p">:</span>
                    <span class="n">out</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span>
                    <span class="k">continue</span>

                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">__set_size__</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">idx</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="mi">1</span> <span class="o">-</span> <span class="n">idx</span><span class="p">])</span>
                    <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

                <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
                    <span class="n">out</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span>
                    <span class="k">continue</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">__set_size__</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">mp_type</span> <span class="o">==</span> <span class="s1">&#39;edge_index&#39;</span><span class="p">:</span>
                    <span class="n">out</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">node_dim</span><span class="p">,</span>
                                                 <span class="n">edge_index</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
                <span class="k">elif</span> <span class="n">mp_type</span> <span class="o">==</span> <span class="s1">&#39;adj_t&#39;</span> <span class="ow">and</span> <span class="n">idx</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">rowptr</span> <span class="o">=</span> <span class="n">edge_index</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">rowptr</span><span class="p">()</span>
                    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">node_dim</span><span class="p">):</span>
                        <span class="n">rowptr</span> <span class="o">=</span> <span class="n">rowptr</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">out</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span> <span class="o">=</span> <span class="n">gather_csr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">rowptr</span><span class="p">)</span>
                <span class="k">elif</span> <span class="n">mp_type</span> <span class="o">==</span> <span class="s1">&#39;adj_t&#39;</span> <span class="ow">and</span> <span class="n">idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">col</span> <span class="o">=</span> <span class="n">edge_index</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">col</span><span class="p">()</span>
                    <span class="n">out</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">node_dim</span><span class="p">,</span> <span class="n">col</span><span class="p">)</span>

        <span class="n">size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="n">size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">mp_type</span> <span class="o">==</span> <span class="s1">&#39;edge_index&#39;</span><span class="p">:</span>
            <span class="n">out</span><span class="p">[</span><span class="s1">&#39;edge_index_j&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">edge_index</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
            <span class="n">out</span><span class="p">[</span><span class="s1">&#39;edge_index_i&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">edge_index</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">out</span><span class="p">[</span><span class="s1">&#39;index&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">out</span><span class="p">[</span><span class="s1">&#39;edge_index_i&#39;</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">mp_type</span> <span class="o">==</span> <span class="s1">&#39;adj_t&#39;</span><span class="p">:</span>
            <span class="n">out</span><span class="p">[</span><span class="s1">&#39;adj_t&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">edge_index</span>
            <span class="n">out</span><span class="p">[</span><span class="s1">&#39;edge_index_i&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">edge_index</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">row</span><span class="p">()</span>
            <span class="n">out</span><span class="p">[</span><span class="s1">&#39;edge_index_j&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">edge_index</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">col</span><span class="p">()</span>
            <span class="n">out</span><span class="p">[</span><span class="s1">&#39;index&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">edge_index</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">row</span><span class="p">()</span>
            <span class="n">out</span><span class="p">[</span><span class="s1">&#39;ptr&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">edge_index</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">rowptr</span><span class="p">()</span>
            <span class="n">out</span><span class="p">[</span><span class="s1">&#39;edge_attr&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">edge_index</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">value</span><span class="p">()</span>

        <span class="n">out</span><span class="p">[</span><span class="s1">&#39;size_j&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">size</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
        <span class="n">out</span><span class="p">[</span><span class="s1">&#39;size_i&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">size</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">out</span><span class="p">[</span><span class="s1">&#39;dim_size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">out</span><span class="p">[</span><span class="s1">&#39;size_i&#39;</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">out</span>

    <span class="k">def</span> <span class="nf">__distribute__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">params</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">inspect</span><span class="o">.</span><span class="n">Parameter</span><span class="o">.</span><span class="n">empty</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">data</span> <span class="ow">is</span> <span class="n">inspect</span><span class="o">.</span><span class="n">Parameter</span><span class="o">.</span><span class="n">empty</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">default</span> <span class="ow">is</span> <span class="n">inspect</span><span class="o">.</span><span class="n">Parameter</span><span class="o">.</span><span class="n">empty</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Required parameter </span><span class="si">{key}</span><span class="s1"> is empty.&#39;</span><span class="p">)</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">default</span>
            <span class="n">out</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span>
        <span class="k">return</span> <span class="n">out</span>

<div class="viewcode-block" id="MessagePassing.propagate"><a class="viewcode-back" href="../../../../modules/nn.html#torch_geometric.nn.conv.message_passing.MessagePassing.propagate">[docs]</a>    <span class="k">def</span> <span class="nf">propagate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;The initial call to start propagating messages.</span>

<span class="sd">        Args:</span>
<span class="sd">            adj (Tensor or SparseTensor): A :obj:`torch.LongTensor` or a</span>
<span class="sd">                :obj:`torch_sparse.SparseTensor` that defines the underlying</span>
<span class="sd">                message propagation.</span>
<span class="sd">                :obj:`edge_index` holds the indices of a general (sparse)</span>
<span class="sd">                assignment matrix of shape :obj:`[N, M]`.</span>
<span class="sd">                If :obj:`edge_index` is of type :obj:`torch.LongTensor`, its</span>
<span class="sd">                shape must be defined as :obj:`[2, num_messages]`, where</span>
<span class="sd">                messages from nodes in :obj:`edge_index[0]` are sent to</span>
<span class="sd">                nodes in :obj:`edge_index[1]`</span>
<span class="sd">                (in case :obj:`flow=&quot;source_to_target&quot;`).</span>
<span class="sd">                If :obj:`edge_index` is of type</span>
<span class="sd">                :obj:`torch_sparse.SparseTensor`, its sparse indices</span>
<span class="sd">                :obj:`(row, col)` should relate to :obj:`row = edge_index[1]`</span>
<span class="sd">                and :obj:`col = edge_index[0]`.</span>
<span class="sd">                Hence, the only difference between those formats is that we</span>
<span class="sd">                need to input the *transposed* sparse adjacency matrix into</span>
<span class="sd">                :func:`propagate`.</span>
<span class="sd">            size (list or tuple, optional): The size :obj:`[N, M]` of the</span>
<span class="sd">                assignment matrix in case :obj:`edge_index` is a</span>
<span class="sd">                :obj:`LongTensor`.</span>
<span class="sd">                If set to :obj:`None`, the size will be automatically inferred</span>
<span class="sd">                and assumed to be quadratic.</span>
<span class="sd">                This argument is ignored in case :obj:`edge_index` is a</span>
<span class="sd">                :obj:`torch_sparse.SparseTensor`. (default: :obj:`None`)</span>
<span class="sd">            **kwargs: Any additional data which is needed to construct and</span>
<span class="sd">                aggregate messages, and to update node embeddings.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># We need to distinguish between the old `edge_index` format and the</span>
        <span class="c1"># new `torch_sparse.SparseTensor` format.</span>
        <span class="n">mp_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__get_mp_type__</span><span class="p">(</span><span class="n">edge_index</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">mp_type</span> <span class="o">==</span> <span class="s1">&#39;adj_t&#39;</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">flow</span> <span class="o">==</span> <span class="s1">&#39;target_to_source&#39;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="p">(</span><span class="s1">&#39;Flow direction &quot;target_to_source&quot; is invalid for message &#39;</span>
                 <span class="s1">&#39;propagation based on `torch_sparse.SparseTensor`. If you &#39;</span>
                 <span class="s1">&#39;really want to make use of a reverse message passing flow, &#39;</span>
                 <span class="s1">&#39;pass in the transposed sparse tensor to the message passing &#39;</span>
                 <span class="s1">&#39;module, e.g., `adj.t()`.&#39;</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">mp_type</span> <span class="o">==</span> <span class="s1">&#39;edge_index&#39;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">size</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                <span class="n">size</span> <span class="o">=</span> <span class="p">[</span><span class="n">size</span><span class="p">,</span> <span class="n">size</span><span class="p">]</span>
            <span class="k">elif</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">size</span><span class="p">):</span>
                <span class="n">size</span> <span class="o">=</span> <span class="n">size</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                <span class="n">size</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mp_type</span> <span class="o">==</span> <span class="s1">&#39;adj_t&#39;</span><span class="p">:</span>
            <span class="n">size</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">edge_index</span><span class="o">.</span><span class="n">sparse_sizes</span><span class="p">())[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">size</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>

        <span class="c1"># We collect all arguments used for message passing in `kwargs`.</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__collect__</span><span class="p">(</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">mp_type</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># Try to run `message_and_aggregate` first and see if it succeeds:</span>
        <span class="k">if</span> <span class="n">mp_type</span> <span class="o">==</span> <span class="s1">&#39;adj_t&#39;</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">__fuse__</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">msg_aggr_kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__distribute__</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__msg_aggr_params__</span><span class="p">,</span>
                                                  <span class="n">kwargs</span><span class="p">)</span>
            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">message_and_aggregate</span><span class="p">(</span><span class="o">**</span><span class="n">msg_aggr_kwargs</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">out</span> <span class="o">==</span> <span class="bp">NotImplemented</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__fuse__</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># Otherwise, run both functions in separation.</span>
        <span class="k">if</span> <span class="n">mp_type</span> <span class="o">==</span> <span class="s1">&#39;edge_index&#39;</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">__fuse__</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
            <span class="n">msg_kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__distribute__</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__msg_params__</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>
            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">message</span><span class="p">(</span><span class="o">**</span><span class="n">msg_kwargs</span><span class="p">)</span>

            <span class="n">aggr_kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__distribute__</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__aggr_params__</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>
            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">aggregate</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="o">**</span><span class="n">aggr_kwargs</span><span class="p">)</span>

        <span class="n">update_kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__distribute__</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__update_params__</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="o">**</span><span class="n">update_kwargs</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span></div>

<div class="viewcode-block" id="MessagePassing.message"><a class="viewcode-back" href="../../../../modules/nn.html#torch_geometric.nn.conv.message_passing.MessagePassing.message">[docs]</a>    <span class="k">def</span> <span class="nf">message</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_j</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Constructs messages from node :math:`j` to node :math:`i`</span>
<span class="sd">        in analogy to :math:`\phi_{\mathbf{\Theta}}` for each edge in</span>
<span class="sd">        :obj:`edge_index`.</span>
<span class="sd">        This function can take any argument as input which was initially</span>
<span class="sd">        passed to :meth:`propagate`.</span>
<span class="sd">        Furthermore, tensors passed to :meth:`propagate` can be mapped to the</span>
<span class="sd">        respective nodes :math:`i` and :math:`j` by appending :obj:`_i` or</span>
<span class="sd">        :obj:`_j` to the variable name, *.e.g.* :obj:`x_i` and :obj:`x_j`.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">x_j</span></div>

<div class="viewcode-block" id="MessagePassing.aggregate"><a class="viewcode-back" href="../../../../modules/nn.html#torch_geometric.nn.conv.message_passing.MessagePassing.aggregate">[docs]</a>    <span class="k">def</span> <span class="nf">aggregate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">ptr</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim_size</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Aggregates messages from neighbors as</span>
<span class="sd">        :math:`\square_{j \in \mathcal{N}(i)}`.</span>

<span class="sd">        Takes in the output of message computation as first argument and any</span>
<span class="sd">        argument which was initially passed to :meth:`propagate`.</span>

<span class="sd">        By default, this function will delegate its call to scatter functions</span>
<span class="sd">        that support &quot;add&quot;, &quot;mean&quot; and &quot;max&quot; operations as specified in</span>
<span class="sd">        :meth:`__init__` by the :obj:`aggr` argument.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">ptr</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">node_dim</span><span class="p">):</span>
                <span class="n">ptr</span> <span class="o">=</span> <span class="n">ptr</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">segment_csr</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">ptr</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">aggr</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">scatter</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">node_dim</span><span class="p">,</span> <span class="n">dim_size</span><span class="o">=</span><span class="n">dim_size</span><span class="p">,</span>
                           <span class="n">reduce</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">aggr</span><span class="p">)</span></div>

<div class="viewcode-block" id="MessagePassing.message_and_aggregate"><a class="viewcode-back" href="../../../../modules/nn.html#torch_geometric.nn.conv.message_passing.MessagePassing.message_and_aggregate">[docs]</a>    <span class="k">def</span> <span class="nf">message_and_aggregate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">adj_t</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Fuses computations of :func:`message` and :func:`aggregate` into a</span>
<span class="sd">        single function.</span>
<span class="sd">        If applicable, this saves both time and memory since messages do not</span>
<span class="sd">        explicitly need to be materialized.</span>
<span class="sd">        This function will only gets called in case it is implemented and</span>
<span class="sd">        propagation takes place based on a :obj:`torch_sparse.SparseTensor`.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="bp">NotImplemented</span></div>

<div class="viewcode-block" id="MessagePassing.update"><a class="viewcode-back" href="../../../../modules/nn.html#torch_geometric.nn.conv.message_passing.MessagePassing.update">[docs]</a>    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Updates node embeddings in analogy to</span>
<span class="sd">        :math:`\gamma_{\mathbf{\Theta}}` for each node</span>
<span class="sd">        :math:`i \in \mathcal{V}`.</span>
<span class="sd">        Takes in the output of aggregation as first argument and any argument</span>
<span class="sd">        which was initially passed to :meth:`propagate`.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">inputs</span></div></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Matthias Fey

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>