

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>图网络消息传递框架 &mdash; pytorch_geometric 1.4.3 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="构建数据集" href="create_dataset.html" />
    <link rel="prev" title="PyG中基本概念" href="introduction.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html">
          

          
            
            <img src="../_static/pyg_logo_text.svg" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                1.4.3
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Notes</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">PyG 安装</a><ul>
<li class="toctree-l2"><a class="reference internal" href="installation.html#id1">安装步骤</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#c-cuda-extensions-on-macos">C++/CUDA Extensions on macOS</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#id2">常见问题集</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="introduction.html">PyG中基本概念</a><ul>
<li class="toctree-l2"><a class="reference internal" href="introduction.html#id1">图数据类</a></li>
<li class="toctree-l2"><a class="reference internal" href="introduction.html#id2">基准数据集</a></li>
<li class="toctree-l2"><a class="reference internal" href="introduction.html#mini-batches">Mini-batches</a></li>
<li class="toctree-l2"><a class="reference internal" href="introduction.html#data-transforms">Data Transforms</a></li>
<li class="toctree-l2"><a class="reference internal" href="introduction.html#id3">图网络端对端例子</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">图网络消息传递框架</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#messagepassing">“MessagePassing” 基类</a></li>
<li class="toctree-l2"><a class="reference internal" href="#gcn">GCN层实现</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id2">边卷积层的实现</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="create_dataset.html">构建数据集</a><ul>
<li class="toctree-l2"><a class="reference internal" href="create_dataset.html#creating-in-memory-datasets">Creating “In Memory Datasets”</a></li>
<li class="toctree-l2"><a class="reference internal" href="create_dataset.html#creating-larger-datasets">Creating “Larger” Datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="create_dataset.html#id2">常见问题集</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="batching.html">Advanced Mini-Batching</a><ul>
<li class="toctree-l2"><a class="reference internal" href="batching.html#pairs-of-graphs">Pairs of Graphs</a></li>
<li class="toctree-l2"><a class="reference internal" href="batching.html#bipartite-graphs">Bipartite Graphs</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="resources.html">相关资料</a></li>
</ul>
<p class="caption"><span class="caption-text">从PyG到图网路</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../notebooks/01-quick_survey.html">PyG 的快速调研</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/01-quick_survey.html#资料">资料</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/01-quick_survey.html#综述理解">综述理解</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/01-quick_survey.html#课程内容">课程内容</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/01-quick_survey.html#重点阅读">重点阅读</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/01-quick_survey.html#GCN,GAT,GraphSAGE框架回顾及其PyG复现">GCN,GAT,GraphSAGE框架回顾及其PyG复现</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/01-quick_survey.html#图网络综述">图网络综述</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/01-quick_survey.html#Introduction-to-Graph-Neural-Networks">Introduction to Graph Neural Networks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/01-quick_survey.html#为什么图网络会有用？">为什么图网络会有用？</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks/02-researchers.html">图网络 Researchers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/02-researchers.html#Tsinghua">Tsinghua</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/02-researchers.html#Bengio">Bengio</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Package Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../modules/root.html">torch_geometric</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/nn.html">torch_geometric.nn</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../modules/nn.html#module-torch_geometric.nn.conv.message_passing">Convolutional Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../modules/nn.html#module-torch_geometric.nn.dense.dense_gcn_conv">Dense Convolutional Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../modules/nn.html#module-torch_geometric.nn.norm">Normalization Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../modules/nn.html#module-torch_geometric.nn.glob">Global Pooling Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../modules/nn.html#module-torch_geometric.nn.pool">Pooling Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../modules/nn.html#module-torch_geometric.nn.dense.diff_pool">Dense Pooling Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../modules/nn.html#module-torch_geometric.nn.unpool">Unpooling Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../modules/nn.html#module-torch_geometric.nn.models">Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../modules/nn.html#module-torch_geometric.nn.data_parallel">DataParallel Layers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../modules/data.html">torch_geometric.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/datasets.html">torch_geometric.datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/transforms.html">torch_geometric.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/utils.html">torch_geometric.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../modules/io.html">torch_geometric.io</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">pytorch_geometric</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>图网络消息传递框架</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/notes/create_gnn.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="id1">
<h1>图网络消息传递框架<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<p>将卷积算子推广到不规则域 is typically expressed as a <em>neighborhood aggregation</em> or <em>message passing</em> scheme.
我们用 <span class="math notranslate nohighlight">\(\mathbf{x}^{(k-1)}_i \in \mathbb{R}^F\)</span> 表示第 <span class="math notranslate nohighlight">\((k-1)\)</span> 层 node <span class="math notranslate nohighlight">\(i\)</span> 的节点特征， <span class="math notranslate nohighlight">\(\mathbf{e}_{j,i} \in \mathbb{R}^D\)</span> 表示从node <span class="math notranslate nohighlight">\(j\)</span> 到 node <span class="math notranslate nohighlight">\(i\)</span> 的边特征， 则消息传递图神经网络可以描述为</p>
<div class="math notranslate nohighlight">
\[\mathbf{x}_i^{(k)} = \gamma^{(k)} \left( \mathbf{x}_i^{(k-1)}, \square_{j \in \mathcal{N}(i)} \, \phi^{(k)}\left(\mathbf{x}_i^{(k-1)}, \mathbf{x}_j^{(k-1)},\mathbf{e}_{j,i}\right) \right),\]</div>
<p>其中 <span class="math notranslate nohighlight">\(\square\)</span> 表示具有置换不变性的可微函数(例如 sum, mean or max, and <span class="math notranslate nohighlight">\(\gamma\)</span>)， <span class="math notranslate nohighlight">\(\phi\)</span> 表示可微函数(例如多层感知机 MLPs).</p>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#messagepassing" id="id3">“MessagePassing” 基类</a></p></li>
<li><p><a class="reference internal" href="#gcn" id="id4">GCN层实现</a></p></li>
<li><p><a class="reference internal" href="#id2" id="id5">边卷积层的实现</a></p></li>
</ul>
</div>
<div class="section" id="messagepassing">
<h2><a class="toc-backref" href="#id3">“MessagePassing” 基类</a><a class="headerlink" href="#messagepassing" title="Permalink to this headline">¶</a></h2>
<p>PyTorch Geometric 提供了 <code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.MessagePassing</span></code> 基类，来帮助创建消息传递图神经网络。因此我们只需要指定函数 <span class="math notranslate nohighlight">\(\phi\)</span> , <em>i.e.</em> <code class="xref py py-meth docutils literal notranslate"><span class="pre">message()</span></code>, and <span class="math notranslate nohighlight">\(\gamma\)</span> , <em>.i.e.</em> <code class="xref py py-meth docutils literal notranslate"><span class="pre">update()</span></code>, as well as the aggregation scheme to use, <em>.i.e.</em> <code class="xref py py-obj docutils literal notranslate"><span class="pre">aggr='add'</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">aggr='mean'</span></code> or <code class="xref py py-obj docutils literal notranslate"><span class="pre">aggr='max'</span></code>.</p>
<p>This is done with the help of the following methods:</p>
<ul class="simple">
<li><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">torch_geometric.nn.MessagePassing(aggr=&quot;add&quot;,</span> <span class="pre">flow=&quot;source_to_target&quot;)</span></code>: Defines the aggregation scheme to use (<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;add&quot;</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;mean&quot;</span></code> or <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;max&quot;</span></code>) and the flow direction of message passing (either <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;source_to_target&quot;</span></code> or <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;target_to_source&quot;</span></code>).</p></li>
<li><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">torch_geometric.nn.MessagePassing.propagate(edge_index,</span> <span class="pre">size=None,</span> <span class="pre">dim=0,</span> <span class="pre">**kwargs)</span></code>:
The initial call to start propagating messages.
Takes in the edge indices and all additional data which is needed to construct messages and to update node embeddings.
Note that <code class="xref py py-meth docutils literal notranslate"><span class="pre">propagate()</span></code> is not limited to exchange messages in symmetric adjacency matrices of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">[N,</span> <span class="pre">N]</span></code> only, but can also exchange messages in general sparse assignment matrices, <em>.e.g.</em>, bipartite graphs, of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">[N,</span> <span class="pre">M]</span></code> by passing <code class="xref py py-obj docutils literal notranslate"><span class="pre">size=(N,</span> <span class="pre">M)</span></code> as an additional argument.
If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>, the assignment matrix is assumed to be symmetric.
For bipartite graphs with two independent sets of nodes and indices, and each set holding its own information, this split can be marked by passing the information as a tuple, <em>e.g.</em> <code class="xref py py-obj docutils literal notranslate"><span class="pre">x=(x_N,</span> <span class="pre">x_M)</span></code>.
Furthermore, the <code class="xref py py-obj docutils literal notranslate"><span class="pre">dim</span></code> attribute indicates along which axis to propagate.</p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch_geometric.nn.MessagePassing.message()</span></code>: Constructs messages to node <span class="math notranslate nohighlight">\(i\)</span> in analogy to <span class="math notranslate nohighlight">\(\phi\)</span> for each edge in <span class="math notranslate nohighlight">\((j,i) \in \mathcal{E}\)</span> if <code class="xref py py-obj docutils literal notranslate"><span class="pre">flow=&quot;source_to_target&quot;</span></code> and <span class="math notranslate nohighlight">\((i,j) \in \mathcal{E}\)</span> if <code class="xref py py-obj docutils literal notranslate"><span class="pre">flow=&quot;target_to_source&quot;</span></code>.
Can take any argument which was initially passed to <code class="xref py py-meth docutils literal notranslate"><span class="pre">propagate()</span></code>.
In addition, tensors passed to <code class="xref py py-meth docutils literal notranslate"><span class="pre">propagate()</span></code> can be mapped to the respective nodes <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span> by appending <code class="xref py py-obj docutils literal notranslate"><span class="pre">_i</span></code> or <code class="xref py py-obj docutils literal notranslate"><span class="pre">_j</span></code> to the variable name, <em>.e.g.</em> <code class="xref py py-obj docutils literal notranslate"><span class="pre">x_i</span></code> and <code class="xref py py-obj docutils literal notranslate"><span class="pre">x_j</span></code>.</p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch_geometric.nn.MessagePassing.update()</span></code>: Updates node embeddings in analogy to <span class="math notranslate nohighlight">\(\gamma\)</span> for each node <span class="math notranslate nohighlight">\(i \in \mathcal{V}\)</span>.
Takes in the output of aggregation as first argument and any argument which was initially passed to <code class="xref py py-meth docutils literal notranslate"><span class="pre">propagate()</span></code>.</p></li>
</ul>
<p>Let us verify this by re-implementing two popular GNN variants, the <a class="reference external" href="https://arxiv.org/abs/1609.02907">GCN layer from Kipf and Welling</a> and the <a class="reference external" href="https://arxiv.org/abs/1801.07829">EdgeConv layer from Wang et al.</a>.</p>
</div>
<div class="section" id="gcn">
<h2><a class="toc-backref" href="#id4">GCN层实现</a><a class="headerlink" href="#gcn" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="https://arxiv.org/abs/1609.02907">GCN layer</a> 在数学上定义为</p>
<div class="math notranslate nohighlight">
\[\mathbf{x}_i^{(k)} = \sum_{j \in \mathcal{N}(i) \cup \{ i \}} \frac{1}{\sqrt{\deg(i)} \cdot \sqrt{deg(j)}} \cdot \left( \mathbf{\Theta} \cdot \mathbf{x}_j^{(k-1)} \right),\]</div>
<p>where neighboring node features are first transformed by a weight matrix <span class="math notranslate nohighlight">\(\mathbf{\Theta}\)</span>, normalized by their degree, and finally summed up.
该公式可以分为以下步骤：</p>
<ol class="arabic simple">
<li><p>Add self-loops to the adjacency matrix.</p></li>
<li><p>Linearly transform node feature matrix.</p></li>
<li><p>Compute normalization coefficients.</p></li>
<li><p>Normalize node features in <span class="math notranslate nohighlight">\(\phi\)</span>.</p></li>
<li><p>Sum up neighboring node features (<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;add&quot;</span></code> aggregation).</p></li>
<li><p>Return new node embeddings in <span class="math notranslate nohighlight">\(\gamma\)</span>.</p></li>
</ol>
<p>通常在消息传递发生之前计算步骤1-3。使用 <code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.MessagePassing</span></code> 基类可以轻松地执行步骤4-6。完整的层实现如下所示：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">MessagePassing</span>
<span class="kn">from</span> <span class="nn">torch_geometric.utils</span> <span class="kn">import</span> <span class="n">add_self_loops</span><span class="p">,</span> <span class="n">degree</span>

<span class="k">class</span> <span class="nc">GCNConv</span><span class="p">(</span><span class="n">MessagePassing</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GCNConv</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">aggr</span><span class="o">=</span><span class="s1">&#39;add&#39;</span><span class="p">)</span>  <span class="c1"># &quot;Add&quot; aggregation.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">):</span>
        <span class="c1"># x has shape [N, in_channels]</span>
        <span class="c1"># edge_index has shape [2, E]</span>

        <span class="c1"># Step 1: Add self-loops to the adjacency matrix.</span>
        <span class="n">edge_index</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">add_self_loops</span><span class="p">(</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">num_nodes</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>

        <span class="c1"># Step 2: Linearly transform node feature matrix.</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># Step 3: Compute normalization</span>
        <span class="n">row</span><span class="p">,</span> <span class="n">col</span> <span class="o">=</span> <span class="n">edge_index</span>
        <span class="n">deg</span> <span class="o">=</span> <span class="n">degree</span><span class="p">(</span><span class="n">row</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">deg_inv_sqrt</span> <span class="o">=</span> <span class="n">deg</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="n">norm</span> <span class="o">=</span> <span class="n">deg_inv_sqrt</span><span class="p">[</span><span class="n">row</span><span class="p">]</span> <span class="o">*</span> <span class="n">deg_inv_sqrt</span><span class="p">[</span><span class="n">col</span><span class="p">]</span>

        <span class="c1"># Step 4-6: Start propagating messages.</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">propagate</span><span class="p">(</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)),</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
                              <span class="n">norm</span><span class="o">=</span><span class="n">norm</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">message</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_j</span><span class="p">,</span> <span class="n">norm</span><span class="p">):</span>
        <span class="c1"># x_j has shape [E, out_channels]</span>

        <span class="c1"># Step 4: Normalize node features.</span>
        <span class="k">return</span> <span class="n">norm</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">x_j</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">aggr_out</span><span class="p">):</span>
        <span class="c1"># aggr_out has shape [N, out_channels]</span>

        <span class="c1"># Step 6: Return new node embeddings.</span>
        <span class="k">return</span> <span class="n">aggr_out</span>
</pre></div>
</div>
<p><code class="xref py py-class docutils literal notranslate"><span class="pre">GCNConv</span></code> inherits from <code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.MessagePassing</span></code> with <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;add&quot;</span></code> propagation.
All the logic of the layer takes place in <code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code>.
Here, we first add self-loops to our edge indices using the <a class="reference internal" href="../modules/utils.html#torch_geometric.utils.add_self_loops" title="torch_geometric.utils.add_self_loops"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch_geometric.utils.add_self_loops()</span></code></a> function (step 1), as well as linearly transform node features by calling the <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.Linear</span></code> instance (step 2).</p>
<p>We then proceed to call <code class="xref py py-meth docutils literal notranslate"><span class="pre">propagate()</span></code>, which internally calls the <code class="xref py py-meth docutils literal notranslate"><span class="pre">message()</span></code> and <code class="xref py py-meth docutils literal notranslate"><span class="pre">update()</span></code> functions.
As additional arguments for message propagation, we pass the node embeddings <code class="xref py py-obj docutils literal notranslate"><span class="pre">x</span></code>.</p>
<p>In the <code class="xref py py-meth docutils literal notranslate"><span class="pre">message()</span></code> function, we need to normalize the neighboring node features <code class="xref py py-obj docutils literal notranslate"><span class="pre">x_j</span></code>.
Here, <code class="xref py py-obj docutils literal notranslate"><span class="pre">x_j</span></code> denotes a <em>mapped</em> tensor, which contains the neighboring node features of each edge.
Node features can be automatically mapped by appending <code class="xref py py-obj docutils literal notranslate"><span class="pre">_i</span></code> or <code class="xref py py-obj docutils literal notranslate"><span class="pre">_j</span></code> to the variable name.
In fact, any tensor can be mapped this way, as long as they have <span class="math notranslate nohighlight">\(N\)</span> entries in its first dimension.</p>
<p>The neighboring node features are normalized by computing node degrees <span class="math notranslate nohighlight">\(\deg(i)\)</span> for each node <span class="math notranslate nohighlight">\(i\)</span> and saving <span class="math notranslate nohighlight">\(1/(\sqrt{\deg(i)} \cdot \sqrt{\deg(j)})\)</span> in <code class="xref py py-obj docutils literal notranslate"><span class="pre">norm</span></code> for each edge <span class="math notranslate nohighlight">\((i,j) \in \mathcal{E}\)</span>.</p>
<p>In the <code class="xref py py-meth docutils literal notranslate"><span class="pre">update()</span></code> function, we simply return the output of the aggregation.</p>
<p>这就是创建简单的消息传递层所需的全部。您可以将此层用作深度架构的组件。初始化和调用很简单：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">conv</span> <span class="o">=</span> <span class="n">GCNConv</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="id2">
<h2><a class="toc-backref" href="#id5">边卷积层的实现</a><a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="https://arxiv.org/abs/1801.07829">edge convolutional layer</a> 用于处理图或点云，数学上定义为</p>
<div class="math notranslate nohighlight">
\[\mathbf{x}_i^{(k)} = \max_{j \in \mathcal{N}(i)} h_{\mathbf{\Theta}} \left( \mathbf{x}_i^{(k-1)}, \mathbf{x}_j^{(k-1)} - \mathbf{x}_i^{(k-1)} \right),\]</div>
<p>其中 <span class="math notranslate nohighlight">\(h_{\mathbf{\Theta}}\)</span> 表示一个 MLP. 类似与 GCN layer, 我们也可以用 <code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.MessagePassing</span></code> class 来实现 Edge Convolution, this time using the <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;max&quot;</span></code> aggregation:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">Sequential</span> <span class="k">as</span> <span class="n">Seq</span><span class="p">,</span> <span class="n">Linear</span><span class="p">,</span> <span class="n">ReLU</span>
<span class="kn">from</span> <span class="nn">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">MessagePassing</span>

<span class="k">class</span> <span class="nc">EdgeConv</span><span class="p">(</span><span class="n">MessagePassing</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">EdgeConv</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">aggr</span><span class="o">=</span><span class="s1">&#39;max&#39;</span><span class="p">)</span> <span class="c1">#  &quot;Max&quot; aggregation.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">Seq</span><span class="p">(</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">),</span>
                       <span class="n">ReLU</span><span class="p">(),</span>
                       <span class="n">Linear</span><span class="p">(</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">):</span>
        <span class="c1"># x has shape [N, in_channels]</span>
        <span class="c1"># edge_index has shape [2, E]</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">propagate</span><span class="p">(</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)),</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">message</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_i</span><span class="p">,</span> <span class="n">x_j</span><span class="p">):</span>
        <span class="c1"># x_i has shape [E, in_channels]</span>
        <span class="c1"># x_j has shape [E, in_channels]</span>

        <span class="n">tmp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">x_i</span><span class="p">,</span> <span class="n">x_j</span> <span class="o">-</span> <span class="n">x_i</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># tmp has shape [E, 2 * in_channels]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">(</span><span class="n">tmp</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">aggr_out</span><span class="p">):</span>
        <span class="c1"># aggr_out has shape [N, out_channels]</span>

        <span class="k">return</span> <span class="n">aggr_out</span>
</pre></div>
</div>
<p>Inside the <code class="xref py py-meth docutils literal notranslate"><span class="pre">message()</span></code> function, we use <code class="xref py py-obj docutils literal notranslate"><span class="pre">self.mlp</span></code> to transform both the target node features <code class="xref py py-obj docutils literal notranslate"><span class="pre">x_i</span></code> and the relative source node features <code class="xref py py-obj docutils literal notranslate"><span class="pre">x_j</span> <span class="pre">-</span> <span class="pre">x_i</span></code> for each edge <span class="math notranslate nohighlight">\((j,i) \in \mathcal{E}\)</span>.</p>
<p>边卷积实际上是一种动态卷积，它使用特征空间中的最近邻居重新计算每一层的图。幸运的是，PyTorch Geometric comes with a GPU accelerated batch-wise k-NN graph generation method named <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch_geometric.nn.knn_graph()</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">knn_graph</span>

<span class="k">class</span> <span class="nc">DynamicEdgeConv</span><span class="p">(</span><span class="n">EdgeConv</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">6</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DynamicEdgeConv</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="n">edge_index</span> <span class="o">=</span> <span class="n">knn_graph</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">loop</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">flow</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">flow</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">DynamicEdgeConv</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
</pre></div>
</div>
<p>Here, <code class="xref py py-meth docutils literal notranslate"><span class="pre">knn_graph()</span></code> computes a nearest neighbor graph, which is further used to call the <code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code> method of <code class="xref py py-class docutils literal notranslate"><span class="pre">EdgeConv</span></code>.</p>
<p>这为我们提供了一个干净的接口，用于初始化和调用此层：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">conv</span> <span class="o">=</span> <span class="n">DynamicEdgeConv</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="create_dataset.html" class="btn btn-neutral float-right" title="构建数据集" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="introduction.html" class="btn btn-neutral float-left" title="PyG中基本概念" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Matthias Fey

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>