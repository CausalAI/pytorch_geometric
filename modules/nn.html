

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torch_geometric.nn &mdash; pytorch_geometric 1.4.3 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="torch_geometric.data" href="data.html" />
    <link rel="prev" title="torch_geometric" href="root.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html">
          

          
            
            <img src="../_static/pyg_logo_text.svg" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                1.4.3
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../notes/installation.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../notes/installation.html#c-cuda-extensions-on-macos">C++/CUDA Extensions on macOS</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notes/installation.html#id1">Frequently Asked Questions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../notes/introduction.html">Introduction by Example</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../notes/introduction.html#data-handling-of-graphs">Data Handling of Graphs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notes/introduction.html#common-benchmark-datasets">Common Benchmark Datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notes/introduction.html#mini-batches">Mini-batches</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notes/introduction.html#data-transforms">Data Transforms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notes/introduction.html#learning-methods-on-graphs">Learning Methods on Graphs</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../notes/create_gnn.html">Creating Message Passing Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../notes/create_gnn.html#the-messagepassing-base-class">The “MessagePassing” Base Class</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notes/create_gnn.html#implementing-the-gcn-layer">Implementing the GCN Layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notes/create_gnn.html#implementing-the-edge-convolution">Implementing the Edge Convolution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../notes/create_dataset.html">Creating Your Own Datasets</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../notes/create_dataset.html#creating-in-memory-datasets">Creating “In Memory Datasets”</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notes/create_dataset.html#creating-larger-datasets">Creating “Larger” Datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notes/create_dataset.html#frequently-asked-questions">Frequently Asked Questions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../notes/batching.html">Advanced Mini-Batching</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../notes/batching.html#pairs-of-graphs">Pairs of Graphs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notes/batching.html#bipartite-graphs">Bipartite Graphs</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../notes/resources.html">External Resources</a></li>
</ul>
<p class="caption"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../examples/01-quick_survey.html">PyG 的快速调研</a></li>
</ul>
<p class="caption"><span class="caption-text">Package Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="root.html">torch_geometric</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">torch_geometric.nn</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#module-torch_geometric.nn.conv.message_passing">Convolutional Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-torch_geometric.nn.dense.dense_gcn_conv">Dense Convolutional Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-torch_geometric.nn.norm">Normalization Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-torch_geometric.nn.glob">Global Pooling Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-torch_geometric.nn.pool">Pooling Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-torch_geometric.nn.dense.diff_pool">Dense Pooling Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-torch_geometric.nn.unpool">Unpooling Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-torch_geometric.nn.models">Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-torch_geometric.nn.data_parallel">DataParallel Layers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="data.html">torch_geometric.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="datasets.html">torch_geometric.datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="transforms.html">torch_geometric.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">torch_geometric.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="io.html">torch_geometric.io</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">pytorch_geometric</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>torch_geometric.nn</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/modules/nn.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="torch-geometric-nn">
<h1>torch_geometric.nn<a class="headerlink" href="#torch-geometric-nn" title="Permalink to this headline">¶</a></h1>
<div class="contents local topic" id="contents">
<p class="topic-title first">Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#module-torch_geometric.nn.conv.message_passing" id="id11">Convolutional Layers</a></p></li>
<li><p><a class="reference internal" href="#module-torch_geometric.nn.dense.dense_gcn_conv" id="id12">Dense Convolutional Layers</a></p></li>
<li><p><a class="reference internal" href="#module-torch_geometric.nn.norm" id="id13">Normalization Layers</a></p></li>
<li><p><a class="reference internal" href="#module-torch_geometric.nn.glob" id="id14">Global Pooling Layers</a></p></li>
<li><p><a class="reference internal" href="#module-torch_geometric.nn.pool" id="id15">Pooling Layers</a></p></li>
<li><p><a class="reference internal" href="#module-torch_geometric.nn.dense.diff_pool" id="id16">Dense Pooling Layers</a></p></li>
<li><p><a class="reference internal" href="#module-torch_geometric.nn.unpool" id="id17">Unpooling Layers</a></p></li>
<li><p><a class="reference internal" href="#module-torch_geometric.nn.models" id="id18">Models</a></p></li>
<li><p><a class="reference internal" href="#module-torch_geometric.nn.data_parallel" id="id19">DataParallel Layers</a></p></li>
</ul>
</div>
<div class="section" id="module-torch_geometric.nn.conv.message_passing">
<span id="convolutional-layers"></span><h2><a class="toc-backref" href="#id11">Convolutional Layers</a><a class="headerlink" href="#module-torch_geometric.nn.conv.message_passing" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch_geometric.nn.conv.message_passing.MessagePassing">
<em class="property">class </em><code class="sig-name descname">MessagePassing</code><span class="sig-paren">(</span><em class="sig-param">aggr='add'</em>, <em class="sig-param">flow='source_to_target'</em>, <em class="sig-param">node_dim=0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/message_passing.html#MessagePassing"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.message_passing.MessagePassing" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class for creating message passing layers of the form</p>
<div class="math notranslate nohighlight">
\[\mathbf{x}_i^{\prime} = \gamma_{\mathbf{\Theta}} \left( \mathbf{x}_i,
\square_{j \in \mathcal{N}(i)} \, \phi_{\mathbf{\Theta}}
\left(\mathbf{x}_i, \mathbf{x}_j,\mathbf{e}_{i,j}\right) \right),\]</div>
<p>where <span class="math notranslate nohighlight">\(\square\)</span> denotes a differentiable, permutation invariant
function, <em>e.g.</em>, sum, mean or max, and <span class="math notranslate nohighlight">\(\gamma_{\mathbf{\Theta}}\)</span>
and <span class="math notranslate nohighlight">\(\phi_{\mathbf{\Theta}}\)</span> denote differentiable functions such as
MLPs.
See <a class="reference external" href="https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html">here</a> for the accompanying tutorial.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>aggr</strong> (<em>string</em><em>, </em><em>optional</em>) – The aggregation scheme to use
(<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;add&quot;</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;mean&quot;</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;max&quot;</span></code> or <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>).
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;add&quot;</span></code>)</p></li>
<li><p><strong>flow</strong> (<em>string</em><em>, </em><em>optional</em>) – The flow direction of message passing
(<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;source_to_target&quot;</span></code> or <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;target_to_source&quot;</span></code>).
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;source_to_target&quot;</span></code>)</p></li>
<li><p><strong>node_dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – The axis along which to propagate.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">0</span></code>)</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.conv.message_passing.MessagePassing.aggregate">
<code class="sig-name descname">aggregate</code><span class="sig-paren">(</span><em class="sig-param">inputs</em>, <em class="sig-param">index</em>, <em class="sig-param">ptr=None</em>, <em class="sig-param">dim_size=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/message_passing.html#MessagePassing.aggregate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.message_passing.MessagePassing.aggregate" title="Permalink to this definition">¶</a></dt>
<dd><p>Aggregates messages from neighbors as
<span class="math notranslate nohighlight">\(\square_{j \in \mathcal{N}(i)}\)</span>.</p>
<p>Takes in the output of message computation as first argument and any
argument which was initially passed to <a class="reference internal" href="#torch_geometric.nn.conv.message_passing.MessagePassing.propagate" title="torch_geometric.nn.conv.message_passing.MessagePassing.propagate"><code class="xref py py-meth docutils literal notranslate"><span class="pre">propagate()</span></code></a>.</p>
<p>By default, this function will delegate its call to scatter functions
that support “add”, “mean” and “max” operations as specified in
<code class="xref py py-meth docutils literal notranslate"><span class="pre">__init__()</span></code> by the <code class="xref py py-obj docutils literal notranslate"><span class="pre">aggr</span></code> argument.</p>
</dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.conv.message_passing.MessagePassing.message">
<code class="sig-name descname">message</code><span class="sig-paren">(</span><em class="sig-param">x_j</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/message_passing.html#MessagePassing.message"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.message_passing.MessagePassing.message" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructs messages from node <span class="math notranslate nohighlight">\(j\)</span> to node <span class="math notranslate nohighlight">\(i\)</span>
in analogy to <span class="math notranslate nohighlight">\(\phi_{\mathbf{\Theta}}\)</span> for each edge in
<code class="xref py py-obj docutils literal notranslate"><span class="pre">edge_index</span></code>.
This function can take any argument as input which was initially
passed to <a class="reference internal" href="#torch_geometric.nn.conv.message_passing.MessagePassing.propagate" title="torch_geometric.nn.conv.message_passing.MessagePassing.propagate"><code class="xref py py-meth docutils literal notranslate"><span class="pre">propagate()</span></code></a>.
Furthermore, tensors passed to <a class="reference internal" href="#torch_geometric.nn.conv.message_passing.MessagePassing.propagate" title="torch_geometric.nn.conv.message_passing.MessagePassing.propagate"><code class="xref py py-meth docutils literal notranslate"><span class="pre">propagate()</span></code></a> can be mapped to the
respective nodes <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span> by appending <code class="xref py py-obj docutils literal notranslate"><span class="pre">_i</span></code> or
<code class="xref py py-obj docutils literal notranslate"><span class="pre">_j</span></code> to the variable name, <em>.e.g.</em> <code class="xref py py-obj docutils literal notranslate"><span class="pre">x_i</span></code> and <code class="xref py py-obj docutils literal notranslate"><span class="pre">x_j</span></code>.</p>
</dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.conv.message_passing.MessagePassing.message_and_aggregate">
<code class="sig-name descname">message_and_aggregate</code><span class="sig-paren">(</span><em class="sig-param">adj_t</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/message_passing.html#MessagePassing.message_and_aggregate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.message_passing.MessagePassing.message_and_aggregate" title="Permalink to this definition">¶</a></dt>
<dd><p>Fuses computations of <a class="reference internal" href="#torch_geometric.nn.conv.message_passing.MessagePassing.message" title="torch_geometric.nn.conv.message_passing.MessagePassing.message"><code class="xref py py-func docutils literal notranslate"><span class="pre">message()</span></code></a> and <a class="reference internal" href="#torch_geometric.nn.conv.message_passing.MessagePassing.aggregate" title="torch_geometric.nn.conv.message_passing.MessagePassing.aggregate"><code class="xref py py-func docutils literal notranslate"><span class="pre">aggregate()</span></code></a> into a
single function.
If applicable, this saves both time and memory since messages do not
explicitly need to be materialized.
This function will only gets called in case it is implemented and
propagation takes place based on a <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch_sparse.SparseTensor</span></code>.</p>
</dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.conv.message_passing.MessagePassing.propagate">
<code class="sig-name descname">propagate</code><span class="sig-paren">(</span><em class="sig-param">edge_index</em>, <em class="sig-param">size=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/message_passing.html#MessagePassing.propagate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.message_passing.MessagePassing.propagate" title="Permalink to this definition">¶</a></dt>
<dd><p>The initial call to start propagating messages.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>adj</strong> (<em>Tensor</em><em> or </em><em>SparseTensor</em>) – A <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code> or a
<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch_sparse.SparseTensor</span></code> that defines the underlying
message propagation.
<code class="xref py py-obj docutils literal notranslate"><span class="pre">edge_index</span></code> holds the indices of a general (sparse)
assignment matrix of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">[N,</span> <span class="pre">M]</span></code>.
If <code class="xref py py-obj docutils literal notranslate"><span class="pre">edge_index</span></code> is of type <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.LongTensor</span></code>, its
shape must be defined as <code class="xref py py-obj docutils literal notranslate"><span class="pre">[2,</span> <span class="pre">num_messages]</span></code>, where
messages from nodes in <code class="xref py py-obj docutils literal notranslate"><span class="pre">edge_index[0]</span></code> are sent to
nodes in <code class="xref py py-obj docutils literal notranslate"><span class="pre">edge_index[1]</span></code>
(in case <code class="xref py py-obj docutils literal notranslate"><span class="pre">flow=&quot;source_to_target&quot;</span></code>).
If <code class="xref py py-obj docutils literal notranslate"><span class="pre">edge_index</span></code> is of type
<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch_sparse.SparseTensor</span></code>, its sparse indices
<code class="xref py py-obj docutils literal notranslate"><span class="pre">(row,</span> <span class="pre">col)</span></code> should relate to <code class="xref py py-obj docutils literal notranslate"><span class="pre">row</span> <span class="pre">=</span> <span class="pre">edge_index[1]</span></code>
and <code class="xref py py-obj docutils literal notranslate"><span class="pre">col</span> <span class="pre">=</span> <span class="pre">edge_index[0]</span></code>.
Hence, the only difference between those formats is that we
need to input the <em>transposed</em> sparse adjacency matrix into
<a class="reference internal" href="#torch_geometric.nn.conv.message_passing.MessagePassing.propagate" title="torch_geometric.nn.conv.message_passing.MessagePassing.propagate"><code class="xref py py-func docutils literal notranslate"><span class="pre">propagate()</span></code></a>.</p></li>
<li><p><strong>size</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a><em>, </em><em>optional</em>) – The size <code class="xref py py-obj docutils literal notranslate"><span class="pre">[N,</span> <span class="pre">M]</span></code> of the
assignment matrix in case <code class="xref py py-obj docutils literal notranslate"><span class="pre">edge_index</span></code> is a
<code class="xref py py-obj docutils literal notranslate"><span class="pre">LongTensor</span></code>.
If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>, the size will be automatically inferred
and assumed to be quadratic.
This argument is ignored in case <code class="xref py py-obj docutils literal notranslate"><span class="pre">edge_index</span></code> is a
<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch_sparse.SparseTensor</span></code>. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>**kwargs</strong> – Any additional data which is needed to construct and
aggregate messages, and to update node embeddings.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.conv.message_passing.MessagePassing.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param">inputs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/message_passing.html#MessagePassing.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.message_passing.MessagePassing.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Updates node embeddings in analogy to
<span class="math notranslate nohighlight">\(\gamma_{\mathbf{\Theta}}\)</span> for each node
<span class="math notranslate nohighlight">\(i \in \mathcal{V}\)</span>.
Takes in the output of aggregation as first argument and any argument
which was initially passed to <a class="reference internal" href="#torch_geometric.nn.conv.message_passing.MessagePassing.propagate" title="torch_geometric.nn.conv.message_passing.MessagePassing.propagate"><code class="xref py py-meth docutils literal notranslate"><span class="pre">propagate()</span></code></a>.</p>
</dd></dl>

</dd></dl>

<span class="target" id="module-torch_geometric.nn.conv"></span><dl class="class">
<dt id="torch_geometric.nn.conv.GCNConv">
<em class="property">class </em><code class="sig-name descname">GCNConv</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">improved=False</em>, <em class="sig-param">cached=False</em>, <em class="sig-param">bias=True</em>, <em class="sig-param">normalize=True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/gcn_conv.html#GCNConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.GCNConv" title="Permalink to this definition">¶</a></dt>
<dd><p>The graph convolutional operator from the <a class="reference external" href="https://arxiv.org/abs/1609.02907">“Semi-supervised
Classification with Graph Convolutional Networks”</a> paper</p>
<div class="math notranslate nohighlight">
\[\mathbf{X}^{\prime} = \mathbf{\hat{D}}^{-1/2} \mathbf{\hat{A}}
\mathbf{\hat{D}}^{-1/2} \mathbf{X} \mathbf{\Theta},\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{\hat{A}} = \mathbf{A} + \mathbf{I}\)</span> denotes the
adjacency matrix with inserted self-loops and
<span class="math notranslate nohighlight">\(\hat{D}_{ii} = \sum_{j=0} \hat{A}_{ij}\)</span> its diagonal degree matrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each input sample.</p></li>
<li><p><strong>out_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each output sample.</p></li>
<li><p><strong>improved</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>, the layer computes
<span class="math notranslate nohighlight">\(\mathbf{\hat{A}}\)</span> as <span class="math notranslate nohighlight">\(\mathbf{A} + 2\mathbf{I}\)</span>.
(default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>)</p></li>
<li><p><strong>cached</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>, the layer will cache
the computation of <span class="math notranslate nohighlight">\(\mathbf{\hat{D}}^{-1/2} \mathbf{\hat{A}}
\mathbf{\hat{D}}^{-1/2}\)</span> on first execution, and will use the
cached version for further executions.
This parameter should only be set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a> in transductive
learning scenarios. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>)</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, the layer will not learn
an additive bias. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
<li><p><strong>normalize</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to add self-loops and apply
symmetric normalization. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Additional arguments of
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.MessagePassing</span></code>.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.conv.GCNConv.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">edge_index</em>, <em class="sig-param">edge_weight=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/gcn_conv.html#GCNConv.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.GCNConv.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.conv.GCNConv.norm">
<em class="property">static </em><code class="sig-name descname">norm</code><span class="sig-paren">(</span><em class="sig-param">edge_index</em>, <em class="sig-param">num_nodes</em>, <em class="sig-param">edge_weight=None</em>, <em class="sig-param">improved=False</em>, <em class="sig-param">dtype=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/gcn_conv.html#GCNConv.norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.GCNConv.norm" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.conv.GCNConv.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/gcn_conv.html#GCNConv.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.GCNConv.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.conv.ChebConv">
<em class="property">class </em><code class="sig-name descname">ChebConv</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">K</em>, <em class="sig-param">normalization='sym'</em>, <em class="sig-param">bias=True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/cheb_conv.html#ChebConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.ChebConv" title="Permalink to this definition">¶</a></dt>
<dd><p>The chebyshev spectral graph convolutional operator from the
<a class="reference external" href="https://arxiv.org/abs/1606.09375">“Convolutional Neural Networks on Graphs with Fast Localized Spectral
Filtering”</a> paper</p>
<div class="math notranslate nohighlight">
\[\mathbf{X}^{\prime} = \sum_{k=1}^{K} \mathbf{Z}^{(k)} \cdot
\mathbf{\Theta}^{(k)}\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{Z}^{(k)}\)</span> is computed recursively by</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{Z}^{(1)} &amp;= \mathbf{X}\\\mathbf{Z}^{(2)} &amp;= \mathbf{\hat{L}} \cdot \mathbf{X}\\\mathbf{Z}^{(k)} &amp;= 2 \cdot \mathbf{\hat{L}} \cdot
\mathbf{Z}^{(k-1)} - \mathbf{Z}^{(k-2)}\end{aligned}\end{align} \]</div>
<p>and <span class="math notranslate nohighlight">\(\mathbf{\hat{L}}\)</span> denotes the scaled and normalized Laplacian
<span class="math notranslate nohighlight">\(\frac{2\mathbf{L}}{\lambda_{\max}} - \mathbf{I}\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each input sample.</p></li>
<li><p><strong>out_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each output sample.</p></li>
<li><p><strong>K</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Chebyshev filter size <span class="math notranslate nohighlight">\(K\)</span>.</p></li>
<li><p><strong>normalization</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – <p>The normalization scheme for the graph
Laplacian (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;sym&quot;</span></code>):</p>
<p>1. <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>: No normalization
<span class="math notranslate nohighlight">\(\mathbf{L} = \mathbf{D} - \mathbf{A}\)</span></p>
<p>2. <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;sym&quot;</span></code>: Symmetric normalization
<span class="math notranslate nohighlight">\(\mathbf{L} = \mathbf{I} - \mathbf{D}^{-1/2} \mathbf{A}
\mathbf{D}^{-1/2}\)</span></p>
<p>3. <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;rw&quot;</span></code>: Random-walk normalization
<span class="math notranslate nohighlight">\(\mathbf{L} = \mathbf{I} - \mathbf{D}^{-1} \mathbf{A}\)</span></p>
<p>You need to pass <code class="xref py py-obj docutils literal notranslate"><span class="pre">lambda_max</span></code> to the <a class="reference internal" href="#torch_geometric.nn.conv.ChebConv.forward" title="torch_geometric.nn.conv.ChebConv.forward"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code></a> method of
this operator in case the normalization is non-symmetric.
<code class="xref py py-obj docutils literal notranslate"><span class="pre">lambda_max</span></code> should be a <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.Tensor</span></code> of size
<code class="xref py py-obj docutils literal notranslate"><span class="pre">[num_graphs]</span></code> in a mini-batch scenario and a scalar when
operating on single graphs.
You can pre-compute <code class="xref py py-obj docutils literal notranslate"><span class="pre">lambda_max</span></code> via the
<a class="reference internal" href="transforms.html#torch_geometric.transforms.LaplacianLambdaMax" title="torch_geometric.transforms.LaplacianLambdaMax"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.transforms.LaplacianLambdaMax</span></code></a> transform.</p>
</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, the layer will not learn
an additive bias. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Additional arguments of
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.MessagePassing</span></code>.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.conv.ChebConv.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">edge_index</em>, <em class="sig-param">edge_weight=None</em>, <em class="sig-param">batch=None</em>, <em class="sig-param">lambda_max=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/cheb_conv.html#ChebConv.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.ChebConv.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.conv.ChebConv.norm">
<em class="property">static </em><code class="sig-name descname">norm</code><span class="sig-paren">(</span><em class="sig-param">edge_index</em>, <em class="sig-param">num_nodes</em>, <em class="sig-param">edge_weight</em>, <em class="sig-param">normalization</em>, <em class="sig-param">lambda_max</em>, <em class="sig-param">dtype=None</em>, <em class="sig-param">batch=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/cheb_conv.html#ChebConv.norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.ChebConv.norm" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.conv.ChebConv.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/cheb_conv.html#ChebConv.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.ChebConv.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.conv.SAGEConv">
<em class="property">class </em><code class="sig-name descname">SAGEConv</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">normalize=False</em>, <em class="sig-param">concat=False</em>, <em class="sig-param">bias=True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/sage_conv.html#SAGEConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.SAGEConv" title="Permalink to this definition">¶</a></dt>
<dd><p>The GraphSAGE operator from the <a class="reference external" href="https://arxiv.org/abs/1706.02216">“Inductive Representation Learning on
Large Graphs”</a> paper</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{\hat{x}}_i &amp;= \mathbf{\Theta} \cdot
\mathrm{mean}_{j \in \mathcal{N(i) \cup \{ i \}}}(\mathbf{x}_j)\\\mathbf{x}^{\prime}_i &amp;= \frac{\mathbf{\hat{x}}_i}
{\| \mathbf{\hat{x}}_i \|_2}.\end{aligned}\end{align} \]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each input sample.</p></li>
<li><p><strong>out_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each output sample.</p></li>
<li><p><strong>normalize</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>, output features
will be <span class="math notranslate nohighlight">\(\ell_2\)</span>-normalized. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>)</p></li>
<li><p><strong>concat</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>, will concatenate
current node features with aggregated ones. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>)</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, the layer will not learn
an additive bias. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Additional arguments of
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.MessagePassing</span></code>.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.conv.SAGEConv.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">edge_index</em>, <em class="sig-param">edge_weight=None</em>, <em class="sig-param">size=None</em>, <em class="sig-param">res_n_id=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/sage_conv.html#SAGEConv.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.SAGEConv.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>res_n_id</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – Residual node indices coming from
<code class="xref py py-obj docutils literal notranslate"><span class="pre">DataFlow</span></code> generated by <code class="xref py py-obj docutils literal notranslate"><span class="pre">NeighborSampler</span></code> are used to
select central node features in <code class="xref py py-obj docutils literal notranslate"><span class="pre">x</span></code>.
Required if operating in a bipartite graph and <code class="xref py py-obj docutils literal notranslate"><span class="pre">concat</span></code> is
<a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.conv.SAGEConv.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/sage_conv.html#SAGEConv.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.SAGEConv.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.conv.GraphConv">
<em class="property">class </em><code class="sig-name descname">GraphConv</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">aggr='add'</em>, <em class="sig-param">bias=True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/graph_conv.html#GraphConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.GraphConv" title="Permalink to this definition">¶</a></dt>
<dd><p>The graph neural network operator from the <a class="reference external" href="https://arxiv.org/abs/1810.02244">“Weisfeiler and Leman Go
Neural: Higher-order Graph Neural Networks”</a> paper</p>
<div class="math notranslate nohighlight">
\[\mathbf{x}^{\prime}_i = \mathbf{\Theta}_1 \mathbf{x}_i +
\sum_{j \in \mathcal{N}(i)} \mathbf{\Theta}_2 \mathbf{x}_j.\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each input sample.</p></li>
<li><p><strong>out_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each output sample.</p></li>
<li><p><strong>aggr</strong> (<em>string</em><em>, </em><em>optional</em>) – The aggregation scheme to use
(<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;add&quot;</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;mean&quot;</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;max&quot;</span></code>).
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;add&quot;</span></code>)</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, the layer will not learn
an additive bias. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Additional arguments of
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.MessagePassing</span></code>.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.conv.GraphConv.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">edge_index</em>, <em class="sig-param">edge_weight=None</em>, <em class="sig-param">size=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/graph_conv.html#GraphConv.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.GraphConv.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.conv.GraphConv.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/graph_conv.html#GraphConv.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.GraphConv.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.conv.GatedGraphConv">
<em class="property">class </em><code class="sig-name descname">GatedGraphConv</code><span class="sig-paren">(</span><em class="sig-param">out_channels</em>, <em class="sig-param">num_layers</em>, <em class="sig-param">aggr='add'</em>, <em class="sig-param">bias=True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/gated_graph_conv.html#GatedGraphConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.GatedGraphConv" title="Permalink to this definition">¶</a></dt>
<dd><p>The gated graph convolution operator from the <a class="reference external" href="https://arxiv.org/abs/1511.05493">“Gated Graph Sequence
Neural Networks”</a> paper</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{h}_i^{(0)} &amp;= \mathbf{x}_i \, \Vert \, \mathbf{0}\\\mathbf{m}_i^{(l+1)} &amp;= \sum_{j \in \mathcal{N}(i)} \mathbf{\Theta}
\cdot \mathbf{h}_j^{(l)}\\\mathbf{h}_i^{(l+1)} &amp;= \textrm{GRU} (\mathbf{m}_i^{(l+1)},
\mathbf{h}_i^{(l)})\end{aligned}\end{align} \]</div>
<p>up to representation <span class="math notranslate nohighlight">\(\mathbf{h}_i^{(L)}\)</span>.
The number of input channels of <span class="math notranslate nohighlight">\(\mathbf{x}_i\)</span> needs to be less or
equal than <code class="xref py py-obj docutils literal notranslate"><span class="pre">out_channels</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>out_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each input sample.</p></li>
<li><p><strong>num_layers</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The sequence length <span class="math notranslate nohighlight">\(L\)</span>.</p></li>
<li><p><strong>aggr</strong> (<em>string</em><em>, </em><em>optional</em>) – The aggregation scheme to use
(<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;add&quot;</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;mean&quot;</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;max&quot;</span></code>).
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;add&quot;</span></code>)</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, the layer will not learn
an additive bias. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Additional arguments of
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.MessagePassing</span></code>.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.conv.GatedGraphConv.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">edge_index</em>, <em class="sig-param">edge_weight=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/gated_graph_conv.html#GatedGraphConv.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.GatedGraphConv.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.conv.GatedGraphConv.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/gated_graph_conv.html#GatedGraphConv.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.GatedGraphConv.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.conv.GATConv">
<em class="property">class </em><code class="sig-name descname">GATConv</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">heads=1</em>, <em class="sig-param">concat=True</em>, <em class="sig-param">negative_slope=0.2</em>, <em class="sig-param">dropout=0</em>, <em class="sig-param">bias=True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/gat_conv.html#GATConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.GATConv" title="Permalink to this definition">¶</a></dt>
<dd><p>The graph attentional operator from the <a class="reference external" href="https://arxiv.org/abs/1710.10903">“Graph Attention Networks”</a> paper</p>
<div class="math notranslate nohighlight">
\[\mathbf{x}^{\prime}_i = \alpha_{i,i}\mathbf{\Theta}\mathbf{x}_{i} +
\sum_{j \in \mathcal{N}(i)} \alpha_{i,j}\mathbf{\Theta}\mathbf{x}_{j},\]</div>
<p>where the attention coefficients <span class="math notranslate nohighlight">\(\alpha_{i,j}\)</span> are computed as</p>
<div class="math notranslate nohighlight">
\[\alpha_{i,j} =
\frac{
\exp\left(\mathrm{LeakyReLU}\left(\mathbf{a}^{\top}
[\mathbf{\Theta}\mathbf{x}_i \, \Vert \, \mathbf{\Theta}\mathbf{x}_j]
\right)\right)}
{\sum_{k \in \mathcal{N}(i) \cup \{ i \}}
\exp\left(\mathrm{LeakyReLU}\left(\mathbf{a}^{\top}
[\mathbf{\Theta}\mathbf{x}_i \, \Vert \, \mathbf{\Theta}\mathbf{x}_k]
\right)\right)}.\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each input sample.</p></li>
<li><p><strong>out_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each output sample.</p></li>
<li><p><strong>heads</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Number of multi-head-attentions.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">1</span></code>)</p></li>
<li><p><strong>concat</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, the multi-head
attentions are averaged instead of concatenated.
(default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
<li><p><strong>negative_slope</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – LeakyReLU angle of the negative
slope. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">0.2</span></code>)</p></li>
<li><p><strong>dropout</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Dropout probability of the normalized
attention coefficients which exposes each node to a stochastically
sampled neighborhood during training. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">0</span></code>)</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, the layer will not learn
an additive bias. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Additional arguments of
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.MessagePassing</span></code>.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.conv.GATConv.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">edge_index</em>, <em class="sig-param">size=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/gat_conv.html#GATConv.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.GATConv.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.conv.GATConv.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/gat_conv.html#GATConv.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.GATConv.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.conv.AGNNConv">
<em class="property">class </em><code class="sig-name descname">AGNNConv</code><span class="sig-paren">(</span><em class="sig-param">requires_grad=True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/agnn_conv.html#AGNNConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.AGNNConv" title="Permalink to this definition">¶</a></dt>
<dd><p>Graph attentional propagation layer from the
<a class="reference external" href="https://arxiv.org/abs/1803.03735">“Attention-based Graph Neural Network for Semi-Supervised Learning”</a> paper</p>
<div class="math notranslate nohighlight">
\[\mathbf{X}^{\prime} = \mathbf{P} \mathbf{X},\]</div>
<p>where the propagation matrix <span class="math notranslate nohighlight">\(\mathbf{P}\)</span> is computed as</p>
<div class="math notranslate nohighlight">
\[P_{i,j} = \frac{\exp( \beta \cdot \cos(\mathbf{x}_i, \mathbf{x}_j))}
{\sum_{k \in \mathcal{N}(i)\cup \{ i \}} \exp( \beta \cdot
\cos(\mathbf{x}_i, \mathbf{x}_k))}\]</div>
<p>with trainable parameter <span class="math notranslate nohighlight">\(\beta\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>requires_grad</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, <span class="math notranslate nohighlight">\(\beta\)</span>
will not be trainable. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Additional arguments of
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.MessagePassing</span></code>.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.conv.AGNNConv.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">edge_index</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/agnn_conv.html#AGNNConv.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.AGNNConv.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.conv.AGNNConv.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/agnn_conv.html#AGNNConv.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.AGNNConv.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.conv.TAGConv">
<em class="property">class </em><code class="sig-name descname">TAGConv</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">K=3</em>, <em class="sig-param">bias=True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/tag_conv.html#TAGConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.TAGConv" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>The topology adaptive graph convolutional networks operator from the</dt><dd><p><a class="reference external" href="https://arxiv.org/abs/1710.10370">“Topology Adaptive Graph Convolutional Networks”</a> paper</p>
</dd>
</dl>
<div class="math notranslate nohighlight">
\[\mathbf{X}^{\prime} = \sum_{k=0}^K \mathbf{D}^{-1/2} \mathbf{A}^k
\mathbf{D}^{-1/2}\mathbf{X} \mathbf{\Theta}_{k},\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> denotes the adjacency matrix and
<span class="math notranslate nohighlight">\(D_{ii} = \sum_{j=0} A_{ij}\)</span> its diagonal degree matrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each input sample.</p></li>
<li><p><strong>out_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each output sample.</p></li>
<li><p><strong>K</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Number of hops <span class="math notranslate nohighlight">\(K\)</span>. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">3</span></code>)</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, the layer will not learn
an additive bias. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Additional arguments of
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.MessagePassing</span></code>.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.conv.TAGConv.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">edge_index</em>, <em class="sig-param">edge_weight=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/tag_conv.html#TAGConv.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.TAGConv.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.conv.TAGConv.norm">
<em class="property">static </em><code class="sig-name descname">norm</code><span class="sig-paren">(</span><em class="sig-param">edge_index</em>, <em class="sig-param">num_nodes</em>, <em class="sig-param">edge_weight=None</em>, <em class="sig-param">dtype=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/tag_conv.html#TAGConv.norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.TAGConv.norm" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.conv.TAGConv.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/tag_conv.html#TAGConv.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.TAGConv.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.conv.GINConv">
<em class="property">class </em><code class="sig-name descname">GINConv</code><span class="sig-paren">(</span><em class="sig-param">nn</em>, <em class="sig-param">eps=0</em>, <em class="sig-param">train_eps=False</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/gin_conv.html#GINConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.GINConv" title="Permalink to this definition">¶</a></dt>
<dd><p>The graph isomorphism operator from the <a class="reference external" href="https://arxiv.org/abs/1810.00826">“How Powerful are
Graph Neural Networks?”</a> paper</p>
<div class="math notranslate nohighlight">
\[\mathbf{x}^{\prime}_i = h_{\mathbf{\Theta}} \left( (1 + \epsilon) \cdot
\mathbf{x}_i + \sum_{j \in \mathcal{N}(i)} \mathbf{x}_j \right),\]</div>
<p>here <span class="math notranslate nohighlight">\(h_{\mathbf{\Theta}}\)</span> denotes a neural network, <em>.i.e.</em> a MLP.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>nn</strong> (<em>torch.nn.Module</em>) – A neural network <span class="math notranslate nohighlight">\(h_{\mathbf{\Theta}}\)</span> that
maps node features <code class="xref py py-obj docutils literal notranslate"><span class="pre">x</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">[-1,</span> <span class="pre">in_channels]</span></code> to
shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">[-1,</span> <span class="pre">out_channels]</span></code>, <em>e.g.</em>, defined by
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.Sequential</span></code>.</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – (Initial) <span class="math notranslate nohighlight">\(\epsilon\)</span> value.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">0</span></code>)</p></li>
<li><p><strong>train_eps</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>, <span class="math notranslate nohighlight">\(\epsilon\)</span>
will be a trainable parameter. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>)</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Additional arguments of
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.MessagePassing</span></code>.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.conv.GINConv.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">edge_index</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/gin_conv.html#GINConv.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.GINConv.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.conv.GINConv.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/gin_conv.html#GINConv.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.GINConv.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.conv.ARMAConv">
<em class="property">class </em><code class="sig-name descname">ARMAConv</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">num_stacks=1</em>, <em class="sig-param">num_layers=1</em>, <em class="sig-param">shared_weights=False</em>, <em class="sig-param">act=&lt;function relu&gt;</em>, <em class="sig-param">dropout=0</em>, <em class="sig-param">bias=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/arma_conv.html#ARMAConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.ARMAConv" title="Permalink to this definition">¶</a></dt>
<dd><p>The ARMA graph convolutional operator from the <a class="reference external" href="https://arxiv.org/abs/1901.01343">“Graph Neural Networks
with Convolutional ARMA Filters”</a> paper</p>
<div class="math notranslate nohighlight">
\[\mathbf{X}^{\prime} = \frac{1}{K} \sum_{k=1}^K \mathbf{X}_k^{(T)},\]</div>
<p>with <span class="math notranslate nohighlight">\(\mathbf{X}_k^{(T)}\)</span> being recursively defined by</p>
<div class="math notranslate nohighlight">
\[\mathbf{X}_k^{(t+1)} = \sigma \left( \mathbf{\hat{L}}
\mathbf{X}_k^{(t)} \mathbf{W} + \mathbf{X}^{(0)} \mathbf{V} \right),\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{\hat{L}} = \mathbf{I} - \mathbf{L} = \mathbf{D}^{-1/2}
\mathbf{A} \mathbf{D}^{-1/2}\)</span> denotes the
modified Laplacian <span class="math notranslate nohighlight">\(\mathbf{L} = \mathbf{I} - \mathbf{D}^{-1/2}
\mathbf{A} \mathbf{D}^{-1/2}\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each input sample <span class="math notranslate nohighlight">\(\mathbf{x}^{(t)}\)</span>.</p></li>
<li><p><strong>out_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each output sample
<span class="math notranslate nohighlight">\(\mathbf{x}^{(t+1)}\)</span>.</p></li>
<li><p><strong>num_stacks</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Number of parallel stacks <span class="math notranslate nohighlight">\(K\)</span>.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">1</span></code>).</p></li>
<li><p><strong>num_layers</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Number of layers <span class="math notranslate nohighlight">\(T\)</span>.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">1</span></code>)</p></li>
<li><p><strong>act</strong> (<em>callable</em><em>, </em><em>optional</em>) – Activation function <span class="math notranslate nohighlight">\(\sigma\)</span>.
(default: <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.functional.ReLU()</span></code>)</p></li>
<li><p><strong>shared_weights</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a> the layers in
each stack will share the same parameters. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>)</p></li>
<li><p><strong>dropout</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Dropout probability of the skip connection.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">0</span></code>)</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, the layer will not learn
an additive bias. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.conv.ARMAConv.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">edge_index</em>, <em class="sig-param">edge_weight=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/arma_conv.html#ARMAConv.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.ARMAConv.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.conv.ARMAConv.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/arma_conv.html#ARMAConv.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.ARMAConv.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.conv.SGConv">
<em class="property">class </em><code class="sig-name descname">SGConv</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">K=1</em>, <em class="sig-param">cached=False</em>, <em class="sig-param">bias=True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/sg_conv.html#SGConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.SGConv" title="Permalink to this definition">¶</a></dt>
<dd><p>The simple graph convolutional operator from the <a class="reference external" href="https://arxiv.org/abs/1902.07153">“Simplifying Graph
Convolutional Networks”</a> paper</p>
<div class="math notranslate nohighlight">
\[\mathbf{X}^{\prime} = {\left(\mathbf{\hat{D}}^{-1/2} \mathbf{\hat{A}}
\mathbf{\hat{D}}^{-1/2} \right)}^K \mathbf{X} \mathbf{\Theta},\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{\hat{A}} = \mathbf{A} + \mathbf{I}\)</span> denotes the
adjacency matrix with inserted self-loops and
<span class="math notranslate nohighlight">\(\hat{D}_{ii} = \sum_{j=0} \hat{A}_{ij}\)</span> its diagonal degree matrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each input sample.</p></li>
<li><p><strong>out_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each output sample.</p></li>
<li><p><strong>K</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Number of hops <span class="math notranslate nohighlight">\(K\)</span>. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">1</span></code>)</p></li>
<li><p><strong>cached</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>, the layer will cache
the computation of <span class="math notranslate nohighlight">\({\left(\mathbf{\hat{D}}^{-1/2}
\mathbf{\hat{A}} \mathbf{\hat{D}}^{-1/2} \right)}^K\)</span> on first
execution, and will use the cached version for further executions.
This parameter should only be set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a> in transductive
learning scenarios. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>)</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, the layer will not learn
an additive bias. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Additional arguments of
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.MessagePassing</span></code>.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.conv.SGConv.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">edge_index</em>, <em class="sig-param">edge_weight=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/sg_conv.html#SGConv.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.SGConv.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.conv.SGConv.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/sg_conv.html#SGConv.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.SGConv.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.conv.APPNP">
<em class="property">class </em><code class="sig-name descname">APPNP</code><span class="sig-paren">(</span><em class="sig-param">K</em>, <em class="sig-param">alpha</em>, <em class="sig-param">bias=True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/appnp.html#APPNP"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.APPNP" title="Permalink to this definition">¶</a></dt>
<dd><p>The approximate personalized propagation of neural predictions layer
from the <a class="reference external" href="https://arxiv.org/abs/1810.05997">“Predict then Propagate: Graph Neural Networks meet Personalized
PageRank”</a> paper</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{X}^{(0)} &amp;= \mathbf{X}\\\mathbf{X}^{(k)} &amp;= (1 - \alpha) \mathbf{\hat{D}}^{-1/2}
\mathbf{\hat{A}} \mathbf{\hat{D}}^{-1/2} \mathbf{X}^{(k-1)} + \alpha
\mathbf{X}^{(0)}\\\mathbf{X}^{\prime} &amp;= \mathbf{X}^{(K)},\end{aligned}\end{align} \]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{\hat{A}} = \mathbf{A} + \mathbf{I}\)</span> denotes the
adjacency matrix with inserted self-loops and
<span class="math notranslate nohighlight">\(\hat{D}_{ii} = \sum_{j=0} \hat{A}_{ij}\)</span> its diagonal degree matrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>K</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of iterations <span class="math notranslate nohighlight">\(K\)</span>.</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Teleport probability <span class="math notranslate nohighlight">\(\alpha\)</span>.</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, the layer will not learn
an additive bias. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Additional arguments of
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.MessagePassing</span></code>.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.conv.APPNP.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">edge_index</em>, <em class="sig-param">edge_weight=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/appnp.html#APPNP.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.APPNP.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.conv.RGCNConv">
<em class="property">class </em><code class="sig-name descname">RGCNConv</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">num_relations</em>, <em class="sig-param">num_bases</em>, <em class="sig-param">root_weight=True</em>, <em class="sig-param">bias=True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/rgcn_conv.html#RGCNConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.RGCNConv" title="Permalink to this definition">¶</a></dt>
<dd><p>The relational graph convolutional operator from the <a class="reference external" href="https://arxiv.org/abs/1703.06103">“Modeling
Relational Data with Graph Convolutional Networks”</a> paper</p>
<div class="math notranslate nohighlight">
\[\mathbf{x}^{\prime}_i = \mathbf{\Theta}_{\textrm{root}} \cdot
\mathbf{x}_i + \sum_{r \in \mathcal{R}} \sum_{j \in \mathcal{N}_r(i)}
\frac{1}{|\mathcal{N}_r(i)|} \mathbf{\Theta}_r \cdot \mathbf{x}_j,\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathcal{R}\)</span> denotes the set of relations, <em>i.e.</em> edge types.
Edge type needs to be a one-dimensional <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.long</span></code> tensor which
stores a relation identifier
<span class="math notranslate nohighlight">\(\in \{ 0, \ldots, |\mathcal{R}| - 1\}\)</span> for each edge.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each input sample.</p></li>
<li><p><strong>out_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each output sample.</p></li>
<li><p><strong>num_relations</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of relations.</p></li>
<li><p><strong>num_bases</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of bases used for basis-decomposition.</p></li>
<li><p><strong>root_weight</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, the layer will
not add transformed root node features to the output.
(default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, the layer will not learn
an additive bias. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Additional arguments of
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.MessagePassing</span></code>.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.conv.RGCNConv.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">edge_index</em>, <em class="sig-param">edge_type</em>, <em class="sig-param">edge_norm=None</em>, <em class="sig-param">size=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/rgcn_conv.html#RGCNConv.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.RGCNConv.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.conv.RGCNConv.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/rgcn_conv.html#RGCNConv.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.RGCNConv.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.conv.SignedConv">
<em class="property">class </em><code class="sig-name descname">SignedConv</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">first_aggr</em>, <em class="sig-param">bias=True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/signed_conv.html#SignedConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.SignedConv" title="Permalink to this definition">¶</a></dt>
<dd><p>The signed graph convolutional operator from the <a class="reference external" href="https://arxiv.org/abs/1808.06354">“Signed Graph
Convolutional Network”</a> paper</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{x}_v^{(\textrm{pos})} &amp;= \mathbf{\Theta}^{(\textrm{pos})}
\left[ \frac{1}{|\mathcal{N}^{+}(v)|} \sum_{w \in \mathcal{N}^{+}(v)}
\mathbf{x}_w , \mathbf{x}_v \right]\\\mathbf{x}_v^{(\textrm{neg})} &amp;= \mathbf{\Theta}^{(\textrm{neg})}
\left[ \frac{1}{|\mathcal{N}^{-}(v)|} \sum_{w \in \mathcal{N}^{-}(v)}
\mathbf{x}_w , \mathbf{x}_v \right]\end{aligned}\end{align} \]</div>
<p>if <code class="xref py py-obj docutils literal notranslate"><span class="pre">first_aggr</span></code> is set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>, and</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{x}_v^{(\textrm{pos})} &amp;= \mathbf{\Theta}^{(\textrm{pos})}
\left[ \frac{1}{|\mathcal{N}^{+}(v)|} \sum_{w \in \mathcal{N}^{+}(v)}
\mathbf{x}_w^{(\textrm{pos})}, \frac{1}{|\mathcal{N}^{-}(v)|}
\sum_{w \in \mathcal{N}^{-}(v)} \mathbf{x}_w^{(\textrm{neg})} ,
\mathbf{x}_v^{(\textrm{pos})} \right]\\\mathbf{x}_v^{(\textrm{neg})} &amp;= \mathbf{\Theta}^{(\textrm{pos})}
\left[ \frac{1}{|\mathcal{N}^{+}(v)|} \sum_{w \in \mathcal{N}^{+}(v)}
\mathbf{x}_w^{(\textrm{neg})}, \frac{1}{|\mathcal{N}^{-}(v)|}
\sum_{w \in \mathcal{N}^{-}(v)} \mathbf{x}_w^{(\textrm{pos})} ,
\mathbf{x}_v^{(\textrm{neg})} \right]\end{aligned}\end{align} \]</div>
<p>otherwise.
In case <code class="xref py py-obj docutils literal notranslate"><span class="pre">first_aggr</span></code> is <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, the layer expects <code class="xref py py-obj docutils literal notranslate"><span class="pre">x</span></code> to be
a tensor where <code class="xref py py-obj docutils literal notranslate"><span class="pre">x[:,</span> <span class="pre">:in_channels]</span></code> denotes the positive node features
<span class="math notranslate nohighlight">\(\mathbf{X}^{(\textrm{pos})}\)</span> and <code class="xref py py-obj docutils literal notranslate"><span class="pre">x[:,</span> <span class="pre">in_channels:]</span></code> denotes
the negative node features <span class="math notranslate nohighlight">\(\mathbf{X}^{(\textrm{neg})}\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each input sample.</p></li>
<li><p><strong>out_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each output sample.</p></li>
<li><p><strong>first_aggr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a>) – Denotes which aggregation formula to use.</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, the layer will not learn
an additive bias. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Additional arguments of
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.MessagePassing</span></code>.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.conv.SignedConv.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">pos_edge_index</em>, <em class="sig-param">neg_edge_index</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/signed_conv.html#SignedConv.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.SignedConv.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.conv.SignedConv.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/signed_conv.html#SignedConv.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.SignedConv.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.conv.DNAConv">
<em class="property">class </em><code class="sig-name descname">DNAConv</code><span class="sig-paren">(</span><em class="sig-param">channels</em>, <em class="sig-param">heads=1</em>, <em class="sig-param">groups=1</em>, <em class="sig-param">dropout=0</em>, <em class="sig-param">cached=False</em>, <em class="sig-param">bias=True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/dna_conv.html#DNAConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.DNAConv" title="Permalink to this definition">¶</a></dt>
<dd><p>The dynamic neighborhood aggregation operator from the <a class="reference external" href="https://arxiv.org/abs/1904.04849">“Just Jump:
Towards Dynamic Neighborhood Aggregation in Graph Neural Networks”</a> paper</p>
<div class="math notranslate nohighlight">
\[\mathbf{x}_v^{(t)} = h_{\mathbf{\Theta}}^{(t)} \left( \mathbf{x}_{v
\leftarrow v}^{(t)}, \left\{ \mathbf{x}_{v \leftarrow w}^{(t)} : w \in
\mathcal{N}(v) \right\} \right)\]</div>
<p>based on (multi-head) dot-product attention</p>
<div class="math notranslate nohighlight">
\[\mathbf{x}_{v \leftarrow w}^{(t)} = \textrm{Attention} \left(
\mathbf{x}^{(t-1)}_v \, \mathbf{\Theta}_Q^{(t)}, [\mathbf{x}_w^{(1)},
\ldots, \mathbf{x}_w^{(t-1)}] \, \mathbf{\Theta}_K^{(t)}, \,
[\mathbf{x}_w^{(1)}, \ldots, \mathbf{x}_w^{(t-1)}] \,
\mathbf{\Theta}_V^{(t)} \right)\]</div>
<p>with <span class="math notranslate nohighlight">\(\mathbf{\Theta}_Q^{(t)}, \mathbf{\Theta}_K^{(t)},
\mathbf{\Theta}_V^{(t)}\)</span> denoting (grouped) projection matrices for query,
key and value information, respectively.
<span class="math notranslate nohighlight">\(h^{(t)}_{\mathbf{\Theta}}\)</span> is implemented as a non-trainable
version of <a class="reference internal" href="#torch_geometric.nn.conv.GCNConv" title="torch_geometric.nn.conv.GCNConv"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.GCNConv</span></code></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In contrast to other layers, this operator expects node features as
shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">[num_nodes,</span> <span class="pre">num_layers,</span> <span class="pre">channels]</span></code>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each input/output sample.</p></li>
<li><p><strong>heads</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Number of multi-head-attentions.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">1</span></code>)</p></li>
<li><p><strong>groups</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Number of groups to use for all linear
projections. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">1</span></code>)</p></li>
<li><p><strong>dropout</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Dropout probability of attention
coefficients. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">0</span></code>)</p></li>
<li><p><strong>cached</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>, the layer will cache
the computation of <span class="math notranslate nohighlight">\(\mathbf{\hat{D}}^{-1/2} \mathbf{\hat{A}}
\mathbf{\hat{D}}^{-1/2}\)</span> on first execution, and will use the
cached version for further executions.
This parameter should only be set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a> in transductive
learning scenarios. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>)</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, the layer will not learn
an additive bias. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Additional arguments of
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.MessagePassing</span></code>.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.conv.DNAConv.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">edge_index</em>, <em class="sig-param">edge_weight=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/dna_conv.html#DNAConv.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.DNAConv.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.conv.DNAConv.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/dna_conv.html#DNAConv.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.DNAConv.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.conv.PointConv">
<em class="property">class </em><code class="sig-name descname">PointConv</code><span class="sig-paren">(</span><em class="sig-param">local_nn=None</em>, <em class="sig-param">global_nn=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/point_conv.html#PointConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.PointConv" title="Permalink to this definition">¶</a></dt>
<dd><p>The PointNet set layer from the <a class="reference external" href="https://arxiv.org/abs/1612.00593">“PointNet: Deep Learning on Point Sets
for 3D Classification and Segmentation”</a> and <a class="reference external" href="https://arxiv.org/abs/1706.02413">“PointNet++: Deep Hierarchical
Feature Learning on Point Sets in a Metric Space”</a> papers</p>
<div class="math notranslate nohighlight">
\[\mathbf{x}^{\prime}_i = \gamma_{\mathbf{\Theta}} \left( \max_{j \in
\mathcal{N}(i) \cup \{ i \}} h_{\mathbf{\Theta}} ( \mathbf{x}_j,
\mathbf{p}_j - \mathbf{p}_i) \right),\]</div>
<p>where <span class="math notranslate nohighlight">\(\gamma_{\mathbf{\Theta}}\)</span> and
<span class="math notranslate nohighlight">\(h_{\mathbf{\Theta}}\)</span> denote neural
networks, <em>.i.e.</em> MLPs, and <span class="math notranslate nohighlight">\(\mathbf{P} \in \mathbb{R}^{N \times D}\)</span>
defines the position of each point.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>local_nn</strong> (<em>torch.nn.Module</em><em>, </em><em>optional</em>) – A neural network
<span class="math notranslate nohighlight">\(h_{\mathbf{\Theta}}\)</span> that maps node features <code class="xref py py-obj docutils literal notranslate"><span class="pre">x</span></code> and
relative spatial coordinates <code class="xref py py-obj docutils literal notranslate"><span class="pre">pos_j</span> <span class="pre">-</span> <span class="pre">pos_i</span></code> of shape
<code class="xref py py-obj docutils literal notranslate"><span class="pre">[-1,</span> <span class="pre">in_channels</span> <span class="pre">+</span> <span class="pre">num_dimensions]</span></code> to shape
<code class="xref py py-obj docutils literal notranslate"><span class="pre">[-1,</span> <span class="pre">out_channels]</span></code>, <em>e.g.</em>, defined by
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.Sequential</span></code>. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>global_nn</strong> (<em>torch.nn.Module</em><em>, </em><em>optional</em>) – A neural network
<span class="math notranslate nohighlight">\(\gamma_{\mathbf{\Theta}}\)</span> that maps aggregated node features
of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">[-1,</span> <span class="pre">out_channels]</span></code> to shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">[-1,</span>
<span class="pre">final_out_channels]</span></code>, <em>e.g.</em>, defined by
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.Sequential</span></code>. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Additional arguments of
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.MessagePassing</span></code>.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.conv.PointConv.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">pos</em>, <em class="sig-param">edge_index</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/point_conv.html#PointConv.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.PointConv.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – The node feature matrix. Allowed to be <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>.</p></li>
<li><p><strong>pos</strong> (<em>Tensor</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – The node position matrix. Either given as
tensor for use in general message passing or as tuple for use
in message passing in bipartite graphs.</p></li>
<li><p><strong>edge_index</strong> (<em>LongTensor</em>) – The edge indices.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.conv.PointConv.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/point_conv.html#PointConv.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.PointConv.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.conv.GMMConv">
<em class="property">class </em><code class="sig-name descname">GMMConv</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">dim</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">separate_gaussians=False</em>, <em class="sig-param">aggr='mean'</em>, <em class="sig-param">root_weight=True</em>, <em class="sig-param">bias=True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/gmm_conv.html#GMMConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.GMMConv" title="Permalink to this definition">¶</a></dt>
<dd><p>The gaussian mixture model convolutional operator from the <a class="reference external" href="https://arxiv.org/abs/1611.08402">“Geometric
Deep Learning on Graphs and Manifolds using Mixture Model CNNs”</a> paper</p>
<div class="math notranslate nohighlight">
\[\mathbf{x}^{\prime}_i = \frac{1}{|\mathcal{N}(i)|}
\sum_{j \in \mathcal{N}(i)} \frac{1}{K} \sum_{k=1}^K
\mathbf{w}_k(\mathbf{e}_{i,j}) \odot \mathbf{\Theta}_k \mathbf{x}_j,\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[\mathbf{w}_k(\mathbf{e}) = \exp \left( -\frac{1}{2} {\left(
\mathbf{e} - \mathbf{\mu}_k \right)}^{\top} \Sigma_k^{-1}
\left( \mathbf{e} - \mathbf{\mu}_k \right) \right)\]</div>
<p>denotes a weighting function based on trainable mean vector
<span class="math notranslate nohighlight">\(\mathbf{\mu}_k\)</span> and diagonal covariance matrix
<span class="math notranslate nohighlight">\(\mathbf{\Sigma}_k\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each input sample.</p></li>
<li><p><strong>out_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each output sample.</p></li>
<li><p><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Pseudo-coordinate dimensionality.</p></li>
<li><p><strong>kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of kernels <span class="math notranslate nohighlight">\(K\)</span>.</p></li>
<li><p><strong>separate_gaussians</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>, will
learn separate GMMs for every pair of input and output channel,
inspired by traditional CNNs. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>)</p></li>
<li><p><strong>aggr</strong> (<em>string</em><em>, </em><em>optional</em>) – The aggregation operator to use
(<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;add&quot;</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;mean&quot;</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;max&quot;</span></code>).
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;mean&quot;</span></code>)</p></li>
<li><p><strong>root_weight</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, the layer will
not add transformed root node features to the output.
(default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, the layer will not learn
an additive bias. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Additional arguments of
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.MessagePassing</span></code>.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.conv.GMMConv.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">edge_index</em>, <em class="sig-param">pseudo</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/gmm_conv.html#GMMConv.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.GMMConv.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.conv.GMMConv.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/gmm_conv.html#GMMConv.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.GMMConv.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.conv.SplineConv">
<em class="property">class </em><code class="sig-name descname">SplineConv</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">dim</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">is_open_spline=True</em>, <em class="sig-param">degree=1</em>, <em class="sig-param">aggr='mean'</em>, <em class="sig-param">root_weight=True</em>, <em class="sig-param">bias=True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/spline_conv.html#SplineConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.SplineConv" title="Permalink to this definition">¶</a></dt>
<dd><p>The spline-based convolutional operator from the <a class="reference external" href="https://arxiv.org/abs/1711.08920">“SplineCNN: Fast
Geometric Deep Learning with Continuous B-Spline Kernels”</a> paper</p>
<div class="math notranslate nohighlight">
\[\mathbf{x}^{\prime}_i = \frac{1}{|\mathcal{N}(i)|} \sum_{j \in
\mathcal{N}(i)} \mathbf{x}_j \cdot
h_{\mathbf{\Theta}}(\mathbf{e}_{i,j}),\]</div>
<p>where <span class="math notranslate nohighlight">\(h_{\mathbf{\Theta}}\)</span> denotes a kernel function defined
over the weighted B-Spline tensor product basis.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Pseudo-coordinates must lay in the fixed interval <span class="math notranslate nohighlight">\([0, 1]\)</span> for
this method to work as intended.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each input sample.</p></li>
<li><p><strong>out_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each output sample.</p></li>
<li><p><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Pseudo-coordinate dimensionality.</p></li>
<li><p><strong>kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em> or </em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>]</em>) – Size of the convolving kernel.</p></li>
<li><p><strong>is_open_spline</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em> or </em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>]</em><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, the
operator will use a closed B-spline basis in this dimension.
(default <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
<li><p><strong>degree</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – B-spline basis degrees. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">1</span></code>)</p></li>
<li><p><strong>aggr</strong> (<em>string</em><em>, </em><em>optional</em>) – The aggregation operator to use
(<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;add&quot;</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;mean&quot;</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;max&quot;</span></code>).
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;mean&quot;</span></code>)</p></li>
<li><p><strong>root_weight</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, the layer will
not add transformed root node features to the output.
(default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, the layer will not learn
an additive bias. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Additional arguments of
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.MessagePassing</span></code>.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.conv.SplineConv.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">edge_index</em>, <em class="sig-param">pseudo</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/spline_conv.html#SplineConv.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.SplineConv.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.conv.SplineConv.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/spline_conv.html#SplineConv.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.SplineConv.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.conv.NNConv">
<em class="property">class </em><code class="sig-name descname">NNConv</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">nn</em>, <em class="sig-param">aggr='add'</em>, <em class="sig-param">root_weight=True</em>, <em class="sig-param">bias=True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/nn_conv.html#NNConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.NNConv" title="Permalink to this definition">¶</a></dt>
<dd><p>The continuous kernel-based convolutional operator from the
<a class="reference external" href="https://arxiv.org/abs/1704.01212">“Neural Message Passing for Quantum Chemistry”</a> paper.
This convolution is also known as the edge-conditioned convolution from the
<a class="reference external" href="https://arxiv.org/abs/1704.02901">“Dynamic Edge-Conditioned Filters in Convolutional Neural Networks on
Graphs”</a> paper (see
<a class="reference internal" href="#torch_geometric.nn.conv.ECConv" title="torch_geometric.nn.conv.ECConv"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.ECConv</span></code></a> for an alias):</p>
<div class="math notranslate nohighlight">
\[\mathbf{x}^{\prime}_i = \mathbf{\Theta} \mathbf{x}_i +
\sum_{j \in \mathcal{N}(i)} \mathbf{x}_j \cdot
h_{\mathbf{\Theta}}(\mathbf{e}_{i,j}),\]</div>
<p>where <span class="math notranslate nohighlight">\(h_{\mathbf{\Theta}}\)</span> denotes a neural network, <em>.i.e.</em>
a MLP.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each input sample.</p></li>
<li><p><strong>out_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each output sample.</p></li>
<li><p><strong>nn</strong> (<em>torch.nn.Module</em>) – A neural network <span class="math notranslate nohighlight">\(h_{\mathbf{\Theta}}\)</span> that
maps edge features <code class="xref py py-obj docutils literal notranslate"><span class="pre">edge_attr</span></code> of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">[-1,</span>
<span class="pre">num_edge_features]</span></code> to shape
<code class="xref py py-obj docutils literal notranslate"><span class="pre">[-1,</span> <span class="pre">in_channels</span> <span class="pre">*</span> <span class="pre">out_channels]</span></code>, <em>e.g.</em>, defined by
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.Sequential</span></code>.</p></li>
<li><p><strong>aggr</strong> (<em>string</em><em>, </em><em>optional</em>) – The aggregation scheme to use
(<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;add&quot;</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;mean&quot;</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;max&quot;</span></code>).
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;add&quot;</span></code>)</p></li>
<li><p><strong>root_weight</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, the layer will
not add the transformed root node features to the output.
(default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, the layer will not learn
an additive bias. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Additional arguments of
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.MessagePassing</span></code>.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.conv.NNConv.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">edge_index</em>, <em class="sig-param">edge_attr</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/nn_conv.html#NNConv.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.NNConv.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.conv.NNConv.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/nn_conv.html#NNConv.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.NNConv.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="attribute">
<dt id="torch_geometric.nn.conv.ECConv">
<code class="sig-name descname">ECConv</code><a class="headerlink" href="#torch_geometric.nn.conv.ECConv" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.nn_conv.NNConv</span></code></p>
</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.conv.CGConv">
<em class="property">class </em><code class="sig-name descname">CGConv</code><span class="sig-paren">(</span><em class="sig-param">channels</em>, <em class="sig-param">dim</em>, <em class="sig-param">aggr='add'</em>, <em class="sig-param">bias=True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/cg_conv.html#CGConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.CGConv" title="Permalink to this definition">¶</a></dt>
<dd><p>The crystal graph convolutional operator from the
<a class="reference external" href="https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.120.145301">“Crystal Graph Convolutional Neural Networks for an
Accurate and Interpretable Prediction of Material Properties”</a>
paper</p>
<div class="math notranslate nohighlight">
\[\mathbf{x}^{\prime}_i = \mathbf{x}_i + \sum_{j \in \mathcal{N}(i)}
\sigma \left( \mathbf{z}_{i,j} \mathbf{W}_f + \mathbf{b}_f \right)
\odot g \left( \mathbf{z}_{i,j} \mathbf{W}_s + \mathbf{b}_s  \right)\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{z}_{i,j} = [ \mathbf{x}_i, \mathbf{x}_j,
\mathbf{e}_{i,j} ]\)</span> denotes the concatenation of central node features,
neighboring node features and edge features.
In addition, <span class="math notranslate nohighlight">\(\sigma\)</span> and <span class="math notranslate nohighlight">\(g\)</span> denote the sigmoid and softplus
functions, respectively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each input sample.</p></li>
<li><p><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Edge feature dimensionality.</p></li>
<li><p><strong>aggr</strong> (<em>string</em><em>, </em><em>optional</em>) – The aggregation operator to use
(<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;add&quot;</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;mean&quot;</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;max&quot;</span></code>).
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;add&quot;</span></code>)</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, the layer will not learn
an additive bias. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Additional arguments of
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.MessagePassing</span></code>.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.conv.CGConv.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">edge_index</em>, <em class="sig-param">edge_attr</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/cg_conv.html#CGConv.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.CGConv.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.conv.CGConv.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/cg_conv.html#CGConv.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.CGConv.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.conv.EdgeConv">
<em class="property">class </em><code class="sig-name descname">EdgeConv</code><span class="sig-paren">(</span><em class="sig-param">nn</em>, <em class="sig-param">aggr='max'</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/edge_conv.html#EdgeConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.EdgeConv" title="Permalink to this definition">¶</a></dt>
<dd><p>The edge convolutional operator from the <a class="reference external" href="https://arxiv.org/abs/1801.07829">“Dynamic Graph CNN for
Learning on Point Clouds”</a> paper</p>
<div class="math notranslate nohighlight">
\[\mathbf{x}^{\prime}_i = \sum_{j \in \mathcal{N}(i)}
h_{\mathbf{\Theta}}(\mathbf{x}_i \, \Vert \,
\mathbf{x}_j - \mathbf{x}_i),\]</div>
<p>where <span class="math notranslate nohighlight">\(h_{\mathbf{\Theta}}\)</span> denotes a neural network, <em>.i.e.</em> a MLP.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>nn</strong> (<em>torch.nn.Module</em>) – A neural network <span class="math notranslate nohighlight">\(h_{\mathbf{\Theta}}\)</span> that
maps pair-wise concatenated node features <code class="xref py py-obj docutils literal notranslate"><span class="pre">x</span></code> of shape
<code class="xref py py-obj docutils literal notranslate"><span class="pre">[-1,</span> <span class="pre">2</span> <span class="pre">*</span> <span class="pre">in_channels]</span></code> to shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">[-1,</span> <span class="pre">out_channels]</span></code>,
<em>e.g.</em>, defined by <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.Sequential</span></code>.</p></li>
<li><p><strong>aggr</strong> (<em>string</em><em>, </em><em>optional</em>) – The aggregation scheme to use
(<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;add&quot;</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;mean&quot;</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;max&quot;</span></code>).
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;max&quot;</span></code>)</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Additional arguments of
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.MessagePassing</span></code>.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.conv.EdgeConv.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">edge_index</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/edge_conv.html#EdgeConv.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.EdgeConv.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.conv.EdgeConv.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/edge_conv.html#EdgeConv.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.EdgeConv.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.conv.DynamicEdgeConv">
<em class="property">class </em><code class="sig-name descname">DynamicEdgeConv</code><span class="sig-paren">(</span><em class="sig-param">nn</em>, <em class="sig-param">k</em>, <em class="sig-param">aggr='max'</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/edge_conv.html#DynamicEdgeConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.DynamicEdgeConv" title="Permalink to this definition">¶</a></dt>
<dd><p>The dynamic edge convolutional operator from the <a class="reference external" href="https://arxiv.org/abs/1801.07829">“Dynamic Graph CNN
for Learning on Point Clouds”</a> paper
(see <a class="reference internal" href="#torch_geometric.nn.conv.EdgeConv" title="torch_geometric.nn.conv.EdgeConv"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.EdgeConv</span></code></a>), where the graph is
dynamically constructed using nearest neighbors in the feature space.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>nn</strong> (<em>torch.nn.Module</em>) – A neural network <span class="math notranslate nohighlight">\(h_{\mathbf{\Theta}}\)</span> that
maps pair-wise concatenated node features <code class="xref py py-obj docutils literal notranslate"><span class="pre">x</span></code> of shape
<cite>:obj:`[-1, 2 * in_channels]</cite> to shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">[-1,</span> <span class="pre">out_channels]</span></code>,
<em>e.g.</em> defined by <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.Sequential</span></code>.</p></li>
<li><p><strong>k</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of nearest neighbors.</p></li>
<li><p><strong>aggr</strong> (<em>string</em>) – The aggregation operator to use (<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;add&quot;</span></code>,
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;mean&quot;</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;max&quot;</span></code>). (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;max&quot;</span></code>)</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Additional arguments of
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.MessagePassing</span></code>.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.conv.DynamicEdgeConv.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">batch=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/edge_conv.html#DynamicEdgeConv.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.DynamicEdgeConv.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.conv.XConv">
<em class="property">class </em><code class="sig-name descname">XConv</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">dim</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">hidden_channels=None</em>, <em class="sig-param">dilation=1</em>, <em class="sig-param">bias=True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/x_conv.html#XConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.XConv" title="Permalink to this definition">¶</a></dt>
<dd><p>The convolutional operator on <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>-transformed points
from the <a class="reference external" href="https://arxiv.org/abs/1801.07791">“PointCNN: Convolution On X-Transformed Points”</a> paper</p>
<div class="math notranslate nohighlight">
\[\mathbf{x}^{\prime}_i = \mathrm{Conv}\left(\mathbf{K},
\gamma_{\mathbf{\Theta}}(\mathbf{P}_i - \mathbf{p}_i) \times
\left( h_\mathbf{\Theta}(\mathbf{P}_i - \mathbf{p}_i) \, \Vert \,
\mathbf{x}_i \right) \right),\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{K}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{P}_i\)</span> denote the trainable
filter and neighboring point positions of <span class="math notranslate nohighlight">\(\mathbf{x}_i\)</span>,
respectively.
<span class="math notranslate nohighlight">\(\gamma_{\mathbf{\Theta}}\)</span> and <span class="math notranslate nohighlight">\(h_{\mathbf{\Theta}}\)</span> describe
neural networks, <em>i.e.</em> MLPs, where <span class="math notranslate nohighlight">\(h_{\mathbf{\Theta}}\)</span>
individually lifts each point into a higher-dimensional space, and
<span class="math notranslate nohighlight">\(\gamma_{\mathbf{\Theta}}\)</span> computes the <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>-
transformation matrix based on <em>all</em> points in a neighborhood.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each input sample.</p></li>
<li><p><strong>out_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each output sample.</p></li>
<li><p><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Point cloud dimensionality.</p></li>
<li><p><strong>kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of the convolving kernel, <em>i.e.</em> number of
neighbors including self-loops.</p></li>
<li><p><strong>hidden_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Output size of
<span class="math notranslate nohighlight">\(h_{\mathbf{\Theta}}\)</span>, <em>i.e.</em> dimensionality of lifted
points. If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>, will be automatically set to
<code class="xref py py-obj docutils literal notranslate"><span class="pre">in_channels</span> <span class="pre">/</span> <span class="pre">4</span></code>. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – The factor by which the neighborhood is
extended, from which <code class="xref py py-obj docutils literal notranslate"><span class="pre">kernel_size</span></code> neighbors are then
uniformly sampled. Can be interpreted as the dilation rate of
classical convolutional operators. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">1</span></code>)</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, the layer will not learn
an additive bias. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Additional arguments of
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch_cluster.knn_graph</span></code>.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.conv.XConv.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">pos</em>, <em class="sig-param">batch=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/x_conv.html#XConv.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.XConv.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.conv.XConv.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/x_conv.html#XConv.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.XConv.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.conv.PPFConv">
<em class="property">class </em><code class="sig-name descname">PPFConv</code><span class="sig-paren">(</span><em class="sig-param">local_nn=None</em>, <em class="sig-param">global_nn=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/ppf_conv.html#PPFConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.PPFConv" title="Permalink to this definition">¶</a></dt>
<dd><p>The PPFNet operator from the <a class="reference external" href="https://arxiv.org/abs/1802.02669">“PPFNet: Global Context Aware Local
Features for Robust 3D Point Matching”</a>
paper</p>
<div class="math notranslate nohighlight">
\[\mathbf{x}^{\prime}_i = \gamma_{\mathbf{\Theta}} \left( \max_{j \in
\mathcal{N}(i) \cup \{ i \}} h_{\mathbf{\Theta}} ( \mathbf{x}_j, \|
\mathbf{d_{j,i}} \|, \angle(\mathbf{n}_i, \mathbf{d_{j,i}}),
\angle(\mathbf{n}_j, \mathbf{d_{j,i}}), \angle(\mathbf{n}_i,
\mathbf{n}_j) \right)\]</div>
<p>where <span class="math notranslate nohighlight">\(\gamma_{\mathbf{\Theta}}\)</span> and <span class="math notranslate nohighlight">\(h_{\mathbf{\Theta}}\)</span>
denote neural networks, <em>.i.e.</em> MLPs, which takes in node features and
<a class="reference internal" href="transforms.html#torch_geometric.transforms.PointPairFeatures" title="torch_geometric.transforms.PointPairFeatures"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.transforms.PointPairFeatures</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>local_nn</strong> (<em>torch.nn.Module</em><em>, </em><em>optional</em>) – A neural network
<span class="math notranslate nohighlight">\(h_{\mathbf{\Theta}}\)</span> that maps node features <code class="xref py py-obj docutils literal notranslate"><span class="pre">x</span></code> and
relative spatial coordinates <code class="xref py py-obj docutils literal notranslate"><span class="pre">pos_j</span> <span class="pre">-</span> <span class="pre">pos_i</span></code> of shape
<code class="xref py py-obj docutils literal notranslate"><span class="pre">[-1,</span> <span class="pre">in_channels</span> <span class="pre">+</span> <span class="pre">num_dimensions]</span></code> to shape
<code class="xref py py-obj docutils literal notranslate"><span class="pre">[-1,</span> <span class="pre">out_channels]</span></code>, <em>e.g.</em>, defined by
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.Sequential</span></code>. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>global_nn</strong> (<em>torch.nn.Module</em><em>, </em><em>optional</em>) – A neural network
<span class="math notranslate nohighlight">\(\gamma_{\mathbf{\Theta}}\)</span> that maps aggregated node features
of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">[-1,</span> <span class="pre">out_channels]</span></code> to shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">[-1,</span>
<span class="pre">final_out_channels]</span></code>, <em>e.g.</em>, defined by
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.Sequential</span></code>. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Additional arguments of
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.MessagePassing</span></code>.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.conv.PPFConv.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">pos</em>, <em class="sig-param">norm</em>, <em class="sig-param">edge_index</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/ppf_conv.html#PPFConv.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.PPFConv.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – The node feature matrix. Allowed to be <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>.</p></li>
<li><p><strong>pos</strong> (<em>Tensor</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – The node position matrix. Either given as
tensor for use in general message passing or as tuple for use
in message passing in bipartite graphs.</p></li>
<li><p><strong>norm</strong> (<em>Tensor</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – The normal vectors of each node. Either
given as tensor for use in general message passing or as tuple
for use in message passing in bipartite graphs.</p></li>
<li><p><strong>edge_index</strong> (<em>LongTensor</em>) – The edge indices.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.conv.PPFConv.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/ppf_conv.html#PPFConv.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.PPFConv.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.conv.FeaStConv">
<em class="property">class </em><code class="sig-name descname">FeaStConv</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">heads=1</em>, <em class="sig-param">bias=True</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/feast_conv.html#FeaStConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.FeaStConv" title="Permalink to this definition">¶</a></dt>
<dd><p>The (translation-invariant) feature-steered convolutional operator from
the <a class="reference external" href="https://arxiv.org/abs/1706.05206">“FeaStNet: Feature-Steered Graph Convolutions for 3D Shape Analysis”</a> paper</p>
<div class="math notranslate nohighlight">
\[\mathbf{x}^{\prime}_i = \frac{1}{|\mathcal{N}(i)|}
\sum_{j \in \mathcal{N}(i)} \sum_{h=1}^H
q_h(\mathbf{x}_i, \mathbf{x}_j) \mathbf{W}_h \mathbf{x}_j\]</div>
<p>with <span class="math notranslate nohighlight">\(q_h(\mathbf{x}_i, \mathbf{x}_j) = \mathrm{softmax}_j
(\mathbf{u}_h^{\top} (\mathbf{x}_j - \mathbf{x}_i) + c_h)\)</span>, where <span class="math notranslate nohighlight">\(H\)</span>
denotes the number of attention heads, and <span class="math notranslate nohighlight">\(\mathbf{W}_h\)</span>,
<span class="math notranslate nohighlight">\(\mathbf{u}_h\)</span> and <span class="math notranslate nohighlight">\(c_h\)</span> are trainable parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each input sample.</p></li>
<li><p><strong>out_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each output sample.</p></li>
<li><p><strong>heads</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Number of attention heads <span class="math notranslate nohighlight">\(H\)</span>.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">1</span></code>)</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, the layer will not learn
an additive bias. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Additional arguments of
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.MessagePassing</span></code>.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.conv.FeaStConv.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">edge_index</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/feast_conv.html#FeaStConv.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.FeaStConv.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.conv.FeaStConv.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/feast_conv.html#FeaStConv.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.FeaStConv.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.conv.HypergraphConv">
<em class="property">class </em><code class="sig-name descname">HypergraphConv</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">use_attention=False</em>, <em class="sig-param">heads=1</em>, <em class="sig-param">concat=True</em>, <em class="sig-param">negative_slope=0.2</em>, <em class="sig-param">dropout=0</em>, <em class="sig-param">bias=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/hypergraph_conv.html#HypergraphConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.HypergraphConv" title="Permalink to this definition">¶</a></dt>
<dd><p>The hypergraph convolutional operator from the <a class="reference external" href="https://arxiv.org/abs/1901.08150">“Hypergraph Convolution
and Hypergraph Attention”</a> paper</p>
<div class="math notranslate nohighlight">
\[\mathbf{X}^{\prime} = \mathbf{D}^{-1} \mathbf{H} \mathbf{W}
\mathbf{B}^{-1} \mathbf{H}^{\top} \mathbf{X} \mathbf{\Theta}\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{H} \in {\{ 0, 1 \}}^{N \times M}\)</span> is the incidence
matrix, <span class="math notranslate nohighlight">\(\mathbf{W}\)</span> is the diagonal hyperedge weight matrix, and
<span class="math notranslate nohighlight">\(\mathbf{D}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{B}\)</span> are the corresponding degree
matrices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each input sample.</p></li>
<li><p><strong>out_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each output sample.</p></li>
<li><p><strong>use_attention</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>, attention
will be added to this layer. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>)</p></li>
<li><p><strong>heads</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Number of multi-head-attentions.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">1</span></code>)</p></li>
<li><p><strong>concat</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, the multi-head
attentions are averaged instead of concatenated.
(default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
<li><p><strong>negative_slope</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – LeakyReLU angle of the negative
slope. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">0.2</span></code>)</p></li>
<li><p><strong>dropout</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Dropout probability of the normalized
attention coefficients which exposes each node to a stochastically
sampled neighborhood during training. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">0</span></code>)</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, the layer will not learn
an additive bias. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.conv.HypergraphConv.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">hyperedge_index</em>, <em class="sig-param">hyperedge_weight=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/hypergraph_conv.html#HypergraphConv.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.HypergraphConv.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Node feature matrix <span class="math notranslate nohighlight">\(\mathbf{X}\)</span></p></li>
<li><p><strong>hyper_edge_index</strong> (<em>LongTensor</em>) – Hyperedge indices from
<span class="math notranslate nohighlight">\(\mathbf{H}\)</span>.</p></li>
<li><p><strong>hyperedge_weight</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – Sparse hyperedge weights from
<span class="math notranslate nohighlight">\(\mathbf{W}\)</span>. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.conv.HypergraphConv.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/conv/hypergraph_conv.html#HypergraphConv.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.conv.HypergraphConv.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<span class="target" id="module-torch_geometric.nn.meta"></span><dl class="class">
<dt id="torch_geometric.nn.meta.MetaLayer">
<em class="property">class </em><code class="sig-name descname">MetaLayer</code><span class="sig-paren">(</span><em class="sig-param">edge_model=None</em>, <em class="sig-param">node_model=None</em>, <em class="sig-param">global_model=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/meta.html#MetaLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.meta.MetaLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>A meta layer for building any kind of graph network, inspired by the
<a class="reference external" href="https://arxiv.org/abs/1806.01261">“Relational Inductive Biases, Deep Learning, and Graph Networks”</a> paper.</p>
<p>A graph network takes a graph as input and returns an updated graph as
output (with same connectivity).
The input graph has node features <code class="xref py py-obj docutils literal notranslate"><span class="pre">x</span></code>, edge features <code class="xref py py-obj docutils literal notranslate"><span class="pre">edge_attr</span></code>
as well as global-level features <code class="xref py py-obj docutils literal notranslate"><span class="pre">u</span></code>.
The output graph has the same structure, but updated features.</p>
<p>Edge features, node features as well as global features are updated by
calling the modules <code class="xref py py-obj docutils literal notranslate"><span class="pre">edge_model</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">node_model</span></code> and
<code class="xref py py-obj docutils literal notranslate"><span class="pre">global_model</span></code>, respectively.</p>
<p>To allow for batch-wise graph processing, all callable functions take an
additional argument <code class="xref py py-obj docutils literal notranslate"><span class="pre">batch</span></code>, which determines the assignment of
edges or nodes to their specific graphs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>edge_model</strong> (<em>Module</em><em>, </em><em>optional</em>) – A callable which updates a graph’s edge
features based on its source and target node features, its current
edge features and its global features. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>node_model</strong> (<em>Module</em><em>, </em><em>optional</em>) – A callable which updates a graph’s node
features based on its current node features, its graph
connectivity, its edge features and its global features.
(default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>global_model</strong> (<em>Module</em><em>, </em><em>optional</em>) – A callable which updates a graph’s
global features based on its node features, its graph connectivity,
its edge features and its current global features.</p></li>
</ul>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">Sequential</span> <span class="k">as</span> <span class="n">Seq</span><span class="p">,</span> <span class="n">Linear</span> <span class="k">as</span> <span class="n">Lin</span><span class="p">,</span> <span class="n">ReLU</span>
<span class="kn">from</span> <span class="nn">torch_scatter</span> <span class="kn">import</span> <span class="n">scatter_mean</span>
<span class="kn">from</span> <span class="nn">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">MetaLayer</span>

<span class="k">class</span> <span class="nc">EdgeModel</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">EdgeModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">edge_mlp</span> <span class="o">=</span> <span class="n">Seq</span><span class="p">(</span><span class="n">Lin</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="o">...</span><span class="p">),</span> <span class="n">ReLU</span><span class="p">(),</span> <span class="n">Lin</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="o">...</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">dest</span><span class="p">,</span> <span class="n">edge_attr</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="c1"># source, target: [E, F_x], where E is the number of edges.</span>
        <span class="c1"># edge_attr: [E, F_e]</span>
        <span class="c1"># u: [B, F_u], where B is the number of graphs.</span>
        <span class="c1"># batch: [E] with max entry B - 1.</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">src</span><span class="p">,</span> <span class="n">dest</span><span class="p">,</span> <span class="n">edge_attr</span><span class="p">,</span> <span class="n">u</span><span class="p">[</span><span class="n">batch</span><span class="p">]],</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_mlp</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">NodeModel</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">NodeModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">node_mlp_1</span> <span class="o">=</span> <span class="n">Seq</span><span class="p">(</span><span class="n">Lin</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="o">...</span><span class="p">),</span> <span class="n">ReLU</span><span class="p">(),</span> <span class="n">Lin</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="o">...</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">node_mlp_2</span> <span class="o">=</span> <span class="n">Seq</span><span class="p">(</span><span class="n">Lin</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="o">...</span><span class="p">),</span> <span class="n">ReLU</span><span class="p">(),</span> <span class="n">Lin</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="o">...</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">edge_attr</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="c1"># x: [N, F_x], where N is the number of nodes.</span>
        <span class="c1"># edge_index: [2, E] with max entry N - 1.</span>
        <span class="c1"># edge_attr: [E, F_e]</span>
        <span class="c1"># u: [B, F_u]</span>
        <span class="c1"># batch: [N] with max entry B - 1.</span>
        <span class="n">row</span><span class="p">,</span> <span class="n">col</span> <span class="o">=</span> <span class="n">edge_index</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="n">row</span><span class="p">],</span> <span class="n">edge_attr</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_mlp_1</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">scatter_mean</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim_size</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">u</span><span class="p">[</span><span class="n">batch</span><span class="p">]],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_mlp_2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">GlobalModel</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GlobalModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">global_mlp</span> <span class="o">=</span> <span class="n">Seq</span><span class="p">(</span><span class="n">Lin</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="o">...</span><span class="p">),</span> <span class="n">ReLU</span><span class="p">(),</span> <span class="n">Lin</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="o">...</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">edge_attr</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="c1"># x: [N, F_x], where N is the number of nodes.</span>
        <span class="c1"># edge_index: [2, E] with max entry N - 1.</span>
        <span class="c1"># edge_attr: [E, F_e]</span>
        <span class="c1"># u: [B, F_u]</span>
        <span class="c1"># batch: [N] with max entry B - 1.</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">u</span><span class="p">,</span> <span class="n">scatter_mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_mlp</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

<span class="n">op</span> <span class="o">=</span> <span class="n">MetaLayer</span><span class="p">(</span><span class="n">EdgeModel</span><span class="p">(),</span> <span class="n">NodeModel</span><span class="p">(),</span> <span class="n">GlobalModel</span><span class="p">())</span>
<span class="n">x</span><span class="p">,</span> <span class="n">edge_attr</span><span class="p">,</span> <span class="n">u</span> <span class="o">=</span> <span class="n">op</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">edge_attr</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="torch_geometric.nn.meta.MetaLayer.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">edge_index</em>, <em class="sig-param">edge_attr=None</em>, <em class="sig-param">u=None</em>, <em class="sig-param">batch=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/meta.html#MetaLayer.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.meta.MetaLayer.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.meta.MetaLayer.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/meta.html#MetaLayer.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.meta.MetaLayer.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-torch_geometric.nn.dense.dense_gcn_conv">
<span id="dense-convolutional-layers"></span><h2><a class="toc-backref" href="#id12">Dense Convolutional Layers</a><a class="headerlink" href="#module-torch_geometric.nn.dense.dense_gcn_conv" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch_geometric.nn.dense.dense_gcn_conv.DenseGCNConv">
<em class="property">class </em><code class="sig-name descname">DenseGCNConv</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">improved=False</em>, <em class="sig-param">bias=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/dense/dense_gcn_conv.html#DenseGCNConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.dense.dense_gcn_conv.DenseGCNConv" title="Permalink to this definition">¶</a></dt>
<dd><p>See <a class="reference internal" href="#torch_geometric.nn.conv.GCNConv" title="torch_geometric.nn.conv.GCNConv"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.GCNConv</span></code></a>.</p>
<dl class="method">
<dt id="torch_geometric.nn.dense.dense_gcn_conv.DenseGCNConv.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">adj</em>, <em class="sig-param">mask=None</em>, <em class="sig-param">add_loop=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/dense/dense_gcn_conv.html#DenseGCNConv.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.dense.dense_gcn_conv.DenseGCNConv.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Node feature tensor <span class="math notranslate nohighlight">\(\mathbf{X} \in \mathbb{R}^{B
\times N \times F}\)</span>, with batch-size <span class="math notranslate nohighlight">\(B\)</span>, (maximum)
number of nodes <span class="math notranslate nohighlight">\(N\)</span> for each graph, and feature
dimension <span class="math notranslate nohighlight">\(F\)</span>.</p></li>
<li><p><strong>adj</strong> (<em>Tensor</em>) – Adjacency tensor <span class="math notranslate nohighlight">\(\mathbf{A} \in \mathbb{R}^{B
\times N \times N}\)</span>. The adjacency tensor is broadcastable in
the batch dimension, resulting in a shared adjacency matrix for
the complete batch.</p></li>
<li><p><strong>mask</strong> (<em>BoolTensor</em><em>, </em><em>optional</em>) – Mask matrix
<span class="math notranslate nohighlight">\(\mathbf{M} \in {\{ 0, 1 \}}^{B \times N}\)</span> indicating
the valid nodes for each graph. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>add_loop</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, the layer will
not automatically add self-loops to the adjacency matrices.
(default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.dense.dense_gcn_conv.DenseGCNConv.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/dense/dense_gcn_conv.html#DenseGCNConv.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.dense.dense_gcn_conv.DenseGCNConv.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<span class="target" id="module-torch_geometric.nn.dense.dense_sage_conv"></span><dl class="class">
<dt id="torch_geometric.nn.dense.dense_sage_conv.DenseSAGEConv">
<em class="property">class </em><code class="sig-name descname">DenseSAGEConv</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">normalize=False</em>, <em class="sig-param">bias=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/dense/dense_sage_conv.html#DenseSAGEConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.dense.dense_sage_conv.DenseSAGEConv" title="Permalink to this definition">¶</a></dt>
<dd><p>See <a class="reference internal" href="#torch_geometric.nn.conv.SAGEConv" title="torch_geometric.nn.conv.SAGEConv"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.SAGEConv</span></code></a>.</p>
<dl class="method">
<dt id="torch_geometric.nn.dense.dense_sage_conv.DenseSAGEConv.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">adj</em>, <em class="sig-param">mask=None</em>, <em class="sig-param">add_loop=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/dense/dense_sage_conv.html#DenseSAGEConv.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.dense.dense_sage_conv.DenseSAGEConv.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Node feature tensor <span class="math notranslate nohighlight">\(\mathbf{X} \in \mathbb{R}^{B
\times N \times F}\)</span>, with batch-size <span class="math notranslate nohighlight">\(B\)</span>, (maximum)
number of nodes <span class="math notranslate nohighlight">\(N\)</span> for each graph, and feature
dimension <span class="math notranslate nohighlight">\(F\)</span>.</p></li>
<li><p><strong>adj</strong> (<em>Tensor</em>) – Adjacency tensor <span class="math notranslate nohighlight">\(\mathbf{A} \in \mathbb{R}^{B
\times N \times N}\)</span>. The adjacency tensor is broadcastable in
the batch dimension, resulting in a shared adjacency matrix for
the complete batch.</p></li>
<li><p><strong>mask</strong> (<em>BoolTensor</em><em>, </em><em>optional</em>) – Mask matrix
<span class="math notranslate nohighlight">\(\mathbf{M} \in {\{ 0, 1 \}}^{B \times N}\)</span> indicating
the valid nodes for each graph. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>add_loop</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, the layer will
not automatically add self-loops to the adjacency matrices.
(default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.dense.dense_sage_conv.DenseSAGEConv.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/dense/dense_sage_conv.html#DenseSAGEConv.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.dense.dense_sage_conv.DenseSAGEConv.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<span class="target" id="module-torch_geometric.nn.dense.dense_graph_conv"></span><dl class="class">
<dt id="torch_geometric.nn.dense.dense_graph_conv.DenseGraphConv">
<em class="property">class </em><code class="sig-name descname">DenseGraphConv</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">aggr='add'</em>, <em class="sig-param">bias=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/dense/dense_graph_conv.html#DenseGraphConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.dense.dense_graph_conv.DenseGraphConv" title="Permalink to this definition">¶</a></dt>
<dd><p>See <a class="reference internal" href="#torch_geometric.nn.conv.GraphConv" title="torch_geometric.nn.conv.GraphConv"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.GraphConv</span></code></a>.</p>
<dl class="method">
<dt id="torch_geometric.nn.dense.dense_graph_conv.DenseGraphConv.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">adj</em>, <em class="sig-param">mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/dense/dense_graph_conv.html#DenseGraphConv.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.dense.dense_graph_conv.DenseGraphConv.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Node feature tensor <span class="math notranslate nohighlight">\(\mathbf{X} \in \mathbb{R}^{B
\times N \times F}\)</span>, with batch-size <span class="math notranslate nohighlight">\(B\)</span>, (maximum)
number of nodes <span class="math notranslate nohighlight">\(N\)</span> for each graph, and feature
dimension <span class="math notranslate nohighlight">\(F\)</span>.</p></li>
<li><p><strong>adj</strong> (<em>Tensor</em>) – Adjacency tensor <span class="math notranslate nohighlight">\(\mathbf{A} \in \mathbb{R}^{B
\times N \times N}\)</span>. The adjacency tensor is broadcastable in
the batch dimension, resulting in a shared adjacency matrix for
the complete batch.</p></li>
<li><p><strong>mask</strong> (<em>BoolTensor</em><em>, </em><em>optional</em>) – Mask matrix
<span class="math notranslate nohighlight">\(\mathbf{M} \in {\{ 0, 1 \}}^{B \times N}\)</span> indicating
the valid nodes for each graph. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.dense.dense_graph_conv.DenseGraphConv.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/dense/dense_graph_conv.html#DenseGraphConv.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.dense.dense_graph_conv.DenseGraphConv.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<span class="target" id="module-torch_geometric.nn.dense.dense_gin_conv"></span><dl class="class">
<dt id="torch_geometric.nn.dense.dense_gin_conv.DenseGINConv">
<em class="property">class </em><code class="sig-name descname">DenseGINConv</code><span class="sig-paren">(</span><em class="sig-param">nn</em>, <em class="sig-param">eps=0</em>, <em class="sig-param">train_eps=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/dense/dense_gin_conv.html#DenseGINConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.dense.dense_gin_conv.DenseGINConv" title="Permalink to this definition">¶</a></dt>
<dd><p>See <a class="reference internal" href="#torch_geometric.nn.conv.GINConv" title="torch_geometric.nn.conv.GINConv"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.GINConv</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.dense.dense_gin_conv.DenseGINConv.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">adj</em>, <em class="sig-param">mask=None</em>, <em class="sig-param">add_loop=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/dense/dense_gin_conv.html#DenseGINConv.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.dense.dense_gin_conv.DenseGINConv.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Node feature tensor <span class="math notranslate nohighlight">\(\mathbf{X} \in \mathbb{R}^{B
\times N \times F}\)</span>, with batch-size <span class="math notranslate nohighlight">\(B\)</span>, (maximum)
number of nodes <span class="math notranslate nohighlight">\(N\)</span> for each graph, and feature
dimension <span class="math notranslate nohighlight">\(F\)</span>.</p></li>
<li><p><strong>adj</strong> (<em>Tensor</em>) – Adjacency tensor <span class="math notranslate nohighlight">\(\mathbf{A} \in \mathbb{R}^{B
\times N \times N}\)</span>. The adjacency tensor is broadcastable in
the batch dimension, resulting in a shared adjacency matrix for
the complete batch.</p></li>
<li><p><strong>mask</strong> (<em>BoolTensor</em><em>, </em><em>optional</em>) – Mask matrix
<span class="math notranslate nohighlight">\(\mathbf{M} \in {\{ 0, 1 \}}^{B \times N}\)</span> indicating
the valid nodes for each graph. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>add_loop</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, the layer will
not automatically add self-loops to the adjacency matrices.
(default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.dense.dense_gin_conv.DenseGINConv.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/dense/dense_gin_conv.html#DenseGINConv.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.dense.dense_gin_conv.DenseGINConv.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-torch_geometric.nn.norm">
<span id="normalization-layers"></span><h2><a class="toc-backref" href="#id13">Normalization Layers</a><a class="headerlink" href="#module-torch_geometric.nn.norm" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch_geometric.nn.norm.BatchNorm">
<em class="property">class </em><code class="sig-name descname">BatchNorm</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">eps=1e-05</em>, <em class="sig-param">momentum=0.1</em>, <em class="sig-param">affine=True</em>, <em class="sig-param">track_running_stats=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/norm/batch_norm.html#BatchNorm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.norm.BatchNorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies batch normalization over a batch of node features as described
in the <a class="reference external" href="https://arxiv.org/abs/1502.03167">“Batch Normalization: Accelerating Deep Network Training by
Reducing Internal Covariate Shift”</a>
paper</p>
<div class="math notranslate nohighlight">
\[\mathbf{x}^{\prime}_i = \frac{\mathbf{x} -
\textrm{E}[\mathbf{x}]}{\sqrt{\textrm{Var}[\mathbf{x}] + \epsilon}}
\odot \gamma + \beta\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each input sample.</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – A value added to the denominator for numerical
stability. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">1e-5</span></code>)</p></li>
<li><p><strong>momentum</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – The value used for the running mean and
running variance computation. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">0.1</span></code>)</p></li>
<li><p><strong>affine</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>, this module has
learnable affine parameters <span class="math notranslate nohighlight">\(\gamma\)</span> and <span class="math notranslate nohighlight">\(\beta\)</span>.
(default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
<li><p><strong>track_running_stats</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>, this
module tracks the running mean and variance, and when set to
<a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, this module does not track such statistics and always
uses batch statistics in both training and eval modes.
(default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.norm.BatchNorm.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/norm/batch_norm.html#BatchNorm.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.norm.BatchNorm.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.norm.InstanceNorm">
<em class="property">class </em><code class="sig-name descname">InstanceNorm</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">eps=1e-05</em>, <em class="sig-param">momentum=0.1</em>, <em class="sig-param">affine=False</em>, <em class="sig-param">track_running_stats=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/norm/instance_norm.html#InstanceNorm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.norm.InstanceNorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies instance normalization over each individual example in a batch
of node features as described in the <a class="reference external" href="https://arxiv.org/abs/1607.08022">“Instance Normalization: The Missing
Ingredient for Fast Stylization”</a>
paper</p>
<div class="math notranslate nohighlight">
\[\mathbf{x}^{\prime}_i = \frac{\mathbf{x} -
\textrm{E}[\mathbf{x}]}{\sqrt{\textrm{Var}[\mathbf{x}] + \epsilon}}
\odot \gamma + \beta\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each input sample.</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – A value added to the denominator for numerical
stability. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">1e-5</span></code>)</p></li>
<li><p><strong>momentum</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – The value used for the running mean and
running variance computation. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">0.1</span></code>)</p></li>
<li><p><strong>affine</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>, this module has
learnable affine parameters <span class="math notranslate nohighlight">\(\gamma\)</span> and <span class="math notranslate nohighlight">\(\beta\)</span>.
(default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>)</p></li>
<li><p><strong>track_running_stats</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>, this
module tracks the running mean and variance, and when set to
<a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, this module does not track such statistics and always
uses instance statistics in both training and eval modes.
(default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>)</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.norm.InstanceNorm.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">batch=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/norm/instance_norm.html#InstanceNorm.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.norm.InstanceNorm.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.norm.GraphSizeNorm">
<em class="property">class </em><code class="sig-name descname">GraphSizeNorm</code><a class="reference internal" href="../_modules/torch_geometric/nn/norm/graph_size_norm.html#GraphSizeNorm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.norm.GraphSizeNorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies Graph Size Normalization over each individual graph in a batch
of node features as described in the
<a class="reference external" href="https://arxiv.org/abs/2003.00982">“Benchmarking Graph Neural Networks”</a>
paper</p>
<div class="math notranslate nohighlight">
\[\mathbf{x}^{\prime}_i = \frac{\mathbf{x}_i}{\sqrt{|\mathcal{V}|}}\]</div>
<dl class="method">
<dt id="torch_geometric.nn.norm.GraphSizeNorm.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">batch=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/norm/graph_size_norm.html#GraphSizeNorm.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.norm.GraphSizeNorm.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-torch_geometric.nn.glob">
<span id="global-pooling-layers"></span><h2><a class="toc-backref" href="#id14">Global Pooling Layers</a><a class="headerlink" href="#module-torch_geometric.nn.glob" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="torch_geometric.nn.glob.global_add_pool">
<code class="sig-name descname">global_add_pool</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">batch</em>, <em class="sig-param">size=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/glob/glob.html#global_add_pool"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.glob.global_add_pool" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns batch-wise graph-level-outputs by adding node features
across the node dimension, so that for a single graph
<span class="math notranslate nohighlight">\(\mathcal{G}_i\)</span> its output is computed by</p>
<div class="math notranslate nohighlight">
\[\mathbf{r}_i = \sum_{n=1}^{N_i} \mathbf{x}_n\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Node feature matrix
<span class="math notranslate nohighlight">\(\mathbf{X} \in \mathbb{R}^{(N_1 + \ldots + N_B) \times F}\)</span>.</p></li>
<li><p><strong>batch</strong> (<em>LongTensor</em>) – Batch vector <span class="math notranslate nohighlight">\(\mathbf{b} \in {\{ 0, \ldots,
B-1\}}^N\)</span>, which assigns each node to a specific example.</p></li>
<li><p><strong>size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Batch-size <span class="math notranslate nohighlight">\(B\)</span>.
Automatically calculated if not given. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="torch_geometric.nn.glob.global_mean_pool">
<code class="sig-name descname">global_mean_pool</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">batch</em>, <em class="sig-param">size=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/glob/glob.html#global_mean_pool"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.glob.global_mean_pool" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns batch-wise graph-level-outputs by averaging node features
across the node dimension, so that for a single graph
<span class="math notranslate nohighlight">\(\mathcal{G}_i\)</span> its output is computed by</p>
<div class="math notranslate nohighlight">
\[\mathbf{r}_i = \frac{1}{N_i} \sum_{n=1}^{N_i} \mathbf{x}_n\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Node feature matrix
<span class="math notranslate nohighlight">\(\mathbf{X} \in \mathbb{R}^{(N_1 + \ldots + N_B) \times F}\)</span>.</p></li>
<li><p><strong>batch</strong> (<em>LongTensor</em>) – Batch vector <span class="math notranslate nohighlight">\(\mathbf{b} \in {\{ 0, \ldots,
B-1\}}^N\)</span>, which assigns each node to a specific example.</p></li>
<li><p><strong>size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Batch-size <span class="math notranslate nohighlight">\(B\)</span>.
Automatically calculated if not given. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="torch_geometric.nn.glob.global_max_pool">
<code class="sig-name descname">global_max_pool</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">batch</em>, <em class="sig-param">size=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/glob/glob.html#global_max_pool"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.glob.global_max_pool" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns batch-wise graph-level-outputs by taking the channel-wise
maximum across the node dimension, so that for a single graph
<span class="math notranslate nohighlight">\(\mathcal{G}_i\)</span> its output is computed by</p>
<div class="math notranslate nohighlight">
\[\mathbf{r}_i = \mathrm{max}_{n=1}^{N_i} \, \mathbf{x}_n\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Node feature matrix
<span class="math notranslate nohighlight">\(\mathbf{X} \in \mathbb{R}^{(N_1 + \ldots + N_B) \times F}\)</span>.</p></li>
<li><p><strong>batch</strong> (<em>LongTensor</em>) – Batch vector <span class="math notranslate nohighlight">\(\mathbf{b} \in {\{ 0, \ldots,
B-1\}}^N\)</span>, which assigns each node to a specific example.</p></li>
<li><p><strong>size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Batch-size <span class="math notranslate nohighlight">\(B\)</span>.
Automatically calculated if not given. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="torch_geometric.nn.glob.global_sort_pool">
<code class="sig-name descname">global_sort_pool</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">batch</em>, <em class="sig-param">k</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/glob/sort.html#global_sort_pool"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.glob.global_sort_pool" title="Permalink to this definition">¶</a></dt>
<dd><p>The global pooling operator from the <a class="reference external" href="https://www.cse.wustl.edu/~muhan/papers/AAAI_2018_DGCNN.pdf">“An End-to-End Deep Learning
Architecture for Graph Classification”</a> paper,
where node features are first sorted individually and then  sorted in
descending order based on their last features. The first <span class="math notranslate nohighlight">\(k\)</span> nodes
form the output of the layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Node feature matrix
<span class="math notranslate nohighlight">\(\mathbf{X} \in \mathbb{R}^{N \times F}\)</span>.</p></li>
<li><p><strong>batch</strong> (<em>LongTensor</em>) – Batch vector <span class="math notranslate nohighlight">\(\mathbf{b} \in {\{ 0, \ldots,
B-1\}}^N\)</span>, which assigns each node to a specific example.</p></li>
<li><p><strong>k</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of nodes to hold for each graph.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.glob.GlobalAttention">
<em class="property">class </em><code class="sig-name descname">GlobalAttention</code><span class="sig-paren">(</span><em class="sig-param">gate_nn</em>, <em class="sig-param">nn=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/glob/attention.html#GlobalAttention"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.glob.GlobalAttention" title="Permalink to this definition">¶</a></dt>
<dd><p>Global soft attention layer from the <a class="reference external" href="https://arxiv.org/abs/1511.05493">“Gated Graph Sequence Neural
Networks”</a> paper</p>
<div class="math notranslate nohighlight">
\[\mathbf{r}_i = \sum_{n=1}^{N_i} \mathrm{softmax} \left(
h_{\mathrm{gate}} ( \mathbf{x}_n ) \right) \odot
h_{\mathbf{\Theta}} ( \mathbf{x}_n ),\]</div>
<p>where <span class="math notranslate nohighlight">\(h_{\mathrm{gate}} \colon \mathbb{R}^F \to
\mathbb{R}\)</span> and <span class="math notranslate nohighlight">\(h_{\mathbf{\Theta}}\)</span> denote neural networks, <em>i.e.</em>
MLPS.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>gate_nn</strong> (<em>torch.nn.Module</em>) – A neural network <span class="math notranslate nohighlight">\(h_{\mathrm{gate}}\)</span>
that computes attention scores by mapping node features <code class="xref py py-obj docutils literal notranslate"><span class="pre">x</span></code> of
shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">[-1,</span> <span class="pre">in_channels]</span></code> to shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">[-1,</span> <span class="pre">1]</span></code>, <em>e.g.</em>,
defined by <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.Sequential</span></code>.</p></li>
<li><p><strong>nn</strong> (<em>torch.nn.Module</em><em>, </em><em>optional</em>) – A neural network
<span class="math notranslate nohighlight">\(h_{\mathbf{\Theta}}\)</span> that maps node features <code class="xref py py-obj docutils literal notranslate"><span class="pre">x</span></code> of
shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">[-1,</span> <span class="pre">in_channels]</span></code> to shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">[-1,</span> <span class="pre">out_channels]</span></code>
before combining them with the attention scores, <em>e.g.</em>, defined by
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.Sequential</span></code>. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.glob.GlobalAttention.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">batch</em>, <em class="sig-param">size=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/glob/attention.html#GlobalAttention.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.glob.GlobalAttention.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.glob.GlobalAttention.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/glob/attention.html#GlobalAttention.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.glob.GlobalAttention.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.glob.Set2Set">
<em class="property">class </em><code class="sig-name descname">Set2Set</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">processing_steps</em>, <em class="sig-param">num_layers=1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/glob/set2set.html#Set2Set"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.glob.Set2Set" title="Permalink to this definition">¶</a></dt>
<dd><p>The global pooling operator based on iterative content-based attention
from the <a class="reference external" href="https://arxiv.org/abs/1511.06391">“Order Matters: Sequence to sequence for sets”</a> paper</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{q}_t &amp;= \mathrm{LSTM}(\mathbf{q}^{*}_{t-1})\\\alpha_{i,t} &amp;= \mathrm{softmax}(\mathbf{x}_i \cdot \mathbf{q}_t)\\\mathbf{r}_t &amp;= \sum_{i=1}^N \alpha_{i,t} \mathbf{x}_i\\\mathbf{q}^{*}_t &amp;= \mathbf{q}_t \, \Vert \, \mathbf{r}_t,\end{aligned}\end{align} \]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{q}^{*}_T\)</span> defines the output of the layer with twice
the dimensionality as the input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each input sample.</p></li>
<li><p><strong>processing_steps</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of iterations <span class="math notranslate nohighlight">\(T\)</span>.</p></li>
<li><p><strong>num_layers</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Number of recurrent layers, <em>.e.g</em>, setting
<code class="xref py py-obj docutils literal notranslate"><span class="pre">num_layers=2</span></code> would mean stacking two LSTMs together to form
a stacked LSTM, with the second LSTM taking in outputs of the first
LSTM and computing the final results. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">1</span></code>)</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.glob.Set2Set.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">batch</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/glob/set2set.html#Set2Set.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.glob.Set2Set.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.glob.Set2Set.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/glob/set2set.html#Set2Set.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.glob.Set2Set.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-torch_geometric.nn.pool">
<span id="pooling-layers"></span><h2><a class="toc-backref" href="#id15">Pooling Layers</a><a class="headerlink" href="#module-torch_geometric.nn.pool" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch_geometric.nn.pool.TopKPooling">
<em class="property">class </em><code class="sig-name descname">TopKPooling</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">ratio=0.5</em>, <em class="sig-param">min_score=None</em>, <em class="sig-param">multiplier=1</em>, <em class="sig-param">nonlinearity=&lt;built-in method tanh of type object&gt;</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/pool/topk_pool.html#TopKPooling"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.pool.TopKPooling" title="Permalink to this definition">¶</a></dt>
<dd><p><span class="math notranslate nohighlight">\(\mathrm{top}_k\)</span> pooling operator from the <a class="reference external" href="https://arxiv.org/abs/1905.05178">“Graph U-Nets”</a>, <a class="reference external" href="https://arxiv.org/abs/1811.01287">“Towards Sparse
Hierarchical Graph Classifiers”</a>
and <a class="reference external" href="https://arxiv.org/abs/1905.02850">“Understanding Attention and Generalization in Graph Neural
Networks”</a> papers</p>
<p>if min_score <span class="math notranslate nohighlight">\(\tilde{\alpha}\)</span> is None:</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{y} &amp;= \frac{\mathbf{X}\mathbf{p}}{\| \mathbf{p} \|}\\\mathbf{i} &amp;= \mathrm{top}_k(\mathbf{y})\\\mathbf{X}^{\prime} &amp;= (\mathbf{X} \odot
\mathrm{tanh}(\mathbf{y}))_{\mathbf{i}}\\\mathbf{A}^{\prime} &amp;= \mathbf{A}_{\mathbf{i},\mathbf{i}}\end{aligned}\end{align} \]</div>
</div></blockquote>
<p>if min_score <span class="math notranslate nohighlight">\(\tilde{\alpha}\)</span> is a value in [0, 1]:</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{y} &amp;= \mathrm{softmax}(\mathbf{X}\mathbf{p})\\\mathbf{i} &amp;= \mathbf{y}_i &gt; \tilde{\alpha}\\\mathbf{X}^{\prime} &amp;= (\mathbf{X} \odot \mathbf{y})_{\mathbf{i}}\\\mathbf{A}^{\prime} &amp;= \mathbf{A}_{\mathbf{i},\mathbf{i}},\end{aligned}\end{align} \]</div>
</div></blockquote>
<p>where nodes are dropped based on a learnable projection score
<span class="math notranslate nohighlight">\(\mathbf{p}\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each input sample.</p></li>
<li><p><strong>ratio</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Graph pooling ratio, which is used to compute
<span class="math notranslate nohighlight">\(k = \lceil \mathrm{ratio} \cdot N \rceil\)</span>.
This value is ignored if min_score is not None.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">0.5</span></code>)</p></li>
<li><p><strong>min_score</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Minimal node score <span class="math notranslate nohighlight">\(\tilde{\alpha}\)</span>
which is used to compute indices of pooled nodes
<span class="math notranslate nohighlight">\(\mathbf{i} = \mathbf{y}_i &gt; \tilde{\alpha}\)</span>.
When this value is not <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>, the <code class="xref py py-obj docutils literal notranslate"><span class="pre">ratio</span></code> argument is
ignored. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>multiplier</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Coefficient by which features gets
multiplied after pooling. This can be useful for large graphs and
when <code class="xref py py-obj docutils literal notranslate"><span class="pre">min_score</span></code> is used. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">1</span></code>)</p></li>
<li><p><strong>nonlinearity</strong> (<em>torch.nn.functional</em><em>, </em><em>optional</em>) – The nonlinearity to use.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.tanh</span></code>)</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.pool.TopKPooling.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">edge_index</em>, <em class="sig-param">edge_attr=None</em>, <em class="sig-param">batch=None</em>, <em class="sig-param">attn=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/pool/topk_pool.html#TopKPooling.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.pool.TopKPooling.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.pool.TopKPooling.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/pool/topk_pool.html#TopKPooling.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.pool.TopKPooling.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.pool.SAGPooling">
<em class="property">class </em><code class="sig-name descname">SAGPooling</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">ratio=0.5</em>, <em class="sig-param">GNN=&lt;class 'torch_geometric.nn.conv.graph_conv.GraphConv'&gt;</em>, <em class="sig-param">min_score=None</em>, <em class="sig-param">multiplier=1</em>, <em class="sig-param">nonlinearity=&lt;built-in method tanh of type object&gt;</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/pool/sag_pool.html#SAGPooling"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.pool.SAGPooling" title="Permalink to this definition">¶</a></dt>
<dd><p>The self-attention pooling operator from the <a class="reference external" href="https://arxiv.org/abs/1904.08082">“Self-Attention Graph
Pooling”</a> and <a class="reference external" href="https://arxiv.org/abs/1905.02850">“Understanding
Attention and Generalization in Graph Neural Networks”</a> papers</p>
<p>if <code class="xref py py-obj docutils literal notranslate"><span class="pre">min_score</span></code> <span class="math notranslate nohighlight">\(\tilde{\alpha}\)</span> is <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>:</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{y} &amp;= \textrm{GNN}(\mathbf{X}, \mathbf{A})\\\mathbf{i} &amp;= \mathrm{top}_k(\mathbf{y})\\\mathbf{X}^{\prime} &amp;= (\mathbf{X} \odot
\mathrm{tanh}(\mathbf{y}))_{\mathbf{i}}\\\mathbf{A}^{\prime} &amp;= \mathbf{A}_{\mathbf{i},\mathbf{i}}\end{aligned}\end{align} \]</div>
</div></blockquote>
<p>if <code class="xref py py-obj docutils literal notranslate"><span class="pre">min_score</span></code> <span class="math notranslate nohighlight">\(\tilde{\alpha}\)</span> is a value in [0, 1]:</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{y} &amp;= \mathrm{softmax}(\textrm{GNN}(\mathbf{X},\mathbf{A}))\\\mathbf{i} &amp;= \mathbf{y}_i &gt; \tilde{\alpha}\\\mathbf{X}^{\prime} &amp;= (\mathbf{X} \odot \mathbf{y})_{\mathbf{i}}\\\mathbf{A}^{\prime} &amp;= \mathbf{A}_{\mathbf{i},\mathbf{i}},\end{aligned}\end{align} \]</div>
</div></blockquote>
<p>where nodes are dropped based on a learnable projection score
<span class="math notranslate nohighlight">\(\mathbf{p}\)</span>.
Projections scores are learned based on a graph neural network layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each input sample.</p></li>
<li><p><strong>ratio</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Graph pooling ratio, which is used to compute
<span class="math notranslate nohighlight">\(k = \lceil \mathrm{ratio} \cdot N \rceil\)</span>.
This value is ignored if min_score is not None.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">0.5</span></code>)</p></li>
<li><p><strong>GNN</strong> (<em>torch.nn.Module</em><em>, </em><em>optional</em>) – A graph neural network layer for
calculating projection scores (one of
<a class="reference internal" href="#torch_geometric.nn.conv.GraphConv" title="torch_geometric.nn.conv.GraphConv"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.GraphConv</span></code></a>,
<a class="reference internal" href="#torch_geometric.nn.conv.GCNConv" title="torch_geometric.nn.conv.GCNConv"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.GCNConv</span></code></a>,
<a class="reference internal" href="#torch_geometric.nn.conv.GATConv" title="torch_geometric.nn.conv.GATConv"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.GATConv</span></code></a> or
<a class="reference internal" href="#torch_geometric.nn.conv.SAGEConv" title="torch_geometric.nn.conv.SAGEConv"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.SAGEConv</span></code></a>). (default:
<a class="reference internal" href="#torch_geometric.nn.conv.GraphConv" title="torch_geometric.nn.conv.GraphConv"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.GraphConv</span></code></a>)</p></li>
<li><p><strong>min_score</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Minimal node score <span class="math notranslate nohighlight">\(\tilde{\alpha}\)</span>
which is used to compute indices of pooled nodes
<span class="math notranslate nohighlight">\(\mathbf{i} = \mathbf{y}_i &gt; \tilde{\alpha}\)</span>.
When this value is not <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>, the <code class="xref py py-obj docutils literal notranslate"><span class="pre">ratio</span></code> argument is
ignored. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>multiplier</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Coefficient by which features gets
multiplied after pooling. This can be useful for large graphs and
when <code class="xref py py-obj docutils literal notranslate"><span class="pre">min_score</span></code> is used. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">1</span></code>)</p></li>
<li><p><strong>nonlinearity</strong> (<em>torch.nn.functional</em><em>, </em><em>optional</em>) – The nonlinearity to use.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.tanh</span></code>)</p></li>
<li><p><strong>**kwargs</strong> (<em>optional</em>) – Additional parameters for initializing the graph
neural network layer.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.pool.SAGPooling.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">edge_index</em>, <em class="sig-param">edge_attr=None</em>, <em class="sig-param">batch=None</em>, <em class="sig-param">attn=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/pool/sag_pool.html#SAGPooling.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.pool.SAGPooling.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.pool.SAGPooling.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/pool/sag_pool.html#SAGPooling.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.pool.SAGPooling.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.pool.EdgePooling">
<em class="property">class </em><code class="sig-name descname">EdgePooling</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">edge_score_method=None</em>, <em class="sig-param">dropout=0</em>, <em class="sig-param">add_to_edge_score=0.5</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/pool/edge_pool.html#EdgePooling"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.pool.EdgePooling" title="Permalink to this definition">¶</a></dt>
<dd><p>The edge pooling operator from the <a class="reference external" href="https://graphreason.github.io/papers/17.pdf">“Towards Graph Pooling by Edge
Contraction”</a> and
<a class="reference external" href="https://arxiv.org/abs/1905.10990">“Edge Contraction Pooling for Graph Neural Networks”</a> papers.</p>
<p>In short, a score is computed for each edge.
Edges are contracted iteratively according to that score unless one of
their nodes has already been part of a contracted edge.</p>
<p>To duplicate the configuration from the “Towards Graph Pooling by Edge
Contraction” paper, use either
<a class="reference internal" href="#torch_geometric.nn.pool.EdgePooling.compute_edge_score_softmax" title="torch_geometric.nn.pool.EdgePooling.compute_edge_score_softmax"><code class="xref py py-func docutils literal notranslate"><span class="pre">EdgePooling.compute_edge_score_softmax()</span></code></a>
or <a class="reference internal" href="#torch_geometric.nn.pool.EdgePooling.compute_edge_score_tanh" title="torch_geometric.nn.pool.EdgePooling.compute_edge_score_tanh"><code class="xref py py-func docutils literal notranslate"><span class="pre">EdgePooling.compute_edge_score_tanh()</span></code></a>, and set
<code class="xref py py-obj docutils literal notranslate"><span class="pre">add_to_edge_score</span></code> to <code class="xref py py-obj docutils literal notranslate"><span class="pre">0</span></code>.</p>
<p>To duplicate the configuration from the “Edge Contraction Pooling for
Graph Neural Networks” paper, set <code class="xref py py-obj docutils literal notranslate"><span class="pre">dropout</span></code> to <code class="xref py py-obj docutils literal notranslate"><span class="pre">0.2</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each input sample.</p></li>
<li><p><strong>edge_score_method</strong> (<em>function</em><em>, </em><em>optional</em>) – The function to apply
to compute the edge score from raw edge scores. By default,
this is the softmax over all incoming edges for each node.
This function takes in a <code class="xref py py-obj docutils literal notranslate"><span class="pre">raw_edge_score</span></code> tensor of shape
<code class="xref py py-obj docutils literal notranslate"><span class="pre">[num_nodes]</span></code>, an <code class="xref py py-obj docutils literal notranslate"><span class="pre">edge_index</span></code> tensor and the number of
nodes <code class="xref py py-obj docutils literal notranslate"><span class="pre">num_nodes</span></code>, and produces a new tensor of the same size
as <code class="xref py py-obj docutils literal notranslate"><span class="pre">raw_edge_score</span></code> describing normalized edge scores.
Included functions are
<a class="reference internal" href="#torch_geometric.nn.pool.EdgePooling.compute_edge_score_softmax" title="torch_geometric.nn.pool.EdgePooling.compute_edge_score_softmax"><code class="xref py py-func docutils literal notranslate"><span class="pre">EdgePooling.compute_edge_score_softmax()</span></code></a>,
<a class="reference internal" href="#torch_geometric.nn.pool.EdgePooling.compute_edge_score_tanh" title="torch_geometric.nn.pool.EdgePooling.compute_edge_score_tanh"><code class="xref py py-func docutils literal notranslate"><span class="pre">EdgePooling.compute_edge_score_tanh()</span></code></a>, and
<a class="reference internal" href="#torch_geometric.nn.pool.EdgePooling.compute_edge_score_sigmoid" title="torch_geometric.nn.pool.EdgePooling.compute_edge_score_sigmoid"><code class="xref py py-func docutils literal notranslate"><span class="pre">EdgePooling.compute_edge_score_sigmoid()</span></code></a>.
(default: <a class="reference internal" href="#torch_geometric.nn.pool.EdgePooling.compute_edge_score_softmax" title="torch_geometric.nn.pool.EdgePooling.compute_edge_score_softmax"><code class="xref py py-func docutils literal notranslate"><span class="pre">EdgePooling.compute_edge_score_softmax()</span></code></a>)</p></li>
<li><p><strong>dropout</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – The probability with
which to drop edge scores during training. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">0</span></code>)</p></li>
<li><p><strong>add_to_edge_score</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – This is added to each
computed edge score. Adding this greatly helps with unpool
stability. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">0.5</span></code>)</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.pool.EdgePooling.compute_edge_score_sigmoid">
<em class="property">static </em><code class="sig-name descname">compute_edge_score_sigmoid</code><span class="sig-paren">(</span><em class="sig-param">raw_edge_score</em>, <em class="sig-param">edge_index</em>, <em class="sig-param">num_nodes</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/pool/edge_pool.html#EdgePooling.compute_edge_score_sigmoid"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.pool.EdgePooling.compute_edge_score_sigmoid" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.pool.EdgePooling.compute_edge_score_softmax">
<em class="property">static </em><code class="sig-name descname">compute_edge_score_softmax</code><span class="sig-paren">(</span><em class="sig-param">raw_edge_score</em>, <em class="sig-param">edge_index</em>, <em class="sig-param">num_nodes</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/pool/edge_pool.html#EdgePooling.compute_edge_score_softmax"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.pool.EdgePooling.compute_edge_score_softmax" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.pool.EdgePooling.compute_edge_score_tanh">
<em class="property">static </em><code class="sig-name descname">compute_edge_score_tanh</code><span class="sig-paren">(</span><em class="sig-param">raw_edge_score</em>, <em class="sig-param">edge_index</em>, <em class="sig-param">num_nodes</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/pool/edge_pool.html#EdgePooling.compute_edge_score_tanh"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.pool.EdgePooling.compute_edge_score_tanh" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.pool.EdgePooling.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">edge_index</em>, <em class="sig-param">batch</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/pool/edge_pool.html#EdgePooling.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.pool.EdgePooling.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Forward computation which computes the raw edge score, normalizes
it, and merges the edges.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – The node features.</p></li>
<li><p><strong>edge_index</strong> (<em>LongTensor</em>) – The edge indices.</p></li>
<li><p><strong>batch</strong> (<em>LongTensor</em>) – Batch vector
<span class="math notranslate nohighlight">\(\mathbf{b} \in {\{ 0, \ldots, B-1\}}^N\)</span>, which assigns
each node to a specific example.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Return types:</dt><dd><ul class="simple">
<li><p><strong>x</strong> <em>(Tensor)</em> - The pooled node features.</p></li>
<li><p><strong>edge_index</strong> <em>(LongTensor)</em> - The coarsened edge indices.</p></li>
<li><p><strong>batch</strong> <em>(LongTensor)</em> - The coarsened batch vector.</p></li>
<li><p><strong>unpool_info</strong> <em>(unpool_description)</em> - Information that is
consumed by <a class="reference internal" href="#torch_geometric.nn.pool.EdgePooling.unpool" title="torch_geometric.nn.pool.EdgePooling.unpool"><code class="xref py py-func docutils literal notranslate"><span class="pre">EdgePooling.unpool()</span></code></a> for unpooling.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.pool.EdgePooling.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/pool/edge_pool.html#EdgePooling.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.pool.EdgePooling.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.pool.EdgePooling.unpool">
<code class="sig-name descname">unpool</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">unpool_info</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/pool/edge_pool.html#EdgePooling.unpool"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.pool.EdgePooling.unpool" title="Permalink to this definition">¶</a></dt>
<dd><p>Unpools a previous edge pooling step.</p>
<p>For unpooling, <code class="xref py py-obj docutils literal notranslate"><span class="pre">x</span></code> should be of same shape as those produced by
this layer’s <a class="reference internal" href="#torch_geometric.nn.pool.EdgePooling.forward" title="torch_geometric.nn.pool.EdgePooling.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> function. Then, it will produce an
unpooled <code class="xref py py-obj docutils literal notranslate"><span class="pre">x</span></code> in addition to <code class="xref py py-obj docutils literal notranslate"><span class="pre">edge_index</span></code> and <code class="xref py py-obj docutils literal notranslate"><span class="pre">batch</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – The node features.</p></li>
<li><p><strong>unpool_info</strong> (<em>unpool_description</em>) – Information that has
been produced by <a class="reference internal" href="#torch_geometric.nn.pool.EdgePooling.forward" title="torch_geometric.nn.pool.EdgePooling.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">EdgePooling.forward()</span></code></a>.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Return types:</dt><dd><ul class="simple">
<li><p><strong>x</strong> <em>(Tensor)</em> - The unpooled node features.</p></li>
<li><p><strong>edge_index</strong> <em>(LongTensor)</em> - The new edge indices.</p></li>
<li><p><strong>batch</strong> <em>(LongTensor)</em> - The new batch vector.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="torch_geometric.nn.pool.EdgePooling.unpool_description">
<code class="sig-name descname">unpool_description</code><a class="headerlink" href="#torch_geometric.nn.pool.EdgePooling.unpool_description" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">UnpoolDescription</span></code></p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="torch_geometric.nn.pool.max_pool">
<code class="sig-name descname">max_pool</code><span class="sig-paren">(</span><em class="sig-param">cluster</em>, <em class="sig-param">data</em>, <em class="sig-param">transform=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/pool/max_pool.html#max_pool"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.pool.max_pool" title="Permalink to this definition">¶</a></dt>
<dd><p>Pools and coarsens a graph given by the
<a class="reference internal" href="data.html#torch_geometric.data.Data" title="torch_geometric.data.Data"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.data.Data</span></code></a> object according to the clustering
defined in <code class="xref py py-attr docutils literal notranslate"><span class="pre">cluster</span></code>.
All nodes within the same cluster will be represented as one node.
Final node features are defined by the <em>maximum</em> features of all nodes
within the same cluster, node positions are averaged and edge indices are
defined to be the union of the edge indices of all nodes within the same
cluster.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cluster</strong> (<em>LongTensor</em>) – Cluster vector <span class="math notranslate nohighlight">\(\mathbf{c} \in \{ 0,
\ldots, N - 1 \}^N\)</span>, which assigns each node to a specific cluster.</p></li>
<li><p><strong>data</strong> (<a class="reference internal" href="data.html#torch_geometric.data.Data" title="torch_geometric.data.Data"><em>Data</em></a>) – Graph data object.</p></li>
<li><p><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
coarsened and pooled <a class="reference internal" href="data.html#torch_geometric.data.Data" title="torch_geometric.data.Data"><code class="xref py py-obj docutils literal notranslate"><span class="pre">torch_geometric.data.Data</span></code></a> object and
returns a transformed version. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="data.html#torch_geometric.data.Data" title="torch_geometric.data.Data"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.data.Data</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="torch_geometric.nn.pool.avg_pool">
<code class="sig-name descname">avg_pool</code><span class="sig-paren">(</span><em class="sig-param">cluster</em>, <em class="sig-param">data</em>, <em class="sig-param">transform=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/pool/avg_pool.html#avg_pool"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.pool.avg_pool" title="Permalink to this definition">¶</a></dt>
<dd><p>Pools and coarsens a graph given by the
<a class="reference internal" href="data.html#torch_geometric.data.Data" title="torch_geometric.data.Data"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.data.Data</span></code></a> object according to the clustering
defined in <code class="xref py py-attr docutils literal notranslate"><span class="pre">cluster</span></code>.
Final node features are defined by the <em>average</em> features of all nodes
within the same cluster.
See <a class="reference internal" href="#torch_geometric.nn.pool.max_pool" title="torch_geometric.nn.pool.max_pool"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch_geometric.nn.pool.max_pool()</span></code></a> for more details.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cluster</strong> (<em>LongTensor</em>) – Cluster vector <span class="math notranslate nohighlight">\(\mathbf{c} \in \{ 0,
\ldots, N - 1 \}^N\)</span>, which assigns each node to a specific cluster.</p></li>
<li><p><strong>data</strong> (<a class="reference internal" href="data.html#torch_geometric.data.Data" title="torch_geometric.data.Data"><em>Data</em></a>) – Graph data object.</p></li>
<li><p><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
coarsened and pooled <a class="reference internal" href="data.html#torch_geometric.data.Data" title="torch_geometric.data.Data"><code class="xref py py-obj docutils literal notranslate"><span class="pre">torch_geometric.data.Data</span></code></a> object and
returns a transformed version. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="data.html#torch_geometric.data.Data" title="torch_geometric.data.Data"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.data.Data</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="torch_geometric.nn.pool.max_pool_x">
<code class="sig-name descname">max_pool_x</code><span class="sig-paren">(</span><em class="sig-param">cluster</em>, <em class="sig-param">x</em>, <em class="sig-param">batch</em>, <em class="sig-param">size=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/pool/max_pool.html#max_pool_x"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.pool.max_pool_x" title="Permalink to this definition">¶</a></dt>
<dd><p>Max-Pools node features according to the clustering defined in
<code class="xref py py-attr docutils literal notranslate"><span class="pre">cluster</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cluster</strong> (<em>LongTensor</em>) – Cluster vector <span class="math notranslate nohighlight">\(\mathbf{c} \in \{ 0,
\ldots, N - 1 \}^N\)</span>, which assigns each node to a specific cluster.</p></li>
<li><p><strong>x</strong> (<em>Tensor</em>) – Node feature matrix
<span class="math notranslate nohighlight">\(\mathbf{X} \in \mathbb{R}^{(N_1 + \ldots + N_B) \times F}\)</span>.</p></li>
<li><p><strong>batch</strong> (<em>LongTensor</em>) – Batch vector <span class="math notranslate nohighlight">\(\mathbf{b} \in {\{ 0, \ldots,
B-1\}}^N\)</span>, which assigns each node to a specific example.</p></li>
<li><p><strong>size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – The maximum number of clusters in a single
example. This property is useful to obtain a batch-wise dense
representation, <em>e.g.</em> for applying FC layers, but should only be
used if the size of the maximum number of clusters per example is
known in advance. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>(<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">LongTensor</span></code>) if <code class="xref py py-attr docutils literal notranslate"><span class="pre">size</span></code> is
<a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>, else <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="torch_geometric.nn.pool.avg_pool_x">
<code class="sig-name descname">avg_pool_x</code><span class="sig-paren">(</span><em class="sig-param">cluster</em>, <em class="sig-param">x</em>, <em class="sig-param">batch</em>, <em class="sig-param">size=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/pool/avg_pool.html#avg_pool_x"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.pool.avg_pool_x" title="Permalink to this definition">¶</a></dt>
<dd><p>Average pools node features according to the clustering defined in
<code class="xref py py-attr docutils literal notranslate"><span class="pre">cluster</span></code>.
See <a class="reference internal" href="#torch_geometric.nn.pool.max_pool_x" title="torch_geometric.nn.pool.max_pool_x"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch_geometric.nn.pool.max_pool_x()</span></code></a> for more details.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cluster</strong> (<em>LongTensor</em>) – Cluster vector <span class="math notranslate nohighlight">\(\mathbf{c} \in \{ 0,
\ldots, N - 1 \}^N\)</span>, which assigns each node to a specific cluster.</p></li>
<li><p><strong>x</strong> (<em>Tensor</em>) – Node feature matrix
<span class="math notranslate nohighlight">\(\mathbf{X} \in \mathbb{R}^{(N_1 + \ldots + N_B) \times F}\)</span>.</p></li>
<li><p><strong>batch</strong> (<em>LongTensor</em>) – Batch vector <span class="math notranslate nohighlight">\(\mathbf{b} \in {\{ 0, \ldots,
B-1\}}^N\)</span>, which assigns each node to a specific example.</p></li>
<li><p><strong>size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – The maximum number of clusters in a single
example. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>(<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">LongTensor</span></code>) if <code class="xref py py-attr docutils literal notranslate"><span class="pre">size</span></code> is
<a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>, else <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="torch_geometric.nn.pool.graclus">
<code class="sig-name descname">graclus</code><span class="sig-paren">(</span><em class="sig-param">edge_index</em>, <em class="sig-param">weight=None</em>, <em class="sig-param">num_nodes=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/pool/graclus.html#graclus"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.pool.graclus" title="Permalink to this definition">¶</a></dt>
<dd><p>A greedy clustering algorithm from the <a class="reference external" href="http://www.cs.utexas.edu/users/inderjit/public_papers/multilevel_pami.pdf">“Weighted Graph Cuts without
Eigenvectors: A Multilevel Approach”</a> paper of picking an unmarked
vertex and matching it with one of its unmarked neighbors (that maximizes
its edge weight).
The GPU algoithm is adapted from the <a class="reference external" href="http://www.staff.science.uu.nl/~bisse101/Articles/match12.pdf">“A GPU Algorithm for Greedy Graph
Matching”</a>
paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>edge_index</strong> (<em>LongTensor</em>) – The edge indices.</p></li>
<li><p><strong>weight</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – One-dimensional edge weights.
(default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>num_nodes</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – The number of nodes, <em>i.e.</em>
<code class="xref py py-obj docutils literal notranslate"><span class="pre">max_val</span> <span class="pre">+</span> <span class="pre">1</span></code> of <code class="xref py py-attr docutils literal notranslate"><span class="pre">edge_index</span></code>. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">LongTensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="torch_geometric.nn.pool.voxel_grid">
<code class="sig-name descname">voxel_grid</code><span class="sig-paren">(</span><em class="sig-param">pos</em>, <em class="sig-param">batch</em>, <em class="sig-param">size</em>, <em class="sig-param">start=None</em>, <em class="sig-param">end=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/pool/voxel_grid.html#voxel_grid"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.pool.voxel_grid" title="Permalink to this definition">¶</a></dt>
<dd><p>Voxel grid pooling from the, <em>e.g.</em>, <a class="reference external" href="https://arxiv.org/abs/1704.02901">Dynamic Edge-Conditioned Filters
in Convolutional Networks on Graphs</a>
paper, which overlays a regular grid of user-defined size over a point
cloud and clusters all points within the same voxel.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pos</strong> (<em>Tensor</em>) – Node position matrix
<span class="math notranslate nohighlight">\(\mathbf{X} \in \mathbb{R}^{(N_1 + \ldots + N_B) \times D}\)</span>.</p></li>
<li><p><strong>batch</strong> (<em>LongTensor</em>) – Batch vector <span class="math notranslate nohighlight">\(\mathbf{b} \in {\{ 0, \ldots,
B-1\}}^N\)</span>, which assigns each node to a specific example.</p></li>
<li><p><strong>size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em> or </em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>] or </em><em>Tensor</em>) – Size of a voxel (in each dimension).</p></li>
<li><p><strong>start</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em> or </em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>] or </em><em>Tensor</em><em>, </em><em>optional</em>) – Start coordinates of the
grid (in each dimension). If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>, will be set to the
minimum coordinates found in <code class="xref py py-attr docutils literal notranslate"><span class="pre">pos</span></code>. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>end</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em> or </em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>] or </em><em>Tensor</em><em>, </em><em>optional</em>) – End coordinates of the grid
(in each dimension). If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>, will be set to the
maximum coordinates found in <code class="xref py py-attr docutils literal notranslate"><span class="pre">pos</span></code>. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">LongTensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="torch_geometric.nn.pool.fps">
<code class="sig-name descname">fps</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">batch=None</em>, <em class="sig-param">ratio=0.5</em>, <em class="sig-param">random_start=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/pool.html#fps"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.pool.fps" title="Permalink to this definition">¶</a></dt>
<dd><p>“A sampling algorithm from the <a class="reference external" href="https://arxiv.org/abs/1706.02413">“PointNet++: Deep Hierarchical Feature
Learning on Point Sets in a Metric Space”</a> paper, which iteratively samples the
most distant point with regard to the rest points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Node feature matrix
<span class="math notranslate nohighlight">\(\mathbf{X} \in \mathbb{R}^{N \times F}\)</span>.</p></li>
<li><p><strong>batch</strong> (<em>LongTensor</em><em>, </em><em>optional</em>) – Batch vector
<span class="math notranslate nohighlight">\(\mathbf{b} \in {\{ 0, \ldots, B-1\}}^N\)</span>, which assigns each
node to a specific example. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>ratio</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Sampling ratio. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">0.5</span></code>)</p></li>
<li><p><strong>random_start</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, use the first
node in <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> as starting node. (default: obj:<cite>True</cite>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">LongTensor</span></code></p>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">fps</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">index</span> <span class="o">=</span> <span class="n">fps</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch_geometric.nn.pool.knn">
<code class="sig-name descname">knn</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">y</em>, <em class="sig-param">k</em>, <em class="sig-param">batch_x=None</em>, <em class="sig-param">batch_y=None</em>, <em class="sig-param">cosine=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/pool.html#knn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.pool.knn" title="Permalink to this definition">¶</a></dt>
<dd><p>Finds for each element in <code class="xref py py-obj docutils literal notranslate"><span class="pre">y</span></code> the <code class="xref py py-obj docutils literal notranslate"><span class="pre">k</span></code> nearest points in
<code class="xref py py-obj docutils literal notranslate"><span class="pre">x</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Node feature matrix
<span class="math notranslate nohighlight">\(\mathbf{X} \in \mathbb{R}^{N \times F}\)</span>.</p></li>
<li><p><strong>y</strong> (<em>Tensor</em>) – Node feature matrix
<span class="math notranslate nohighlight">\(\mathbf{X} \in \mathbb{R}^{M \times F}\)</span>.</p></li>
<li><p><strong>k</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of neighbors.</p></li>
<li><p><strong>batch_x</strong> (<em>LongTensor</em><em>, </em><em>optional</em>) – Batch vector
<span class="math notranslate nohighlight">\(\mathbf{b} \in {\{ 0, \ldots, B-1\}}^N\)</span>, which assigns each
node to a specific example. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>batch_y</strong> (<em>LongTensor</em><em>, </em><em>optional</em>) – Batch vector
<span class="math notranslate nohighlight">\(\mathbf{b} \in {\{ 0, \ldots, B-1\}}^M\)</span>, which assigns each
node to a specific example. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>cosine</strong> (<em>boolean</em><em>, </em><em>optional</em>) – If <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>, will use the cosine
distance instead of euclidean distance to find nearest neighbors.
(default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">LongTensor</span></code></p>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">knn</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">batch_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">batch_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">assign_index</span> <span class="o">=</span> <span class="n">knn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_y</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch_geometric.nn.pool.knn_graph">
<code class="sig-name descname">knn_graph</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">k</em>, <em class="sig-param">batch=None</em>, <em class="sig-param">loop=False</em>, <em class="sig-param">flow='source_to_target'</em>, <em class="sig-param">cosine=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/pool.html#knn_graph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.pool.knn_graph" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes graph edges to the nearest <code class="xref py py-obj docutils literal notranslate"><span class="pre">k</span></code> points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Node feature matrix
<span class="math notranslate nohighlight">\(\mathbf{X} \in \mathbb{R}^{N \times F}\)</span>.</p></li>
<li><p><strong>k</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of neighbors.</p></li>
<li><p><strong>batch</strong> (<em>LongTensor</em><em>, </em><em>optional</em>) – Batch vector
<span class="math notranslate nohighlight">\(\mathbf{b} \in {\{ 0, \ldots, B-1\}}^N\)</span>, which assigns each
node to a specific example. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>loop</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>, the graph will contain
self-loops. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>)</p></li>
<li><p><strong>flow</strong> (<em>string</em><em>, </em><em>optional</em>) – The flow direction when using in combination
with message passing (<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;source_to_target&quot;</span></code> or
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;target_to_source&quot;</span></code>). (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;source_to_target&quot;</span></code>)</p></li>
<li><p><strong>cosine</strong> (<em>boolean</em><em>, </em><em>optional</em>) – If <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>, will use the cosine
distance instead of euclidean distance to find nearest neighbors.
(default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">LongTensor</span></code></p>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">knn_graph</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">edge_index</span> <span class="o">=</span> <span class="n">knn_graph</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span> <span class="n">loop</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch_geometric.nn.pool.radius">
<code class="sig-name descname">radius</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">y</em>, <em class="sig-param">r</em>, <em class="sig-param">batch_x=None</em>, <em class="sig-param">batch_y=None</em>, <em class="sig-param">max_num_neighbors=32</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/pool.html#radius"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.pool.radius" title="Permalink to this definition">¶</a></dt>
<dd><p>Finds for each element in <code class="xref py py-obj docutils literal notranslate"><span class="pre">y</span></code> all points in <code class="xref py py-obj docutils literal notranslate"><span class="pre">x</span></code> within
distance <code class="xref py py-obj docutils literal notranslate"><span class="pre">r</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Node feature matrix
<span class="math notranslate nohighlight">\(\mathbf{X} \in \mathbb{R}^{N \times F}\)</span>.</p></li>
<li><p><strong>y</strong> (<em>Tensor</em>) – Node feature matrix
<span class="math notranslate nohighlight">\(\mathbf{Y} \in \mathbb{R}^{M \times F}\)</span>.</p></li>
<li><p><strong>r</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The radius.</p></li>
<li><p><strong>batch_x</strong> (<em>LongTensor</em><em>, </em><em>optional</em>) – Batch vector
<span class="math notranslate nohighlight">\(\mathbf{b} \in {\{ 0, \ldots, B-1\}}^N\)</span>, which assigns each
node to a specific example. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>batch_y</strong> (<em>LongTensor</em><em>, </em><em>optional</em>) – Batch vector
<span class="math notranslate nohighlight">\(\mathbf{b} \in {\{ 0, \ldots, B-1\}}^M\)</span>, which assigns each
node to a specific example. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>max_num_neighbors</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – The maximum number of neighbors to
return for each element in <code class="xref py py-obj docutils literal notranslate"><span class="pre">y</span></code>. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">32</span></code>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">LongTensor</span></code></p>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">radius</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">batch_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">batch_y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">assign_index</span> <span class="o">=</span> <span class="n">radius</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_y</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch_geometric.nn.pool.radius_graph">
<code class="sig-name descname">radius_graph</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">r</em>, <em class="sig-param">batch=None</em>, <em class="sig-param">loop=False</em>, <em class="sig-param">max_num_neighbors=32</em>, <em class="sig-param">flow='source_to_target'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/pool.html#radius_graph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.pool.radius_graph" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes graph edges to all points within a given distance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Node feature matrix
<span class="math notranslate nohighlight">\(\mathbf{X} \in \mathbb{R}^{N \times F}\)</span>.</p></li>
<li><p><strong>r</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – The radius.</p></li>
<li><p><strong>batch</strong> (<em>LongTensor</em><em>, </em><em>optional</em>) – Batch vector
<span class="math notranslate nohighlight">\(\mathbf{b} \in {\{ 0, \ldots, B-1\}}^N\)</span>, which assigns each
node to a specific example. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>loop</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>, the graph will contain
self-loops. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>)</p></li>
<li><p><strong>max_num_neighbors</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – The maximum number of neighbors to
return for each element in <code class="xref py py-obj docutils literal notranslate"><span class="pre">y</span></code>. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">32</span></code>)</p></li>
<li><p><strong>flow</strong> (<em>string</em><em>, </em><em>optional</em>) – The flow direction when using in combination
with message passing (<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;source_to_target&quot;</span></code> or
<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;target_to_source&quot;</span></code>). (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;source_to_target&quot;</span></code>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">LongTensor</span></code></p>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">radius_graph</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">edge_index</span> <span class="o">=</span> <span class="n">radius_graph</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span> <span class="n">loop</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch_geometric.nn.pool.nearest">
<code class="sig-name descname">nearest</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">y</em>, <em class="sig-param">batch_x=None</em>, <em class="sig-param">batch_y=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/pool.html#nearest"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.pool.nearest" title="Permalink to this definition">¶</a></dt>
<dd><p>Clusters points in <code class="xref py py-obj docutils literal notranslate"><span class="pre">x</span></code> together which are nearest to a given query
point in <code class="xref py py-obj docutils literal notranslate"><span class="pre">y</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Node feature matrix
<span class="math notranslate nohighlight">\(\mathbf{X} \in \mathbb{R}^{N \times F}\)</span>.</p></li>
<li><p><strong>y</strong> (<em>Tensor</em>) – Node feature matrix
<span class="math notranslate nohighlight">\(\mathbf{Y} \in \mathbb{R}^{M \times F}\)</span>.</p></li>
<li><p><strong>batch_x</strong> (<em>LongTensor</em><em>, </em><em>optional</em>) – Batch vector
<span class="math notranslate nohighlight">\(\mathbf{b} \in {\{ 0, \ldots, B-1\}}^N\)</span>, which assigns each
node to a specific example. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>batch_y</strong> (<em>LongTensor</em><em>, </em><em>optional</em>) – Batch vector
<span class="math notranslate nohighlight">\(\mathbf{b} \in {\{ 0, \ldots, B-1\}}^M\)</span>, which assigns each
node to a specific example. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">LongTensor</span></code></p>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">nearest</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">batch_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">batch_y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">cluster</span> <span class="o">=</span> <span class="n">nearest</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_y</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="module-torch_geometric.nn.dense.diff_pool">
<span id="dense-pooling-layers"></span><h2><a class="toc-backref" href="#id16">Dense Pooling Layers</a><a class="headerlink" href="#module-torch_geometric.nn.dense.diff_pool" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="torch_geometric.nn.dense.diff_pool.dense_diff_pool">
<code class="sig-name descname">dense_diff_pool</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">adj</em>, <em class="sig-param">s</em>, <em class="sig-param">mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/dense/diff_pool.html#dense_diff_pool"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.dense.diff_pool.dense_diff_pool" title="Permalink to this definition">¶</a></dt>
<dd><p>Differentiable pooling operator from the <a class="reference external" href="https://arxiv.org/abs/1806.08804">“Hierarchical Graph
Representation Learning with Differentiable Pooling”</a> paper</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{X}^{\prime} &amp;= {\mathrm{softmax}(\mathbf{S})}^{\top} \cdot
\mathbf{X}\\\mathbf{A}^{\prime} &amp;= {\mathrm{softmax}(\mathbf{S})}^{\top} \cdot
\mathbf{A} \cdot \mathrm{softmax}(\mathbf{S})\end{aligned}\end{align} \]</div>
<p>based on dense learned assignments <span class="math notranslate nohighlight">\(\mathbf{S} \in \mathbb{R}^{B
\times N \times C}\)</span>.
Returns pooled node feature matrix, coarsened adjacency matrix and two
auxiliary objectives: (1) The link prediction loss</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}_{LP} = {\| \mathbf{A} -
\mathrm{softmax}(\mathbf{S}) {\mathrm{softmax}(\mathbf{S})}^{\top}
\|}_F,\]</div>
<p>and the entropy regularization</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}_E = \frac{1}{N} \sum_{n=1}^N H(\mathbf{S}_n).\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Node feature tensor <span class="math notranslate nohighlight">\(\mathbf{X} \in \mathbb{R}^{B
\times N \times F}\)</span> with batch-size <span class="math notranslate nohighlight">\(B\)</span>, (maximum)
number of nodes <span class="math notranslate nohighlight">\(N\)</span> for each graph, and feature dimension
<span class="math notranslate nohighlight">\(F\)</span>.</p></li>
<li><p><strong>adj</strong> (<em>Tensor</em>) – Adjacency tensor <span class="math notranslate nohighlight">\(\mathbf{A} \in \mathbb{R}^{B
\times N \times N}\)</span>.</p></li>
<li><p><strong>s</strong> (<em>Tensor</em>) – Assignment tensor <span class="math notranslate nohighlight">\(\mathbf{S} \in \mathbb{R}^{B
\times N \times C}\)</span> with number of clusters <span class="math notranslate nohighlight">\(C\)</span>. The softmax
does not have to be applied beforehand, since it is executed
within this method.</p></li>
<li><p><strong>mask</strong> (<em>BoolTensor</em><em>, </em><em>optional</em>) – Mask matrix
<span class="math notranslate nohighlight">\(\mathbf{M} \in {\{ 0, 1 \}}^{B \times N}\)</span> indicating
the valid nodes for each graph. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>(<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>,
<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>)</p>
</dd>
</dl>
</dd></dl>

<span class="target" id="module-torch_geometric.nn.dense.mincut_pool"></span><dl class="function">
<dt id="torch_geometric.nn.dense.mincut_pool.dense_mincut_pool">
<code class="sig-name descname">dense_mincut_pool</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">adj</em>, <em class="sig-param">s</em>, <em class="sig-param">mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/dense/mincut_pool.html#dense_mincut_pool"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.dense.mincut_pool.dense_mincut_pool" title="Permalink to this definition">¶</a></dt>
<dd><p>MinCUt pooling operator from the <a class="reference external" href="https://arxiv.org/abs/1907.00481">“Mincut Pooling in Graph Neural
Networks”</a> paper</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\mathbf{X}^{\prime} &amp;= {\mathrm{softmax}(\mathbf{S})}^{\top} \cdot
\mathbf{X}\\\mathbf{A}^{\prime} &amp;= {\mathrm{softmax}(\mathbf{S})}^{\top} \cdot
\mathbf{A} \cdot \mathrm{softmax}(\mathbf{S})\end{aligned}\end{align} \]</div>
<p>based on dense learned assignments <span class="math notranslate nohighlight">\(\mathbf{S} \in \mathbb{R}^{B
\times N \times C}\)</span>.
Returns pooled node feature matrix, coarsened symmetrically normalized
adjacency matrix and two auxiliary objectives: (1) The minCUT loss</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}_c = - \frac{\mathrm{Tr}(\mathbf{S}^{\top} \mathbf{A}
\mathbf{S})} {\mathrm{Tr}(\mathbf{S}^{\top} \mathbf{D}
\mathbf{S})}\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{D}\)</span> is the degree matrix, and (2) the orthogonality
loss</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}_o = {\left\| \frac{\mathbf{S}^{\top} \mathbf{S}}
{{\|\mathbf{S}^{\top} \mathbf{S}\|}_F} -\frac{\mathbf{I}_C}{\sqrt{C}}
\right\|}_F.\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Node feature tensor <span class="math notranslate nohighlight">\(\mathbf{X} \in \mathbb{R}^{B
\times N \times F}\)</span> with batch-size <span class="math notranslate nohighlight">\(B\)</span>, (maximum)
number of nodes <span class="math notranslate nohighlight">\(N\)</span> for each graph, and feature dimension
<span class="math notranslate nohighlight">\(F\)</span>.</p></li>
<li><p><strong>adj</strong> (<em>Tensor</em>) – Symmetrically normalized adjacency tensor
<span class="math notranslate nohighlight">\(\mathbf{A} \in \mathbb{R}^{B \times N \times N}\)</span>.</p></li>
<li><p><strong>s</strong> (<em>Tensor</em>) – Assignment tensor <span class="math notranslate nohighlight">\(\mathbf{S} \in \mathbb{R}^{B
\times N \times C}\)</span> with number of clusters <span class="math notranslate nohighlight">\(C\)</span>. The softmax
does not have to be applied beforehand, since it is executed
within this method.</p></li>
<li><p><strong>mask</strong> (<em>BoolTensor</em><em>, </em><em>optional</em>) – Mask matrix
<span class="math notranslate nohighlight">\(\mathbf{M} \in {\{ 0, 1 \}}^{B \times N}\)</span> indicating
the valid nodes for each graph. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>(<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>,
<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>)</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-torch_geometric.nn.unpool">
<span id="unpooling-layers"></span><h2><a class="toc-backref" href="#id17">Unpooling Layers</a><a class="headerlink" href="#module-torch_geometric.nn.unpool" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="torch_geometric.nn.unpool.knn_interpolate">
<code class="sig-name descname">knn_interpolate</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">pos_x</em>, <em class="sig-param">pos_y</em>, <em class="sig-param">batch_x=None</em>, <em class="sig-param">batch_y=None</em>, <em class="sig-param">k=3</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/unpool/knn_interpolate.html#knn_interpolate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.unpool.knn_interpolate" title="Permalink to this definition">¶</a></dt>
<dd><p>The k-NN interpolation from the <a class="reference external" href="https://arxiv.org/abs/1706.02413">“PointNet++: Deep Hierarchical
Feature Learning on Point Sets in a Metric Space”</a> paper.
For each point <span class="math notranslate nohighlight">\(y\)</span> with position <span class="math notranslate nohighlight">\(\mathbf{p}(y)\)</span>, its
interpolated features <span class="math notranslate nohighlight">\(\mathbf{f}(y)\)</span> are given by</p>
<div class="math notranslate nohighlight">
\[\mathbf{f}(y) = \frac{\sum_{i=1}^k w(x_i) \mathbf{f}(x_i)}{\sum_{i=1}^k
w(x_i)} \textrm{, where } w(x_i) = \frac{1}{d(\mathbf{p}(y),
\mathbf{p}(x_i))^2}\]</div>
<p>and <span class="math notranslate nohighlight">\(\{ x_1, \ldots, x_k \}\)</span> denoting the <span class="math notranslate nohighlight">\(k\)</span> nearest points
to <span class="math notranslate nohighlight">\(y\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – Node feature matrix
<span class="math notranslate nohighlight">\(\mathbf{X} \in \mathbb{R}^{N \times F}\)</span>.</p></li>
<li><p><strong>pos_x</strong> (<em>Tensor</em>) – Node position matrix
<span class="math notranslate nohighlight">\(\in \mathbb{R}^{N \times d}\)</span>.</p></li>
<li><p><strong>pos_y</strong> (<em>Tensor</em>) – Upsampled node position matrix
<span class="math notranslate nohighlight">\(\in \mathbb{R}^{M \times d}\)</span>.</p></li>
<li><p><strong>batch_x</strong> (<em>LongTensor</em><em>, </em><em>optional</em>) – Batch vector
<span class="math notranslate nohighlight">\(\mathbf{b_x} \in {\{ 0, \ldots, B-1\}}^N\)</span>, which assigns
each node from <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> to a specific example.
(default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>batch_y</strong> (<em>LongTensor</em><em>, </em><em>optional</em>) – Batch vector
<span class="math notranslate nohighlight">\(\mathbf{b_y} \in {\{ 0, \ldots, B-1\}}^N\)</span>, which assigns
each node from <span class="math notranslate nohighlight">\(\mathbf{Y}\)</span> to a specific example.
(default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>k</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – Number of neighbors. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">3</span></code>)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-torch_geometric.nn.models">
<span id="models"></span><h2><a class="toc-backref" href="#id18">Models</a><a class="headerlink" href="#module-torch_geometric.nn.models" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch_geometric.nn.models.JumpingKnowledge">
<em class="property">class </em><code class="sig-name descname">JumpingKnowledge</code><span class="sig-paren">(</span><em class="sig-param">mode</em>, <em class="sig-param">channels=None</em>, <em class="sig-param">num_layers=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/jumping_knowledge.html#JumpingKnowledge"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.JumpingKnowledge" title="Permalink to this definition">¶</a></dt>
<dd><p>The Jumping Knowledge layer aggregation module from the
<a class="reference external" href="https://arxiv.org/abs/1806.03536">“Representation Learning on Graphs with Jumping Knowledge Networks”</a> paper based on either
<strong>concatenation</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;cat&quot;</span></code>)</p>
<div class="math notranslate nohighlight">
\[\mathbf{x}_v^{(1)} \, \Vert \, \ldots \, \Vert \, \mathbf{x}_v^{(T)}\]</div>
<p><strong>max pooling</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;max&quot;</span></code>)</p>
<div class="math notranslate nohighlight">
\[\max \left( \mathbf{x}_v^{(1)}, \ldots, \mathbf{x}_v^{(T)} \right)\]</div>
<p>or <strong>weighted summation</strong></p>
<div class="math notranslate nohighlight">
\[\sum_{t=1}^T \alpha_v^{(t)} \mathbf{x}_v^{(t)}\]</div>
<p>with attention scores <span class="math notranslate nohighlight">\(\alpha_v^{(t)}\)</span> obtained from a bi-directional
LSTM (<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;lstm&quot;</span></code>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mode</strong> (<em>string</em>) – The aggregation scheme to use
(<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;cat&quot;</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;max&quot;</span></code> or <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;lstm&quot;</span></code>).</p></li>
<li><p><strong>channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – The number of channels per representation.
Needs to be only set for LSTM-style aggregation.
(default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>num_layers</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – The number of layers to aggregate. Needs to
be only set for LSTM-style aggregation. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.models.JumpingKnowledge.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">xs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/jumping_knowledge.html#JumpingKnowledge.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.JumpingKnowledge.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Aggregates representations across different layers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>xs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.8)"><em>tuple</em></a>) – List containing layer-wise representations.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.models.JumpingKnowledge.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/jumping_knowledge.html#JumpingKnowledge.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.JumpingKnowledge.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.models.Node2Vec">
<em class="property">class </em><code class="sig-name descname">Node2Vec</code><span class="sig-paren">(</span><em class="sig-param">num_nodes</em>, <em class="sig-param">embedding_dim</em>, <em class="sig-param">walk_length</em>, <em class="sig-param">context_size</em>, <em class="sig-param">walks_per_node=1</em>, <em class="sig-param">p=1</em>, <em class="sig-param">q=1</em>, <em class="sig-param">num_negative_samples=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/node2vec.html#Node2Vec"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.Node2Vec" title="Permalink to this definition">¶</a></dt>
<dd><p>The Node2Vec model from the
<a class="reference external" href="https://arxiv.org/abs/1607.00653">“node2vec: Scalable Feature Learning for Networks”</a> paper where random walks of
length <code class="xref py py-obj docutils literal notranslate"><span class="pre">walk_length</span></code> are sampled in a given graph, and node embeddings
are learned via negative sampling optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_nodes</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of nodes.</p></li>
<li><p><strong>embedding_dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The size of each embedding vector.</p></li>
<li><p><strong>walk_length</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The walk length.</p></li>
<li><p><strong>context_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The actual context size which is considered for
positive samples. This parameter increases the effective sampling
rate by reusing samples across different source nodes.</p></li>
<li><p><strong>walks_per_node</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – The number of walks to sample for each
node. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">1</span></code>)</p></li>
<li><p><strong>p</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Likelihood of immediately revisiting a node in the
walk. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">1</span></code>)</p></li>
<li><p><strong>q</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Control parameter to interpolate between
breadth-first strategy and depth-first strategy (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">1</span></code>)</p></li>
<li><p><strong>num_negative_samples</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – The number of negative samples to
use for each node. If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>, this parameter gets set
to <code class="xref py py-obj docutils literal notranslate"><span class="pre">context_size</span> <span class="pre">-</span> <span class="pre">1</span></code>. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.models.Node2Vec.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">subset</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/node2vec.html#Node2Vec.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.Node2Vec.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the embeddings for the nodes in <code class="xref py py-obj docutils literal notranslate"><span class="pre">subset</span></code>.</p>
</dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.models.Node2Vec.loss">
<code class="sig-name descname">loss</code><span class="sig-paren">(</span><em class="sig-param">edge_index</em>, <em class="sig-param">subset=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/node2vec.html#Node2Vec.loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.Node2Vec.loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the loss for the nodes in <code class="xref py py-obj docutils literal notranslate"><span class="pre">subset</span></code> with negative
sampling.</p>
</dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.models.Node2Vec.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/node2vec.html#Node2Vec.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.Node2Vec.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.models.Node2Vec.test">
<code class="sig-name descname">test</code><span class="sig-paren">(</span><em class="sig-param">train_z</em>, <em class="sig-param">train_y</em>, <em class="sig-param">test_z</em>, <em class="sig-param">test_y</em>, <em class="sig-param">solver='lbfgs'</em>, <em class="sig-param">multi_class='auto'</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/node2vec.html#Node2Vec.test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.Node2Vec.test" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates latent space quality via a logistic regression downstream
task.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.models.DeepGraphInfomax">
<em class="property">class </em><code class="sig-name descname">DeepGraphInfomax</code><span class="sig-paren">(</span><em class="sig-param">hidden_channels</em>, <em class="sig-param">encoder</em>, <em class="sig-param">summary</em>, <em class="sig-param">corruption</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/deep_graph_infomax.html#DeepGraphInfomax"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.DeepGraphInfomax" title="Permalink to this definition">¶</a></dt>
<dd><p>The Deep Graph Infomax model from the
<a class="reference external" href="https://arxiv.org/abs/1809.10341">“Deep Graph Infomax”</a>
paper based on user-defined encoder and summary model <span class="math notranslate nohighlight">\(\mathcal{E}\)</span>
and <span class="math notranslate nohighlight">\(\mathcal{R}\)</span> respectively, and a corruption function
<span class="math notranslate nohighlight">\(\mathcal{C}\)</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hidden_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The latent space dimensionality.</p></li>
<li><p><strong>encoder</strong> (<em>Module</em>) – The encoder module <span class="math notranslate nohighlight">\(\mathcal{E}\)</span>.</p></li>
<li><p><strong>summary</strong> (<em>callable</em>) – The readout function <span class="math notranslate nohighlight">\(\mathcal{R}\)</span>.</p></li>
<li><p><strong>corruption</strong> (<em>callable</em>) – The corruption function <span class="math notranslate nohighlight">\(\mathcal{C}\)</span>.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.models.DeepGraphInfomax.discriminate">
<code class="sig-name descname">discriminate</code><span class="sig-paren">(</span><em class="sig-param">z</em>, <em class="sig-param">summary</em>, <em class="sig-param">sigmoid=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/deep_graph_infomax.html#DeepGraphInfomax.discriminate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.DeepGraphInfomax.discriminate" title="Permalink to this definition">¶</a></dt>
<dd><p>Given the patch-summary pair <code class="xref py py-obj docutils literal notranslate"><span class="pre">z</span></code> and <code class="xref py py-obj docutils literal notranslate"><span class="pre">summary</span></code>, computes
the probability scores assigned to this patch-summary pair.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z</strong> (<em>Tensor</em>) – The latent space.</p></li>
<li><p><strong>sigmoid</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, does not apply
the logistic sigmoid function to the output.
(default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.models.DeepGraphInfomax.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/deep_graph_infomax.html#DeepGraphInfomax.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.DeepGraphInfomax.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the latent space for the input arguments, their
corruptions and their summary representation.</p>
</dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.models.DeepGraphInfomax.loss">
<code class="sig-name descname">loss</code><span class="sig-paren">(</span><em class="sig-param">pos_z</em>, <em class="sig-param">neg_z</em>, <em class="sig-param">summary</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/deep_graph_infomax.html#DeepGraphInfomax.loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.DeepGraphInfomax.loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the mutal information maximization objective.</p>
</dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.models.DeepGraphInfomax.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/deep_graph_infomax.html#DeepGraphInfomax.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.DeepGraphInfomax.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.models.DeepGraphInfomax.test">
<code class="sig-name descname">test</code><span class="sig-paren">(</span><em class="sig-param">train_z</em>, <em class="sig-param">train_y</em>, <em class="sig-param">test_z</em>, <em class="sig-param">test_y</em>, <em class="sig-param">solver='lbfgs'</em>, <em class="sig-param">multi_class='auto'</em>, <em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/deep_graph_infomax.html#DeepGraphInfomax.test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.DeepGraphInfomax.test" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates latent space quality via a logistic regression downstream
task.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.models.InnerProductDecoder">
<em class="property">class </em><code class="sig-name descname">InnerProductDecoder</code><a class="reference internal" href="../_modules/torch_geometric/nn/models/autoencoder.html#InnerProductDecoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.InnerProductDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>The inner product decoder from the <a class="reference external" href="https://arxiv.org/abs/1611.07308">“Variational Graph Auto-Encoders”</a> paper</p>
<div class="math notranslate nohighlight">
\[\sigma(\mathbf{Z}\mathbf{Z}^{\top})\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{Z} \in \mathbb{R}^{N \times d}\)</span> denotes the latent
space produced by the encoder.</p>
<dl class="method">
<dt id="torch_geometric.nn.models.InnerProductDecoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">z</em>, <em class="sig-param">edge_index</em>, <em class="sig-param">sigmoid=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/autoencoder.html#InnerProductDecoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.InnerProductDecoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Decodes the latent variables <code class="xref py py-obj docutils literal notranslate"><span class="pre">z</span></code> into edge probabilities for
the given node-pairs <code class="xref py py-obj docutils literal notranslate"><span class="pre">edge_index</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z</strong> (<em>Tensor</em>) – The latent space <span class="math notranslate nohighlight">\(\mathbf{Z}\)</span>.</p></li>
<li><p><strong>sigmoid</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, does not apply
the logistic sigmoid function to the output.
(default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.models.InnerProductDecoder.forward_all">
<code class="sig-name descname">forward_all</code><span class="sig-paren">(</span><em class="sig-param">z</em>, <em class="sig-param">sigmoid=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/autoencoder.html#InnerProductDecoder.forward_all"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.InnerProductDecoder.forward_all" title="Permalink to this definition">¶</a></dt>
<dd><p>Decodes the latent variables <code class="xref py py-obj docutils literal notranslate"><span class="pre">z</span></code> into a probabilistic dense
adjacency matrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z</strong> (<em>Tensor</em>) – The latent space <span class="math notranslate nohighlight">\(\mathbf{Z}\)</span>.</p></li>
<li><p><strong>sigmoid</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, does not apply
the logistic sigmoid function to the output.
(default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.models.GAE">
<em class="property">class </em><code class="sig-name descname">GAE</code><span class="sig-paren">(</span><em class="sig-param">encoder</em>, <em class="sig-param">decoder=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/autoencoder.html#GAE"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.GAE" title="Permalink to this definition">¶</a></dt>
<dd><p>The Graph Auto-Encoder model from the
<a class="reference external" href="https://arxiv.org/abs/1611.07308">“Variational Graph Auto-Encoders”</a>
paper based on user-defined encoder and decoder models.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>encoder</strong> (<em>Module</em>) – The encoder module.</p></li>
<li><p><strong>decoder</strong> (<em>Module</em><em>, </em><em>optional</em>) – The decoder module. If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>,
will default to the
<a class="reference internal" href="#torch_geometric.nn.models.InnerProductDecoder" title="torch_geometric.nn.models.InnerProductDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.models.InnerProductDecoder</span></code></a>.
(default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.models.GAE.decode">
<code class="sig-name descname">decode</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/autoencoder.html#GAE.decode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.GAE.decode" title="Permalink to this definition">¶</a></dt>
<dd><p>Runs the decoder and computes edge probabilities.</p>
</dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.models.GAE.encode">
<code class="sig-name descname">encode</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/autoencoder.html#GAE.encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.GAE.encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Runs the encoder and computes node-wise latent variables.</p>
</dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.models.GAE.recon_loss">
<code class="sig-name descname">recon_loss</code><span class="sig-paren">(</span><em class="sig-param">z</em>, <em class="sig-param">pos_edge_index</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/autoencoder.html#GAE.recon_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.GAE.recon_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Given latent variables <code class="xref py py-obj docutils literal notranslate"><span class="pre">z</span></code>, computes the binary cross
entropy loss for positive edges <code class="xref py py-obj docutils literal notranslate"><span class="pre">pos_edge_index</span></code> and negative
sampled edges.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z</strong> (<em>Tensor</em>) – The latent space <span class="math notranslate nohighlight">\(\mathbf{Z}\)</span>.</p></li>
<li><p><strong>pos_edge_index</strong> (<em>LongTensor</em>) – The positive edges to train against.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.models.GAE.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/autoencoder.html#GAE.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.GAE.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.models.GAE.test">
<code class="sig-name descname">test</code><span class="sig-paren">(</span><em class="sig-param">z</em>, <em class="sig-param">pos_edge_index</em>, <em class="sig-param">neg_edge_index</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/autoencoder.html#GAE.test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.GAE.test" title="Permalink to this definition">¶</a></dt>
<dd><p>Given latent variables <code class="xref py py-obj docutils literal notranslate"><span class="pre">z</span></code>, positive edges
<code class="xref py py-obj docutils literal notranslate"><span class="pre">pos_edge_index</span></code> and negative edges <code class="xref py py-obj docutils literal notranslate"><span class="pre">neg_edge_index</span></code>,
computes area under the ROC curve (AUC) and average precision (AP)
scores.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z</strong> (<em>Tensor</em>) – The latent space <span class="math notranslate nohighlight">\(\mathbf{Z}\)</span>.</p></li>
<li><p><strong>pos_edge_index</strong> (<em>LongTensor</em>) – The positive edges to evaluate
against.</p></li>
<li><p><strong>neg_edge_index</strong> (<em>LongTensor</em>) – The negative edges to evaluate
against.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.models.VGAE">
<em class="property">class </em><code class="sig-name descname">VGAE</code><span class="sig-paren">(</span><em class="sig-param">encoder</em>, <em class="sig-param">decoder=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/autoencoder.html#VGAE"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.VGAE" title="Permalink to this definition">¶</a></dt>
<dd><p>The Variational Graph Auto-Encoder model from the
<a class="reference external" href="https://arxiv.org/abs/1611.07308">“Variational Graph Auto-Encoders”</a>
paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>encoder</strong> (<em>Module</em>) – The encoder module to compute <span class="math notranslate nohighlight">\(\mu\)</span> and
<span class="math notranslate nohighlight">\(\log\sigma^2\)</span>.</p></li>
<li><p><strong>decoder</strong> (<em>Module</em><em>, </em><em>optional</em>) – The decoder module. If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>,
will default to the
<a class="reference internal" href="#torch_geometric.nn.models.InnerProductDecoder" title="torch_geometric.nn.models.InnerProductDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.models.InnerProductDecoder</span></code></a>.
(default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.models.VGAE.encode">
<code class="sig-name descname">encode</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/autoencoder.html#VGAE.encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.VGAE.encode" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.models.VGAE.kl_loss">
<code class="sig-name descname">kl_loss</code><span class="sig-paren">(</span><em class="sig-param">mu=None</em>, <em class="sig-param">logvar=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/autoencoder.html#VGAE.kl_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.VGAE.kl_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the KL loss, either for the passed arguments <code class="xref py py-obj docutils literal notranslate"><span class="pre">mu</span></code>
and <code class="xref py py-obj docutils literal notranslate"><span class="pre">logvar</span></code>, or based on latent variables from last encoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mu</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – The latent space for <span class="math notranslate nohighlight">\(\mu\)</span>. If set to
<a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>, uses the last computation of <span class="math notranslate nohighlight">\(mu\)</span>.
(default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
<li><p><strong>logvar</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – The latent space for
<span class="math notranslate nohighlight">\(\log\sigma^2\)</span>.  If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>, uses the last
computation of <span class="math notranslate nohighlight">\(\log\sigma^2\)</span>.(default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.models.VGAE.reparametrize">
<code class="sig-name descname">reparametrize</code><span class="sig-paren">(</span><em class="sig-param">mu</em>, <em class="sig-param">logvar</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/autoencoder.html#VGAE.reparametrize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.VGAE.reparametrize" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.models.ARGA">
<em class="property">class </em><code class="sig-name descname">ARGA</code><span class="sig-paren">(</span><em class="sig-param">encoder</em>, <em class="sig-param">discriminator</em>, <em class="sig-param">decoder=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/autoencoder.html#ARGA"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.ARGA" title="Permalink to this definition">¶</a></dt>
<dd><p>The Adversarially Regularized Graph Auto-Encoder model from the
<a class="reference external" href="https://arxiv.org/abs/1802.04407">“Adversarially Regularized Graph Autoencoder for Graph Embedding”</a> paper.
paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>encoder</strong> (<em>Module</em>) – The encoder module.</p></li>
<li><p><strong>discriminator</strong> (<em>Module</em>) – The discriminator module.</p></li>
<li><p><strong>decoder</strong> (<em>Module</em><em>, </em><em>optional</em>) – The decoder module. If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>,
will default to the
<a class="reference internal" href="#torch_geometric.nn.models.InnerProductDecoder" title="torch_geometric.nn.models.InnerProductDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.models.InnerProductDecoder</span></code></a>.
(default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.models.ARGA.discriminator_loss">
<code class="sig-name descname">discriminator_loss</code><span class="sig-paren">(</span><em class="sig-param">z</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/autoencoder.html#ARGA.discriminator_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.ARGA.discriminator_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the loss of the discriminator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>z</strong> (<em>Tensor</em>) – The latent space <span class="math notranslate nohighlight">\(\mathbf{Z}\)</span>.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.models.ARGA.reg_loss">
<code class="sig-name descname">reg_loss</code><span class="sig-paren">(</span><em class="sig-param">z</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/autoencoder.html#ARGA.reg_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.ARGA.reg_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the regularization loss of the encoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>z</strong> (<em>Tensor</em>) – The latent space <span class="math notranslate nohighlight">\(\mathbf{Z}\)</span>.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.models.ARGA.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/autoencoder.html#ARGA.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.ARGA.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.models.ARGVA">
<em class="property">class </em><code class="sig-name descname">ARGVA</code><span class="sig-paren">(</span><em class="sig-param">encoder</em>, <em class="sig-param">discriminator</em>, <em class="sig-param">decoder=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/autoencoder.html#ARGVA"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.ARGVA" title="Permalink to this definition">¶</a></dt>
<dd><p>The Adversarially Regularized Variational Graph Auto-Encoder model from
the <a class="reference external" href="https://arxiv.org/abs/1802.04407">“Adversarially Regularized Graph Autoencoder for Graph Embedding”</a> paper.
paper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>encoder</strong> (<em>Module</em>) – The encoder module to compute <span class="math notranslate nohighlight">\(\mu\)</span> and
<span class="math notranslate nohighlight">\(\log\sigma^2\)</span>.</p></li>
<li><p><strong>discriminator</strong> (<em>Module</em>) – The discriminator module.</p></li>
<li><p><strong>decoder</strong> (<em>Module</em><em>, </em><em>optional</em>) – The decoder module. If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>,
will default to the
<a class="reference internal" href="#torch_geometric.nn.models.InnerProductDecoder" title="torch_geometric.nn.models.InnerProductDecoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.models.InnerProductDecoder</span></code></a>.
(default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.models.ARGVA.encode">
<code class="sig-name descname">encode</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/autoencoder.html#ARGVA.encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.ARGVA.encode" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.models.ARGVA.kl_loss">
<code class="sig-name descname">kl_loss</code><span class="sig-paren">(</span><em class="sig-param">mu=None</em>, <em class="sig-param">logvar=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/autoencoder.html#ARGVA.kl_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.ARGVA.kl_loss" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.models.ARGVA.reparametrize">
<code class="sig-name descname">reparametrize</code><span class="sig-paren">(</span><em class="sig-param">mu</em>, <em class="sig-param">logvar</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/autoencoder.html#ARGVA.reparametrize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.ARGVA.reparametrize" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.models.SignedGCN">
<em class="property">class </em><code class="sig-name descname">SignedGCN</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">hidden_channels</em>, <em class="sig-param">num_layers</em>, <em class="sig-param">lamb=5</em>, <em class="sig-param">bias=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/signed_gcn.html#SignedGCN"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.SignedGCN" title="Permalink to this definition">¶</a></dt>
<dd><p>The signed graph convolutional network model from the <a class="reference external" href="https://arxiv.org/abs/1808.06354">“Signed Graph
Convolutional Network”</a> paper.
Internally, this module uses the
<a class="reference internal" href="#torch_geometric.nn.conv.SignedConv" title="torch_geometric.nn.conv.SignedConv"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.nn.conv.SignedConv</span></code></a> operator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each input sample.</p></li>
<li><p><strong>hidden_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each hidden sample.</p></li>
<li><p><strong>num_layers</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of layers.</p></li>
<li><p><strong>lamb</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – Balances the contributions of the overall
objective. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">5</span></code>)</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, all layers will not
learn an additive bias. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.models.SignedGCN.create_spectral_features">
<code class="sig-name descname">create_spectral_features</code><span class="sig-paren">(</span><em class="sig-param">pos_edge_index</em>, <em class="sig-param">neg_edge_index</em>, <em class="sig-param">num_nodes=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/signed_gcn.html#SignedGCN.create_spectral_features"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.SignedGCN.create_spectral_features" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates <code class="xref py py-obj docutils literal notranslate"><span class="pre">in_channels</span></code> spectral node features based on
positive and negative edges.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pos_edge_index</strong> (<em>LongTensor</em>) – The positive edge indices.</p></li>
<li><p><strong>neg_edge_index</strong> (<em>LongTensor</em>) – The negative edge indices.</p></li>
<li><p><strong>num_nodes</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – The number of nodes, <em>i.e.</em>
<code class="xref py py-obj docutils literal notranslate"><span class="pre">max_val</span> <span class="pre">+</span> <span class="pre">1</span></code> of <code class="xref py py-attr docutils literal notranslate"><span class="pre">pos_edge_index</span></code> and
<code class="xref py py-attr docutils literal notranslate"><span class="pre">neg_edge_index</span></code>. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code></a>)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.models.SignedGCN.discriminate">
<code class="sig-name descname">discriminate</code><span class="sig-paren">(</span><em class="sig-param">z</em>, <em class="sig-param">edge_index</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/signed_gcn.html#SignedGCN.discriminate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.SignedGCN.discriminate" title="Permalink to this definition">¶</a></dt>
<dd><p>Given node embeddings <code class="xref py py-obj docutils literal notranslate"><span class="pre">z</span></code>, classifies the link relation
between node pairs <code class="xref py py-obj docutils literal notranslate"><span class="pre">edge_index</span></code> to be either positive,
negative or non-existent.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – The input node features.</p></li>
<li><p><strong>edge_index</strong> (<em>LongTensor</em>) – The edge indices.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.models.SignedGCN.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">pos_edge_index</em>, <em class="sig-param">neg_edge_index</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/signed_gcn.html#SignedGCN.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.SignedGCN.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes node embeddings <code class="xref py py-obj docutils literal notranslate"><span class="pre">z</span></code> based on positive edges
<code class="xref py py-obj docutils literal notranslate"><span class="pre">pos_edge_index</span></code> and negative edges <code class="xref py py-obj docutils literal notranslate"><span class="pre">neg_edge_index</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – The input node features.</p></li>
<li><p><strong>pos_edge_index</strong> (<em>LongTensor</em>) – The positive edge indices.</p></li>
<li><p><strong>neg_edge_index</strong> (<em>LongTensor</em>) – The negative edge indices.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.models.SignedGCN.loss">
<code class="sig-name descname">loss</code><span class="sig-paren">(</span><em class="sig-param">z</em>, <em class="sig-param">pos_edge_index</em>, <em class="sig-param">neg_edge_index</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/signed_gcn.html#SignedGCN.loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.SignedGCN.loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the overall objective.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z</strong> (<em>Tensor</em>) – The node embeddings.</p></li>
<li><p><strong>pos_edge_index</strong> (<em>LongTensor</em>) – The positive edge indices.</p></li>
<li><p><strong>neg_edge_index</strong> (<em>LongTensor</em>) – The negative edge indices.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.models.SignedGCN.neg_embedding_loss">
<code class="sig-name descname">neg_embedding_loss</code><span class="sig-paren">(</span><em class="sig-param">z</em>, <em class="sig-param">neg_edge_index</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/signed_gcn.html#SignedGCN.neg_embedding_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.SignedGCN.neg_embedding_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the triplet loss between negative node pairs and sampled
non-node pairs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z</strong> (<em>Tensor</em>) – The node embeddings.</p></li>
<li><p><strong>neg_edge_index</strong> (<em>LongTensor</em>) – The negative edge indices.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.models.SignedGCN.nll_loss">
<code class="sig-name descname">nll_loss</code><span class="sig-paren">(</span><em class="sig-param">z</em>, <em class="sig-param">pos_edge_index</em>, <em class="sig-param">neg_edge_index</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/signed_gcn.html#SignedGCN.nll_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.SignedGCN.nll_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the discriminator loss based on node embeddings <code class="xref py py-obj docutils literal notranslate"><span class="pre">z</span></code>,
and positive edges <code class="xref py py-obj docutils literal notranslate"><span class="pre">pos_edge_index</span></code> and negative nedges
<code class="xref py py-obj docutils literal notranslate"><span class="pre">neg_edge_index</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z</strong> (<em>Tensor</em>) – The node embeddings.</p></li>
<li><p><strong>pos_edge_index</strong> (<em>LongTensor</em>) – The positive edge indices.</p></li>
<li><p><strong>neg_edge_index</strong> (<em>LongTensor</em>) – The negative edge indices.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.models.SignedGCN.pos_embedding_loss">
<code class="sig-name descname">pos_embedding_loss</code><span class="sig-paren">(</span><em class="sig-param">z</em>, <em class="sig-param">pos_edge_index</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/signed_gcn.html#SignedGCN.pos_embedding_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.SignedGCN.pos_embedding_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the triplet loss between positive node pairs and sampled
non-node pairs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z</strong> (<em>Tensor</em>) – The node embeddings.</p></li>
<li><p><strong>pos_edge_index</strong> (<em>LongTensor</em>) – The positive edge indices.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.models.SignedGCN.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/signed_gcn.html#SignedGCN.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.SignedGCN.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.models.SignedGCN.split_edges">
<code class="sig-name descname">split_edges</code><span class="sig-paren">(</span><em class="sig-param">edge_index</em>, <em class="sig-param">test_ratio=0.2</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/signed_gcn.html#SignedGCN.split_edges"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.SignedGCN.split_edges" title="Permalink to this definition">¶</a></dt>
<dd><p>Splits the edges <code class="xref py py-obj docutils literal notranslate"><span class="pre">edge_index</span></code> into train and test edges.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>edge_index</strong> (<em>LongTensor</em>) – The edge indices.</p></li>
<li><p><strong>test_ratio</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – The ratio of test edges.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">0.2</span></code>)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.models.SignedGCN.test">
<code class="sig-name descname">test</code><span class="sig-paren">(</span><em class="sig-param">z</em>, <em class="sig-param">pos_edge_index</em>, <em class="sig-param">neg_edge_index</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/signed_gcn.html#SignedGCN.test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.SignedGCN.test" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluates node embeddings <code class="xref py py-obj docutils literal notranslate"><span class="pre">z</span></code> on positive and negative test
edges by computing AUC and F1 scores.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z</strong> (<em>Tensor</em>) – The node embeddings.</p></li>
<li><p><strong>pos_edge_index</strong> (<em>LongTensor</em>) – The positive edge indices.</p></li>
<li><p><strong>neg_edge_index</strong> (<em>LongTensor</em>) – The negative edge indices.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.models.RENet">
<em class="property">class </em><code class="sig-name descname">RENet</code><span class="sig-paren">(</span><em class="sig-param">num_nodes</em>, <em class="sig-param">num_rels</em>, <em class="sig-param">hidden_channels</em>, <em class="sig-param">seq_len</em>, <em class="sig-param">num_layers=1</em>, <em class="sig-param">dropout=0.0</em>, <em class="sig-param">bias=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/re_net.html#RENet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.RENet" title="Permalink to this definition">¶</a></dt>
<dd><p>The Recurrent Event Network model from the <a class="reference external" href="https://arxiv.org/abs/1904.05530">“Recurrent Event Network
for Reasoning over Temporal Knowledge Graphs”</a> paper</p>
<div class="math notranslate nohighlight">
\[f_{\mathbf{\Theta}}(\mathbf{e}_s, \mathbf{e}_r,
\mathbf{h}^{(t-1)}(s, r))\]</div>
<p>based on a RNN encoder</p>
<div class="math notranslate nohighlight">
\[\mathbf{h}^{(t)}(s, r) = \textrm{RNN}(\mathbf{e}_s, \mathbf{e}_r,
g(\mathcal{O}^{(t)}_r(s)), \mathbf{h}^{(t-1)}(s, r))\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{e}_s\)</span> and <span class="math notranslate nohighlight">\(\mathbf{e}_r\)</span> denote entity and
relation embeddings, and <span class="math notranslate nohighlight">\(\mathcal{O}^{(t)}_r(s)\)</span> represents the set
of objects interacted with subject <span class="math notranslate nohighlight">\(s\)</span> under relation <span class="math notranslate nohighlight">\(r\)</span> at
timestamp <span class="math notranslate nohighlight">\(t\)</span>.
This model implements <span class="math notranslate nohighlight">\(g\)</span> as the <strong>Mean Aggregator</strong> and
<span class="math notranslate nohighlight">\(f_{\mathbf{\Theta}}\)</span> as a linear projection.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_nodes</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of nodes in the knowledge graph.</p></li>
<li><p><strong>num_rels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of relations in the knowledge graph.</p></li>
<li><p><strong>hidden_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Hidden size of node and relation embeddings.</p></li>
<li><p><strong>seq_len</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The sequence length of past events.</p></li>
<li><p><strong>num_layers</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – The number of recurrent layers.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">1</span></code>)</p></li>
<li><p><strong>dropout</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – If non-zero, introduces a dropout layer before the
final prediction. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">0.</span></code>)</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, all layers will not
learn an additive bias. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.models.RENet.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">data</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/re_net.html#RENet.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.RENet.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a <code class="xref py py-obj docutils literal notranslate"><span class="pre">data</span></code> batch, computes the forward pass.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data</strong> (<a class="reference internal" href="data.html#torch_geometric.data.Data" title="torch_geometric.data.Data"><em>torch_geometric.data.Data</em></a>) – The input data, holding subject
<code class="xref py py-obj docutils literal notranslate"><span class="pre">sub</span></code>, relation <code class="xref py py-obj docutils literal notranslate"><span class="pre">rel</span></code> and object <code class="xref py py-obj docutils literal notranslate"><span class="pre">obj</span></code>
information with shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">[batch_size]</span></code>.
In addition, <code class="xref py py-obj docutils literal notranslate"><span class="pre">data</span></code> needs to hold history information for
subjects, given by a vector of node indices <code class="xref py py-obj docutils literal notranslate"><span class="pre">h_sub</span></code> and
their relative timestamps <code class="xref py py-obj docutils literal notranslate"><span class="pre">h_sub_t</span></code> and batch assignments
<code class="xref py py-obj docutils literal notranslate"><span class="pre">h_sub_batch</span></code>.
The same information must be given for objects (<code class="xref py py-obj docutils literal notranslate"><span class="pre">h_obj</span></code>,
<code class="xref py py-obj docutils literal notranslate"><span class="pre">h_obj_t</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">h_obj_batch</span></code>).</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.models.RENet.pre_transform">
<em class="property">static </em><code class="sig-name descname">pre_transform</code><span class="sig-paren">(</span><em class="sig-param">seq_len</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/re_net.html#RENet.pre_transform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.RENet.pre_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Precomputes history objects</p>
<div class="math notranslate nohighlight">
\[\{ \mathcal{O}^{(t-k-1)}_r(s), \ldots, \mathcal{O}^{(t-1)}_r(s) \}\]</div>
<p>of a <code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.datasets.icews.EventDataset</span></code> with
<span class="math notranslate nohighlight">\(k\)</span> denoting the sequence length <code class="xref py py-obj docutils literal notranslate"><span class="pre">seq_len</span></code>.</p>
</dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.models.RENet.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/re_net.html#RENet.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.RENet.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.models.RENet.test">
<code class="sig-name descname">test</code><span class="sig-paren">(</span><em class="sig-param">logits</em>, <em class="sig-param">y</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/re_net.html#RENet.test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.RENet.test" title="Permalink to this definition">¶</a></dt>
<dd><p>Given ground-truth <code class="xref py py-obj docutils literal notranslate"><span class="pre">y</span></code>, computes Mean Reciprocal Rank (MRR)
and Hits at 1/3/10.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch_geometric.nn.models.GraphUNet">
<em class="property">class </em><code class="sig-name descname">GraphUNet</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">hidden_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">depth</em>, <em class="sig-param">pool_ratios=0.5</em>, <em class="sig-param">sum_res=True</em>, <em class="sig-param">act=&lt;function relu&gt;</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/graph_unet.html#GraphUNet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.GraphUNet" title="Permalink to this definition">¶</a></dt>
<dd><p>The Graph U-Net model from the <a class="reference external" href="https://arxiv.org/abs/1905.05178">“Graph U-Nets”</a> paper which implements a U-Net like
architecture with graph pooling and unpooling operations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each input sample.</p></li>
<li><p><strong>hidden_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each hidden sample.</p></li>
<li><p><strong>out_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of each output sample.</p></li>
<li><p><strong>depth</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The depth of the U-Net architecture.</p></li>
<li><p><strong>pool_ratios</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em> or </em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>]</em><em>, </em><em>optional</em>) – Graph pooling ratio for each
depth. (default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">0.5</span></code>)</p></li>
<li><p><strong>sum_res</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">False</span></code></a>, will use
concatenation for integration of skip connections instead
summation. (default: <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">True</span></code></a>)</p></li>
<li><p><strong>act</strong> (<em>torch.nn.functional</em><em>, </em><em>optional</em>) – The nonlinearity to use.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.nn.functional.relu</span></code>)</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.models.GraphUNet.augment_adj">
<code class="sig-name descname">augment_adj</code><span class="sig-paren">(</span><em class="sig-param">edge_index</em>, <em class="sig-param">edge_weight</em>, <em class="sig-param">num_nodes</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/graph_unet.html#GraphUNet.augment_adj"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.GraphUNet.augment_adj" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.models.GraphUNet.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">edge_index</em>, <em class="sig-param">batch=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/graph_unet.html#GraphUNet.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.GraphUNet.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.models.GraphUNet.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/models/graph_unet.html#GraphUNet.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.models.GraphUNet.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-torch_geometric.nn.data_parallel">
<span id="dataparallel-layers"></span><h2><a class="toc-backref" href="#id19">DataParallel Layers</a><a class="headerlink" href="#module-torch_geometric.nn.data_parallel" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch_geometric.nn.data_parallel.DataParallel">
<em class="property">class </em><code class="sig-name descname">DataParallel</code><span class="sig-paren">(</span><em class="sig-param">module</em>, <em class="sig-param">device_ids=None</em>, <em class="sig-param">output_device=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/data_parallel.html#DataParallel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.data_parallel.DataParallel" title="Permalink to this definition">¶</a></dt>
<dd><p>Implements data parallelism at the module level.</p>
<p>This container parallelizes the application of the given <code class="xref py py-attr docutils literal notranslate"><span class="pre">module</span></code> by
splitting a list of <a class="reference internal" href="data.html#torch_geometric.data.Data" title="torch_geometric.data.Data"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.data.Data</span></code></a> objects and copying
them as <a class="reference internal" href="data.html#torch_geometric.data.Batch" title="torch_geometric.data.Batch"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.data.Batch</span></code></a> objects to each device.
In the forward pass, the module is replicated on each device, and each
replica handles a portion of the input.
During the backwards pass, gradients from each replica are summed into the
original module.</p>
<p>The batch size should be larger than the number of GPUs used.</p>
<p>The parallelized <code class="xref py py-attr docutils literal notranslate"><span class="pre">module</span></code> must have its parameters and buffers on
<code class="xref py py-obj docutils literal notranslate"><span class="pre">device_ids[0]</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You need to use the <a class="reference internal" href="data.html#torch_geometric.data.DataListLoader" title="torch_geometric.data.DataListLoader"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch_geometric.data.DataListLoader</span></code></a> for
this module.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> (<em>Module</em>) – Module to be parallelized.</p></li>
<li><p><strong>device_ids</strong> (<em>list of int</em><em> or </em><em>torch.device</em>) – CUDA devices.
(default: all devices)</p></li>
<li><p><strong>output_device</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em> or </em><em>torch.device</em>) – Device location of output.
(default: <code class="xref py py-obj docutils literal notranslate"><span class="pre">device_ids[0]</span></code>)</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch_geometric.nn.data_parallel.DataParallel.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">data_list</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/data_parallel.html#DataParallel.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.data_parallel.DataParallel.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch_geometric.nn.data_parallel.DataParallel.scatter">
<code class="sig-name descname">scatter</code><span class="sig-paren">(</span><em class="sig-param">data_list</em>, <em class="sig-param">device_ids</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch_geometric/nn/data_parallel.html#DataParallel.scatter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch_geometric.nn.data_parallel.DataParallel.scatter" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="data.html" class="btn btn-neutral float-right" title="torch_geometric.data" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="root.html" class="btn btn-neutral float-left" title="torch_geometric" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Matthias Fey

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>